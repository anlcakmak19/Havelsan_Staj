{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87c2e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# scikit-learn modules\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13a5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "rn.seed(12345)\n",
    "\n",
    "# The below set_seed() will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9838c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "def Evolution_Metrics(model,x_test,y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(color.BOLD)\n",
    "    print('MAE: ',mae)\n",
    "    print('MSE: ',mse)\n",
    "    print('RMSE: ',rmse)\n",
    "    print('R2: ',r2)\n",
    "    print(color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2628f5",
   "metadata": {},
   "source": [
    "# Each RunId Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc4343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s.iloc[::4, :]['Z02013']\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 4).mean()\n",
    "        resample_list.append(grouped_df)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 4).max()\n",
    "        resample_list.append(grouped_df)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 4).min()\n",
    "        resample_list.append(grouped_df)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48198112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83794a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Z02013']\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f831439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3069c149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>G00108</th>\n",
       "      <th>G02011</th>\n",
       "      <th>N02015</th>\n",
       "      <th>P00023</th>\n",
       "      <th>P01005</th>\n",
       "      <th>...</th>\n",
       "      <th>T01601</th>\n",
       "      <th>T01603</th>\n",
       "      <th>T02014</th>\n",
       "      <th>T02040</th>\n",
       "      <th>T02041</th>\n",
       "      <th>T02042</th>\n",
       "      <th>T02044</th>\n",
       "      <th>T04600</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z01970</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.033825</td>\n",
       "      <td>305.55825</td>\n",
       "      <td>56.30100</td>\n",
       "      <td>13.809175</td>\n",
       "      <td>2.639642</td>\n",
       "      <td>2.834907</td>\n",
       "      <td>2.640425</td>\n",
       "      <td>73.956575</td>\n",
       "      <td>7.789537</td>\n",
       "      <td>2.153763</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5331</td>\n",
       "      <td>348.143</td>\n",
       "      <td>305.317</td>\n",
       "      <td>303.497</td>\n",
       "      <td>-1.82216</td>\n",
       "      <td>43.7888</td>\n",
       "      <td>48.0049</td>\n",
       "      <td>220.359</td>\n",
       "      <td>12.8062</td>\n",
       "      <td>12.8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.005075</td>\n",
       "      <td>327.46400</td>\n",
       "      <td>788.21375</td>\n",
       "      <td>13.775850</td>\n",
       "      <td>2.647335</td>\n",
       "      <td>2.836055</td>\n",
       "      <td>2.648525</td>\n",
       "      <td>73.934000</td>\n",
       "      <td>7.789335</td>\n",
       "      <td>2.154190</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5319</td>\n",
       "      <td>348.450</td>\n",
       "      <td>305.349</td>\n",
       "      <td>303.541</td>\n",
       "      <td>-1.83174</td>\n",
       "      <td>43.7502</td>\n",
       "      <td>48.0043</td>\n",
       "      <td>220.370</td>\n",
       "      <td>12.8063</td>\n",
       "      <td>12.8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.042100</td>\n",
       "      <td>304.82850</td>\n",
       "      <td>1689.02750</td>\n",
       "      <td>13.818000</td>\n",
       "      <td>2.640332</td>\n",
       "      <td>2.837467</td>\n",
       "      <td>2.641055</td>\n",
       "      <td>73.962475</td>\n",
       "      <td>7.789135</td>\n",
       "      <td>2.154530</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5307</td>\n",
       "      <td>348.401</td>\n",
       "      <td>305.413</td>\n",
       "      <td>303.591</td>\n",
       "      <td>-1.84132</td>\n",
       "      <td>43.7116</td>\n",
       "      <td>48.0038</td>\n",
       "      <td>220.383</td>\n",
       "      <td>12.8065</td>\n",
       "      <td>12.8771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.079175</td>\n",
       "      <td>282.19250</td>\n",
       "      <td>2589.84500</td>\n",
       "      <td>13.860175</td>\n",
       "      <td>2.633325</td>\n",
       "      <td>2.838880</td>\n",
       "      <td>2.633585</td>\n",
       "      <td>73.990975</td>\n",
       "      <td>7.788935</td>\n",
       "      <td>2.154870</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5295</td>\n",
       "      <td>348.352</td>\n",
       "      <td>305.478</td>\n",
       "      <td>303.641</td>\n",
       "      <td>-1.85091</td>\n",
       "      <td>43.6729</td>\n",
       "      <td>48.0032</td>\n",
       "      <td>220.396</td>\n",
       "      <td>12.8067</td>\n",
       "      <td>12.8666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.101650</td>\n",
       "      <td>267.10325</td>\n",
       "      <td>3150.32500</td>\n",
       "      <td>13.885750</td>\n",
       "      <td>2.628635</td>\n",
       "      <td>2.839380</td>\n",
       "      <td>2.628602</td>\n",
       "      <td>74.008350</td>\n",
       "      <td>7.788915</td>\n",
       "      <td>2.155350</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5292</td>\n",
       "      <td>348.340</td>\n",
       "      <td>305.542</td>\n",
       "      <td>303.691</td>\n",
       "      <td>-1.85330</td>\n",
       "      <td>43.6633</td>\n",
       "      <td>48.0031</td>\n",
       "      <td>220.408</td>\n",
       "      <td>12.8069</td>\n",
       "      <td>12.8557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>14.094350</td>\n",
       "      <td>261.61750</td>\n",
       "      <td>3131.57500</td>\n",
       "      <td>13.878475</td>\n",
       "      <td>2.625430</td>\n",
       "      <td>2.834192</td>\n",
       "      <td>2.625402</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.789920</td>\n",
       "      <td>2.156467</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5347</td>\n",
       "      <td>348.376</td>\n",
       "      <td>305.445</td>\n",
       "      <td>303.972</td>\n",
       "      <td>-1.48109</td>\n",
       "      <td>43.9690</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.397</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.8197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>14.096150</td>\n",
       "      <td>255.75850</td>\n",
       "      <td>3131.19000</td>\n",
       "      <td>13.880425</td>\n",
       "      <td>2.624820</td>\n",
       "      <td>2.833965</td>\n",
       "      <td>2.624785</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790100</td>\n",
       "      <td>2.156413</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5328</td>\n",
       "      <td>348.376</td>\n",
       "      <td>305.500</td>\n",
       "      <td>304.039</td>\n",
       "      <td>-1.47201</td>\n",
       "      <td>43.9122</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.407</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.8133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>14.096925</td>\n",
       "      <td>250.91025</td>\n",
       "      <td>3130.95000</td>\n",
       "      <td>13.881100</td>\n",
       "      <td>2.624157</td>\n",
       "      <td>2.833580</td>\n",
       "      <td>2.624128</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790287</td>\n",
       "      <td>2.156290</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5323</td>\n",
       "      <td>348.304</td>\n",
       "      <td>305.556</td>\n",
       "      <td>304.106</td>\n",
       "      <td>-1.46292</td>\n",
       "      <td>43.8772</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.418</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.8043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11091</th>\n",
       "      <td>14.096050</td>\n",
       "      <td>247.74675</td>\n",
       "      <td>3130.95000</td>\n",
       "      <td>13.879650</td>\n",
       "      <td>2.623415</td>\n",
       "      <td>2.832935</td>\n",
       "      <td>2.623400</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790495</td>\n",
       "      <td>2.156050</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5323</td>\n",
       "      <td>348.209</td>\n",
       "      <td>305.560</td>\n",
       "      <td>304.116</td>\n",
       "      <td>-1.45080</td>\n",
       "      <td>43.8493</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.440</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>14.095400</td>\n",
       "      <td>245.37450</td>\n",
       "      <td>3130.95000</td>\n",
       "      <td>13.878600</td>\n",
       "      <td>2.622860</td>\n",
       "      <td>2.832450</td>\n",
       "      <td>2.622860</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790650</td>\n",
       "      <td>2.155870</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5323</td>\n",
       "      <td>348.161</td>\n",
       "      <td>305.565</td>\n",
       "      <td>304.126</td>\n",
       "      <td>-1.43867</td>\n",
       "      <td>43.8354</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.463</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.7896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11093 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E02005     E02006      E02056     E03760    G00027    G00108  \\\n",
       "0      14.033825  305.55825    56.30100  13.809175  2.639642  2.834907   \n",
       "1      14.005075  327.46400   788.21375  13.775850  2.647335  2.836055   \n",
       "2      14.042100  304.82850  1689.02750  13.818000  2.640332  2.837467   \n",
       "3      14.079175  282.19250  2589.84500  13.860175  2.633325  2.838880   \n",
       "4      14.101650  267.10325  3150.32500  13.885750  2.628635  2.839380   \n",
       "...          ...        ...         ...        ...       ...       ...   \n",
       "11088  14.094350  261.61750  3131.57500  13.878475  2.625430  2.834192   \n",
       "11089  14.096150  255.75850  3131.19000  13.880425  2.624820  2.833965   \n",
       "11090  14.096925  250.91025  3130.95000  13.881100  2.624157  2.833580   \n",
       "11091  14.096050  247.74675  3130.95000  13.879650  2.623415  2.832935   \n",
       "11092  14.095400  245.37450  3130.95000  13.878600  2.622860  2.832450   \n",
       "\n",
       "         G02011     N02015    P00023    P01005  ...   T01601   T01603  \\\n",
       "0      2.640425  73.956575  7.789537  2.153763  ...  43.5331  348.143   \n",
       "1      2.648525  73.934000  7.789335  2.154190  ...  43.5319  348.450   \n",
       "2      2.641055  73.962475  7.789135  2.154530  ...  43.5307  348.401   \n",
       "3      2.633585  73.990975  7.788935  2.154870  ...  43.5295  348.352   \n",
       "4      2.628602  74.008350  7.788915  2.155350  ...  43.5292  348.340   \n",
       "...         ...        ...       ...       ...  ...      ...      ...   \n",
       "11088  2.625402  74.001700  7.789920  2.156467  ...  43.5347  348.376   \n",
       "11089  2.624785  74.001700  7.790100  2.156413  ...  43.5328  348.376   \n",
       "11090  2.624128  74.001700  7.790287  2.156290  ...  43.5323  348.304   \n",
       "11091  2.623400  74.001700  7.790495  2.156050  ...  43.5323  348.209   \n",
       "11092  2.622860  74.001700  7.790650  2.155870  ...  43.5323  348.161   \n",
       "\n",
       "        T02014   T02040   T02041   T02042   T02044   T04600   Z00518   Z01970  \n",
       "0      305.317  303.497 -1.82216  43.7888  48.0049  220.359  12.8062  12.8297  \n",
       "1      305.349  303.541 -1.83174  43.7502  48.0043  220.370  12.8063  12.8876  \n",
       "2      305.413  303.591 -1.84132  43.7116  48.0038  220.383  12.8065  12.8771  \n",
       "3      305.478  303.641 -1.85091  43.6729  48.0032  220.396  12.8067  12.8666  \n",
       "4      305.542  303.691 -1.85330  43.6633  48.0031  220.408  12.8069  12.8557  \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "11088  305.445  303.972 -1.48109  43.9690  48.0087  220.397  12.8043  12.8197  \n",
       "11089  305.500  304.039 -1.47201  43.9122  48.0087  220.407  12.8043  12.8133  \n",
       "11090  305.556  304.106 -1.46292  43.8772  48.0087  220.418  12.8043  12.8043  \n",
       "11091  305.560  304.116 -1.45080  43.8493  48.0087  220.440  12.8043  12.7945  \n",
       "11092  305.565  304.126 -1.43867  43.8354  48.0087  220.463  12.8043  12.7896  \n",
       "\n",
       "[11093 rows x 105 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6777d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19.9715\n",
       "1        20.6244\n",
       "2        20.4081\n",
       "3        20.1917\n",
       "4        19.9754\n",
       "          ...   \n",
       "11088    19.9671\n",
       "11089    19.9742\n",
       "11090    19.9814\n",
       "11091    19.9814\n",
       "11092    19.9814\n",
       "Name: Z02013, Length: 11093, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56358e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1287841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dddd978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6954eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f53f2e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6edffb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0027590663345821802\n",
      "MSE:  6.410341156010164e-05\n",
      "RMSE:  0.008006460613785698\n",
      "R2:  0.9570171749712255\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f9803af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06b775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.002761198154446291\n",
      "MSE:  6.420712634791178e-05\n",
      "RMSE:  0.008012934939702916\n",
      "R2:  0.9569476317992033\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dacbecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\AppData\\Local\\Temp/ipykernel_12572/3914077697.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model_3.fit(X_train_scaled, Y_train_scaled)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "122cdcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  19.989326219369737\n",
      "MSE:  400.38467159566704\n",
      "RMSE:  20.009614478936545\n",
      "R2:  -268466.21359384374\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29c306d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 96)               384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 384)              1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55946b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 6ms/step - loss: 0.6988 - mse: 0.6988 - val_loss: 0.2489 - val_mse: 0.2489\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4065 - mse: 0.4065 - val_loss: 0.2816 - val_mse: 0.2816\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.3277 - mse: 0.3277 - val_loss: 0.3742 - val_mse: 0.3742\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.2936 - mse: 0.2936 - val_loss: 0.1563 - val_mse: 0.1563\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.2693 - mse: 0.2693 - val_loss: 0.1438 - val_mse: 0.1438\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.5411 - val_mse: 0.5411\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.2731 - mse: 0.2731 - val_loss: 0.1783 - val_mse: 0.1783\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.2174 - mse: 0.2174 - val_loss: 0.3772 - val_mse: 0.3772\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.2430 - mse: 0.2430 - val_loss: 0.2264 - val_mse: 0.2264\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.2007 - mse: 0.2007 - val_loss: 0.1145 - val_mse: 0.1145\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 0.4415 - val_mse: 0.4415\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1919 - mse: 0.1919 - val_loss: 0.1154 - val_mse: 0.1154\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1649 - mse: 0.1649 - val_loss: 0.1791 - val_mse: 0.1791\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1635 - mse: 0.1635 - val_loss: 0.2380 - val_mse: 0.2380\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1662 - mse: 0.1662 - val_loss: 0.1161 - val_mse: 0.1161\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 0.1050 - val_mse: 0.1050\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1902 - mse: 0.1902 - val_loss: 0.8043 - val_mse: 0.8043\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1749 - mse: 0.1749 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 0.1332 - val_mse: 0.1332\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1610 - mse: 0.1610 - val_loss: 0.2746 - val_mse: 0.2746\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1423 - mse: 0.1423 - val_loss: 0.3215 - val_mse: 0.3215\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1356 - mse: 0.1356 - val_loss: 0.1882 - val_mse: 0.1882\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1336 - mse: 0.1336 - val_loss: 0.2463 - val_mse: 0.2463\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.1340 - mse: 0.1340 - val_loss: 0.1097 - val_mse: 0.1097\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.1215 - mse: 0.1215 - val_loss: 0.1406 - val_mse: 0.1406\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1396 - mse: 0.1396 - val_loss: 0.1720 - val_mse: 0.1720\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 0.1167 - val_mse: 0.1167\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.1519 - mse: 0.1519 - val_loss: 0.1365 - val_mse: 0.1365\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63d4c1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 0s 2ms/step\n",
      "Root Mean Squared Error: 0.013582257632662555\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868ca1b",
   "metadata": {},
   "source": [
    "# Each RunId Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f97dcfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(4 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(4).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(4).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(4).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a21591c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01ae6ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e2b4c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>G00108</th>\n",
       "      <th>G02011</th>\n",
       "      <th>N02015</th>\n",
       "      <th>P00023</th>\n",
       "      <th>P01005</th>\n",
       "      <th>...</th>\n",
       "      <th>T01601</th>\n",
       "      <th>T01603</th>\n",
       "      <th>T02014</th>\n",
       "      <th>T02040</th>\n",
       "      <th>T02041</th>\n",
       "      <th>T02042</th>\n",
       "      <th>T02044</th>\n",
       "      <th>T04600</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z01970</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.033825</td>\n",
       "      <td>305.55825</td>\n",
       "      <td>56.30100</td>\n",
       "      <td>13.809175</td>\n",
       "      <td>2.639642</td>\n",
       "      <td>2.834907</td>\n",
       "      <td>2.640425</td>\n",
       "      <td>73.956575</td>\n",
       "      <td>7.789537</td>\n",
       "      <td>2.153763</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5331</td>\n",
       "      <td>348.143</td>\n",
       "      <td>305.317</td>\n",
       "      <td>303.497</td>\n",
       "      <td>-1.82216</td>\n",
       "      <td>43.7888</td>\n",
       "      <td>48.0049</td>\n",
       "      <td>220.359</td>\n",
       "      <td>12.8062</td>\n",
       "      <td>12.8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.009025</td>\n",
       "      <td>322.87725</td>\n",
       "      <td>168.90300</td>\n",
       "      <td>13.780650</td>\n",
       "      <td>2.645460</td>\n",
       "      <td>2.835085</td>\n",
       "      <td>2.646578</td>\n",
       "      <td>73.937275</td>\n",
       "      <td>7.789492</td>\n",
       "      <td>2.153880</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5328</td>\n",
       "      <td>348.143</td>\n",
       "      <td>305.317</td>\n",
       "      <td>303.497</td>\n",
       "      <td>-1.82455</td>\n",
       "      <td>43.7792</td>\n",
       "      <td>48.0047</td>\n",
       "      <td>220.359</td>\n",
       "      <td>12.8062</td>\n",
       "      <td>12.8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.986525</td>\n",
       "      <td>338.78150</td>\n",
       "      <td>337.80600</td>\n",
       "      <td>13.754775</td>\n",
       "      <td>2.650840</td>\n",
       "      <td>2.835350</td>\n",
       "      <td>2.652262</td>\n",
       "      <td>73.919750</td>\n",
       "      <td>7.789435</td>\n",
       "      <td>2.154020</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5325</td>\n",
       "      <td>348.474</td>\n",
       "      <td>305.317</td>\n",
       "      <td>303.516</td>\n",
       "      <td>-1.82695</td>\n",
       "      <td>43.7695</td>\n",
       "      <td>48.0046</td>\n",
       "      <td>220.364</td>\n",
       "      <td>12.8062</td>\n",
       "      <td>12.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.995800</td>\n",
       "      <td>333.12275</td>\n",
       "      <td>563.00975</td>\n",
       "      <td>13.765300</td>\n",
       "      <td>2.649087</td>\n",
       "      <td>2.835703</td>\n",
       "      <td>2.650395</td>\n",
       "      <td>73.926875</td>\n",
       "      <td>7.789385</td>\n",
       "      <td>2.154105</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5322</td>\n",
       "      <td>348.462</td>\n",
       "      <td>305.333</td>\n",
       "      <td>303.529</td>\n",
       "      <td>-1.82934</td>\n",
       "      <td>43.7599</td>\n",
       "      <td>48.0045</td>\n",
       "      <td>220.367</td>\n",
       "      <td>12.8062</td>\n",
       "      <td>12.8902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.005075</td>\n",
       "      <td>327.46400</td>\n",
       "      <td>788.21375</td>\n",
       "      <td>13.775850</td>\n",
       "      <td>2.647335</td>\n",
       "      <td>2.836055</td>\n",
       "      <td>2.648525</td>\n",
       "      <td>73.934000</td>\n",
       "      <td>7.789335</td>\n",
       "      <td>2.154190</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5319</td>\n",
       "      <td>348.450</td>\n",
       "      <td>305.349</td>\n",
       "      <td>303.541</td>\n",
       "      <td>-1.83174</td>\n",
       "      <td>43.7502</td>\n",
       "      <td>48.0043</td>\n",
       "      <td>220.370</td>\n",
       "      <td>12.8063</td>\n",
       "      <td>12.8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44218</th>\n",
       "      <td>14.096500</td>\n",
       "      <td>249.32850</td>\n",
       "      <td>3130.95000</td>\n",
       "      <td>13.880375</td>\n",
       "      <td>2.623785</td>\n",
       "      <td>2.833260</td>\n",
       "      <td>2.623762</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790392</td>\n",
       "      <td>2.156170</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5323</td>\n",
       "      <td>348.257</td>\n",
       "      <td>305.558</td>\n",
       "      <td>304.111</td>\n",
       "      <td>-1.45686</td>\n",
       "      <td>43.8632</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.429</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.7994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44219</th>\n",
       "      <td>14.096275</td>\n",
       "      <td>248.53750</td>\n",
       "      <td>3130.95000</td>\n",
       "      <td>13.880025</td>\n",
       "      <td>2.623600</td>\n",
       "      <td>2.833098</td>\n",
       "      <td>2.623580</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790445</td>\n",
       "      <td>2.156110</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5323</td>\n",
       "      <td>348.233</td>\n",
       "      <td>305.559</td>\n",
       "      <td>304.113</td>\n",
       "      <td>-1.45383</td>\n",
       "      <td>43.8563</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.435</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.7970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44220</th>\n",
       "      <td>14.096050</td>\n",
       "      <td>247.74675</td>\n",
       "      <td>3130.95000</td>\n",
       "      <td>13.879650</td>\n",
       "      <td>2.623415</td>\n",
       "      <td>2.832935</td>\n",
       "      <td>2.623400</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790495</td>\n",
       "      <td>2.156050</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5323</td>\n",
       "      <td>348.209</td>\n",
       "      <td>305.560</td>\n",
       "      <td>304.116</td>\n",
       "      <td>-1.45080</td>\n",
       "      <td>43.8493</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.440</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44221</th>\n",
       "      <td>14.095825</td>\n",
       "      <td>246.95600</td>\n",
       "      <td>3130.95000</td>\n",
       "      <td>13.879300</td>\n",
       "      <td>2.623230</td>\n",
       "      <td>2.832773</td>\n",
       "      <td>2.623220</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790545</td>\n",
       "      <td>2.155990</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5323</td>\n",
       "      <td>348.185</td>\n",
       "      <td>305.562</td>\n",
       "      <td>304.118</td>\n",
       "      <td>-1.44776</td>\n",
       "      <td>43.8423</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.446</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.7921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44222</th>\n",
       "      <td>14.095600</td>\n",
       "      <td>246.16525</td>\n",
       "      <td>3130.95000</td>\n",
       "      <td>13.878950</td>\n",
       "      <td>2.623045</td>\n",
       "      <td>2.832610</td>\n",
       "      <td>2.623040</td>\n",
       "      <td>74.001700</td>\n",
       "      <td>7.790598</td>\n",
       "      <td>2.155930</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5323</td>\n",
       "      <td>348.161</td>\n",
       "      <td>305.563</td>\n",
       "      <td>304.121</td>\n",
       "      <td>-1.44473</td>\n",
       "      <td>43.8354</td>\n",
       "      <td>48.0087</td>\n",
       "      <td>220.451</td>\n",
       "      <td>12.8043</td>\n",
       "      <td>12.7896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44223 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E02005     E02006      E02056     E03760    G00027    G00108  \\\n",
       "0      14.033825  305.55825    56.30100  13.809175  2.639642  2.834907   \n",
       "1      14.009025  322.87725   168.90300  13.780650  2.645460  2.835085   \n",
       "2      13.986525  338.78150   337.80600  13.754775  2.650840  2.835350   \n",
       "3      13.995800  333.12275   563.00975  13.765300  2.649087  2.835703   \n",
       "4      14.005075  327.46400   788.21375  13.775850  2.647335  2.836055   \n",
       "...          ...        ...         ...        ...       ...       ...   \n",
       "44218  14.096500  249.32850  3130.95000  13.880375  2.623785  2.833260   \n",
       "44219  14.096275  248.53750  3130.95000  13.880025  2.623600  2.833098   \n",
       "44220  14.096050  247.74675  3130.95000  13.879650  2.623415  2.832935   \n",
       "44221  14.095825  246.95600  3130.95000  13.879300  2.623230  2.832773   \n",
       "44222  14.095600  246.16525  3130.95000  13.878950  2.623045  2.832610   \n",
       "\n",
       "         G02011     N02015    P00023    P01005  ...   T01601   T01603  \\\n",
       "0      2.640425  73.956575  7.789537  2.153763  ...  43.5331  348.143   \n",
       "1      2.646578  73.937275  7.789492  2.153880  ...  43.5328  348.143   \n",
       "2      2.652262  73.919750  7.789435  2.154020  ...  43.5325  348.474   \n",
       "3      2.650395  73.926875  7.789385  2.154105  ...  43.5322  348.462   \n",
       "4      2.648525  73.934000  7.789335  2.154190  ...  43.5319  348.450   \n",
       "...         ...        ...       ...       ...  ...      ...      ...   \n",
       "44218  2.623762  74.001700  7.790392  2.156170  ...  43.5323  348.257   \n",
       "44219  2.623580  74.001700  7.790445  2.156110  ...  43.5323  348.233   \n",
       "44220  2.623400  74.001700  7.790495  2.156050  ...  43.5323  348.209   \n",
       "44221  2.623220  74.001700  7.790545  2.155990  ...  43.5323  348.185   \n",
       "44222  2.623040  74.001700  7.790598  2.155930  ...  43.5323  348.161   \n",
       "\n",
       "        T02014   T02040   T02041   T02042   T02044   T04600   Z00518   Z01970  \n",
       "0      305.317  303.497 -1.82216  43.7888  48.0049  220.359  12.8062  12.8297  \n",
       "1      305.317  303.497 -1.82455  43.7792  48.0047  220.359  12.8062  12.8297  \n",
       "2      305.317  303.516 -1.82695  43.7695  48.0046  220.364  12.8062  12.8928  \n",
       "3      305.333  303.529 -1.82934  43.7599  48.0045  220.367  12.8062  12.8902  \n",
       "4      305.349  303.541 -1.83174  43.7502  48.0043  220.370  12.8063  12.8876  \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "44218  305.558  304.111 -1.45686  43.8632  48.0087  220.429  12.8043  12.7994  \n",
       "44219  305.559  304.113 -1.45383  43.8563  48.0087  220.435  12.8043  12.7970  \n",
       "44220  305.560  304.116 -1.45080  43.8493  48.0087  220.440  12.8043  12.7945  \n",
       "44221  305.562  304.118 -1.44776  43.8423  48.0087  220.446  12.8043  12.7921  \n",
       "44222  305.563  304.121 -1.44473  43.8354  48.0087  220.451  12.8043  12.7896  \n",
       "\n",
       "[44223 rows x 105 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23e32e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20.6785\n",
       "1        20.6244\n",
       "2        20.5703\n",
       "3        20.5163\n",
       "4        20.4622\n",
       "          ...   \n",
       "44218    19.9814\n",
       "44219    19.9814\n",
       "44220    19.9814\n",
       "44221    19.9814\n",
       "44222    19.9814\n",
       "Name: Z02013, Length: 44223, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67d8117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d439426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09dc0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "171bdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65c13114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8172a695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0018121468580672086\n",
      "MSE:  3.811351233400561e-05\n",
      "RMSE:  0.0061736142035282385\n",
      "R2:  0.9720246305868635\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adb6405c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6bedbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0018137491946430082\n",
      "MSE:  3.8499730075087596e-05\n",
      "RMSE:  0.006204815071788006\n",
      "R2:  0.9717411462444604\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33527303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\AppData\\Local\\Temp/ipykernel_12572/3914077697.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model_3.fit(X_train_scaled, Y_train_scaled)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "503a68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  19.979783140895922\n",
      "MSE:  400.15714938633175\n",
      "RMSE:  20.003928348860175\n",
      "R2:  -293714.8868825191\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3acdffdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 96)               384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 384)              1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0ea8a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 5ms/step - loss: 0.3296 - mse: 0.3296 - val_loss: 0.3122 - val_mse: 0.3122\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 5s 5ms/step - loss: 0.1855 - mse: 0.1855 - val_loss: 0.2299 - val_mse: 0.2299\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 5s 5ms/step - loss: 0.1581 - mse: 0.1581 - val_loss: 0.2283 - val_mse: 0.2283\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1458 - mse: 0.1458 - val_loss: 0.1932 - val_mse: 0.1932\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1254 - mse: 0.1254 - val_loss: 0.1974 - val_mse: 0.1974\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1192 - mse: 0.1192 - val_loss: 0.2193 - val_mse: 0.2193\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.2150 - val_mse: 0.2150\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1144 - mse: 0.1144 - val_loss: 0.2161 - val_mse: 0.2161\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1125 - mse: 0.1125 - val_loss: 0.2273 - val_mse: 0.2273\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1029 - mse: 0.1029 - val_loss: 0.2205 - val_mse: 0.2205\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1027 - mse: 0.1027 - val_loss: 0.2223 - val_mse: 0.2223\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0943 - mse: 0.0943 - val_loss: 0.2061 - val_mse: 0.2061\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 0.2271 - val_mse: 0.2271\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 0.2041 - val_mse: 0.2041\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b55e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674/674 [==============================] - 2s 3ms/step\n",
      "Root Mean Squared Error: 0.00911957454867337\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea52366",
   "metadata": {},
   "source": [
    "# Each RunId Bucket PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37dffee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s.iloc[::4, :]['Z02013']\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 4).mean()\n",
    "        resample_list.append(grouped_df)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 4).max()\n",
    "        resample_list.append(grouped_df)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 4).min()\n",
    "        resample_list.append(grouped_df)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "878b0002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2a71258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b377c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68e1ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52a778fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d85b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c54551ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAl6klEQVR4nO3deZycVZ3v8c83nY2AEBZtgSBBjUJEkJk2uKC0og6oCDI6Ay4oA0YU3EbvDOJVdMa5F8dR4V6XTBRERpZhGFBkIuAgZYYRDVsIARIJYYvsV7aGdLqr63f/eE4lTxdPpSttqqu7n+/79apXVz1bnV8Tzq/POc9zjiICMzOzRlM6XQAzMxufnCDMzKyQE4SZmRVygjAzs0JOEGZmVsgJwszMCjlB2KQl6RxJX23x2J9L+lAbyjBXUkiaurWv3eT7+iS9eCy+yyY/JwjrOEn3SFqfKrf669tjWYaIOCwifjSW3ynpSkl/V7D9CEkPjSapRMR2EbF265TQys4JwsaLw1PlVn+d3OkCjYFzgA9KUsP2DwLnRUS11QuNVQvFysUJwsY1Sd+TdHHu89ckXa1Mr6R1kk6V9Fhqiby/yXV2lHS5pEclPZ7ez8ntr0g6Ib3/sKRrJf1TOvZuSYfljt1B0lmSHpT0e0lfldSV9nWl8x6TtBZ4x2bC+wmwE/CGfDmBdwLnSlog6TpJT6Tv+rak6bljQ9JJku4E7sxte2l6/w5JN0t6StL9kr6cO7fe9fUhSfel8n4ht78r/V7vkvS0pBsl7ZH27S3pF5L+IGm1pL/YTIw2gTlB2Hj3WWC/VGm/ATge+FBsmiPmhcAuwO7Ah4DFkl5ecJ0pwA+BPYEXAeuBzXVjHQisTtf+R+Cs3F/6PwKqwEuBA4C3ASekfR8hq+APAHqA9zT7gohYD1wEHJvb/BfAqoi4BRgCPpPK8FrgEODjDZc5MpV1fsFXPJOuPZssUX1M0pENxxwEvDxd+0uS9knb/xo4Bng7sD3wV8CzkrYFfgGcD7wgHfNdSa9oFqdNYBHhl18dfQH3AH3AE7nXR3L7FwB/AO4Fjslt7yWrqLfNbbsI+GJ6fw7w1Sbf+Srg8dznCnBCev9hYE1u3ywgyJJRN7AB2Ca3/xjgmvT+l8CJuX1vS+dObVKOg4An69cD/hv4TJNjPw1cmvscwJsbjgngpU3OPwP4Vno/Nx07J7d/GXB0er8aOKLgGn8J/FfDtn8GTuv0vyO/tv7L/ZY2XhwZEf9ZtCMilqXumheQJYC8xyPimdzne4HdGq8haRbwLeBQYMe0+XmSuiJiqOBrH8p9/7Op8bAdWZfQNODB3NDBFOD+9H633Pt6eZqKiGslPQocIWkZ8GrgqFTmlwHfJGuJzAKmAjc2XOJ+mpB0IHA6sC8wHZgB/FuzOIFnU4wAewB3FVx2T+BASU/ktk0F/qVZOWzicheTjXuSTiKr3B4A/qZh946p26PuRem4Rp8l60o5MCK2B95Yv/wWFud+shbELhExO722j4h6F8uDZJVrvjwjOZesK+iDwFUR8XDa/j1gFTAvlfnUgvJubjrm84HLgD0iYgdgUcH5zdwPvKTJ9l/lYp8d2U0FH2vxujaBOEHYuJb+iv4q8AGyCvRvJL2q4bCvSJqexijeyXP/SgZ4Htm4wxOSdgJOG015IuJB4CrgG5K2lzRF0kskHZwOuQj4pKQ5acD5lBYuey7wFrLxi/ytts8DngL6JO0NbGkl/DzgDxHRL2kB8L4tOPcHwN9LmpduCNhP0s7A5cDLJH1Q0rT0enVu7MImEScIGy9+puHPQVyabt38MfC1iLglIu4k+yv6XyTNSOc9BDxO1mo4j6z/f1XB9c8AtgEeA34DXPFHlPVYsi6b29N3XwzsmvZ9H7gSuAW4CbhkpItFxD3Ar4Ftyf7ir/scWaX+dLruv25hOT8O/J2kp4Ev8dzuuc35Zjr+KrIkdRbZOMnTZOMqR5P9zh8CvkbWwrNJRhFeMMgmJkm9wI8jYs4Ih5rZKLgFYWZmhZwgzMyskLuYzMyskFsQZmZWaFI9KLfLLrvE3LlzR3XuM888w7bbbjvygRNcWeKE8sRaljihPLGOZZw33njjYxHx/KJ9kypBzJ07lxtuuGFU51YqFXp7e7dugcahssQJ5Ym1LHFCeWIdyzglNX3a311MZmZWyAnCzMwKOUGYmVkhJwgzMyvkBGFmZoXaliAknS3pEUkrm+yXpP8jaY2kFZL+JLfv0LSU4RpJrcyGaWZmW1k7WxDnkC3O0sxhwLz0Wkg29z1pbd/vpP3zgWMkFS2naGZmbdS25yAiYqmkuZs55Ajg3Mjm+viNpNmSdiVbCnFNRKwFkHRhOvb2dpW1Vf2DQzz4ZD8PP9XPU+sH6dtQ5ZmBIapDNYZqwVAtqAXUIqjVggAiIHJruuRnNtmiSU620pQo99w7wE0Dq7fKtca7ssRaljihPLFuaZyzZkzlxIOL1nf643TyQbndGb5c4rq0rWj7gc0uImkhWQuE7u5uKpXKqArT19fX9NyHnqnxjRv6eXR9Z+et2tKlz4oF3LVmq1xp/CtLrGWJE8oT65bFuf0MsXc0XX121DqZIIrqu9jM9kIRsRhYDNDT0xOjffqw2ZOLtVpw9Pd/Q38M8rm3vZhdd9iGF+4wkx22mcZ2M6Yya0YX06ZMoatLdEl0TRESTJEQoI0/N11T2jpV/WiU5UlUKE+sZYkTyhPreImzkwliHcPX7p1DtkLV9CbbO+L8Zfex7O4/8I9/vh9/8eo9Rj7BzGyS6ORtrpcBx6a7mV4DPJnW+70emCdpL0nTyZY2vGxzF2qXB59cz+k/X8XrX7oz7+3xomVmVi5ta0FIugDoBXaRtI5skfhpABGxCFgCvB1YAzwLHJf2VSWdTLaubxdwdkTc1q5yNhMRfPEnK6nWavzvd+/X0W4hM7NOaOddTMeMsD+Ak5rsW0KWQDrm0ac38J93PMKn3zKPF+08q5NFMTPrCD9J3UTfhioAe+0y+eeeNzMr4gTRRP9gDYAZU7s6XBIzs85wgmiivzoEwMxp/hWZWTm59muif7CeINyCMLNycoJoop4gtnGCMLOScoJooj4G4RaEmZWVE0QTm7qY/Csys3Jy7dfEeo9BmFnJOUE0sbGLybe5mllJOUE0sbGLabp/RWZWTq79mtgwOIQE07v8KzKzcnLt18T6wSFmTu3yJH1mVlpOEE30D9Z8B5OZlZprwCb6B4f8kJyZlZoTRBP91ZpvcTWzUnOCaGL9wBAznCDMrMScIJrYUB3yGISZlZprwCY8BmFmZecE0UR2F5MThJmVlxNEE+sH3cVkZuXmGrCJ/vSgnJlZWTlBNNE/WGPmdCcIMysvJ4gmNrgFYWYl5wTRhMcgzKzs2loDSjpU0mpJaySdUrB/R0mXSlohaZmkfXP7PiVppaTbJH26neVsVB2qUa2F72Iys1JrW4KQ1AV8BzgMmA8cI2l+w2GnAssjYj/gWODMdO6+wEeABcD+wDslzWtXWRv1V7PFgvwchJmVWTtbEAuANRGxNiIGgAuBIxqOmQ9cDRARq4C5krqBfYDfRMSzEVEFfgW8u41lHcbrUZuZwdQ2Xnt34P7c53XAgQ3H3AIcBVwraQGwJzAHWAn8g6SdgfXA24Ebir5E0kJgIUB3dzeVSmVUhe3r69t47qPPZi2Ie+66k8qGe0Z1vfEqH+dkV5ZYyxInlCfW8RJnOxNE0Uo70fD5dOBMScuBW4GbgWpE3CHpa8AvgD6yRFIt+pKIWAwsBujp6Yne3t5RFbZSqVA/d80jT8PSpez/ylfQu/9uo7reeJWPc7IrS6xliRPKE+t4ibOdCWIdsEfu8xzggfwBEfEUcByAsqXb7k4vIuIs4Ky073+l642J/kGPQZiZtbOT/XpgnqS9JE0HjgYuyx8gaXbaB3ACsDQlDSS9IP18EVk31AVtLOswHoMwM2tjCyIiqpJOBq4EuoCzI+I2SSem/YvIBqPPlTQE3A4cn7vEv6cxiEHgpIh4vF1lbbR+Y4JwC8LMyqudXUxExBJgScO2Rbn31wGFt69GxBvaWbbNqXcx+UlqMysz96EUqHcxbTPdvx4zKy/XgAXqCWKGWxBmVmJOEAX6PQZhZuYEUWTjGITvYjKzEnMNWMAtCDMzJ4hC/dUhpk4R07r86zGz8nINWGD9QM2tBzMrPSeIAv1VLxZkZuZasED/4JBbEGZWek4QBTYMuovJzMwJooDXozYzc4Io1D845HmYzKz0nCAK9A8Osc10JwgzKzcniALrB2ueh8nMSs8JosAGj0GYmTlBFPFtrmZmThCF+qs1tyDMrPRcCxZYPzDENm5BmFnJOUE0iIg01YYThJmVmxNEg4GhGhGe6tvMzAmiQX2xoBlT/asxs3JzLdigvliQH5Qzs7JzgmiwcTU5PyhnZiXnBNFg03rUThBmVm5tTRCSDpW0WtIaSacU7N9R0qWSVkhaJmnf3L7PSLpN0kpJF0ia2c6y1m1aj9q508zKrW21oKQu4DvAYcB84BhJ8xsOOxVYHhH7AccCZ6Zzdwc+CfRExL5AF3B0u8qat74+BuEWhJmVXDv/TF4ArImItRExAFwIHNFwzHzgaoCIWAXMldSd9k0FtpE0FZgFPNDGsm5Ub0HMcIIws5JrZ4LYHbg/93ld2pZ3C3AUgKQFwJ7AnIj4PfBPwH3Ag8CTEXFVG8u60aYxCHcxmVm5TW3jtVWwLRo+nw6cKWk5cCtwM1CVtCNZa2Mv4Ang3yR9ICJ+/JwvkRYCCwG6u7upVCqjKmxfXx+VSoWbH6gCsOKmG3n0d5MvSdTjLIOyxFqWOKE8sY6XONuZINYBe+Q+z6GhmygingKOA5Ak4O70+jPg7oh4NO27BHgd8JwEERGLgcUAPT090dvbO6rCVioVent7eWjZfbDiVg4+6LXsNnubUV1rPKvHWQZlibUscUJ5Yh0vcbbzT+TrgXmS9pI0nWyQ+bL8AZJmp30AJwBLU9K4D3iNpFkpcRwC3NHGsm606S4mj0GYWbmN2IKQNIescn8DsBuwHlgJ/Afw84ioFZ0XEVVJJwNXkt2FdHZE3CbpxLR/EbAPcK6kIeB24Pi077eSLgZuAqpkXU+L/5hAW9Vf9RiEmRmMkCAk/ZBsYPly4GvAI8BM4GXAocAXJJ0SEUuLzo+IJcCShm2Lcu+vA+Y1Ofc04LSWI9lK/CS1mVlmpBbENyJiZcH2lcAlqXvoRVu/WJ2zfnCI6VOnMGVK0Ri7mVl5bLYfpSg5SHqJpFem/QMRsaZdheuEDYM1ZnomVzOzLbuLSdKpwCuBmqRaRHywPcXqHK9HbWaW2eyfypI+kabMqNs/Io6JiPcD+7e3aJ3hBGFmlhmpL+Vx4ApJh6fPV0n6laT/Irs7adJZP+j1qM3MYOQxiB8DhwOvkvRT4AayyffeGRH/YwzKN+b6B2u+xdXMjNYelHsJ8K/AR4GTgTOAyfeIcdI/OOSJ+szMGPk5iHPSMdsAd0XERyQdAHxf0rKI+PsxKOOY6q/W2GGbaZ0uhplZx410F9MBEbE/gKSbASLiZuBwSY1Td08K/QNDvHD7GZ0uhplZx42UIK6Q9CtgOnB+fkdE/LRtpeqg/qrvYjIzgxESRET8raTtgVpE9I1RmTqqf3DI02yYmTHycxAfAPqaJYf0VPVBbSlZh/guJjOzzEhdTDsDN0u6EbgReJRssr6XAgcDjwGntLWEY2z94BAzp7sFYWY2UhfTmZK+DbwZeD2wH9l033cAH4yI+9pfxLFTqwUD1Zq7mMzMaGEupogYAn6RXpPahrQWxAx3MZmZtXVFuQlnoJ4g3IIwM3OCyBsYyhLE9C6vBWFm5gSRszFBeD0IM7PWEoSkbklnSfp5+jxf0vHtLdrYq3cxOUGYmbXegjiHbHrv3dLn3wGfbkN5OmowtSCmdTlBmJm1WhPuEhEXATWAiKgCQ20rVYdsbEE4QZiZtZwgnpG0MxAAkl4DPNm2UnXIBncxmZlt1Oqa1H8NXAa8RNJ/A88H3tO2UnWIxyDMzDZpKUFExE2SDgZeDghYHRGDbS1ZBwwOuYvJzKyu1buYTgK2i4jbImIlsJ2kj7e3aGPPLQgzs01arQk/EhFP1D9ExOPAR0Y6SdKhklZLWiPpOZP6SdpR0qWSVkhaJmnftP3lkpbnXk9J+nSLZR01PwdhZrZJq2MQUyQpIuqD1F1kiwg1lY75DvBWYB1wvaTLIuL23GGnAssj4t2S9k7HHxIRq4FX5a7ze+DS1sMaHd/mama2Sas14ZXARZIOkfRm4ALgihHOWQCsiYi1ETEAXAg0LlM6H7gaICJWAXMldTcccwjZetj3tljWUdvg21zNzDZqtQXxt8BHgY+RDVJfBfxghHN2B+7PfV4HHNhwzC3AUcC1khYAewJzgIdzxxxNlpAKSVoILATo7u6mUqmMUKxifX19rLxvFQA3LvsNd82cnEmir69v1L+jiaYssZYlTihPrOMlzlbvYqoB30uvVhXNeBcNn08HzpS0HLgVuBmobryANB14F/D5zZRtMbAYoKenJ3p7e7egiJtUKhXmzt4Tbr+d3jcexOxZm+1Bm7AqlQqj/R1NNGWJtSxxQnliHS9xtpQgJL0e+DLZX/hTySr/iIgXb+a0dcAeuc9zgAfyB0TEU8Bx6TsE3J1edYcBN0VEvkXRNh6DMDPbpNUuprOAz5AtO9rqFBvXA/Mk7UU2yHw08L78AZJmA8+mMYoTgKUpadQdw2a6l7Y23+ZqZrZJqwniyYj4+ZZcOCKqkk4mG+DuAs6OiNsknZj2LwL2Ac6VNATcDmycIVbSLLI7oD66Jd/7xxgYqiHB1CleD8LMrNUEcY2krwOXABvqGyPips2dFBFLgCUN2xbl3l8HzGty7rPAzi2Wb6sYGKoxrWsKWW+XmVm5tZog6ncf9eS2BfDmrVuczhqo1pjh8QczM6D1u5je1O6CjAcD1ZrHH8zMklZbEEh6B/AKYGZ9W0T8XTsK1SlOEGZmm7Q6Wd8i4C+BT5Dd4vpeslteJ5XBNAZhZmatT7Xxuog4Fng8Ir4CvJbhzzhMCgNDbkGYmdW1WhuuTz+flbQbMAjs1Z4idc5AteZ5mMzMklbHIC5PD7V9HbiJ7A6mkeZimnAGhoJpbkGYmQGt38X09+ntv0u6HJgZEZNuTeqB6pBvczUzSzabICS9OSJ+Kemogn1ExCXtK9rYG6jWmDW95Ru7zMwmtZFqw4OBXwKHF+wLsierJ42BoRqz3cVkZgaMkCAi4jRJU4CfR8RFY1SmjhmsBtO6PM2GmRm0cBdTWgvi5DEoS8dlt7l2dboYZmbjQqv9Kb+Q9DlJe0jaqf5qa8k6wLe5mplt0uqI7F+lnyfltgWwuQWDJpysBeEuJjMzaP0210n3UFwRtyDMzDbZksn69gXmM3yyvnPbUahO8WR9ZmabtLom9WlAL1mCWEK2VvS1wORKEJ6Lycxso1Zrw/cAhwAPRcRxwP7AjLaVqgNqEQzVwrO5mpklLU/Wl253rUraHniESTZAXa1lP92CMDPLtDoGcUOarO/7wI1AH7CsXYXqhMF6gnALwswMGHkupm8D50fEx9OmRZKuALaPiBVtL90YGnILwsxsmJFaEHcC35C0K/CvwAURsbztpeqAwVoAbkGYmdVttjaMiDMj4rVkk/b9AfihpDskfUnSy8akhGPEYxBmZsO1VBtGxL0R8bWIOAB4H/Bu4I62lmyMOUGYmQ3XUm0oaZqkwyWdB/wc+B3w5y2cd6ik1ZLWSDqlYP+Oki6VtELSsvQwXn3fbEkXS1qVWi2v3YK4tlg1si4m3+ZqZpYZaZD6rcAxwDvI7lq6EFgYEc+MdGFJXcB3gLcC64DrJV0WEbfnDjsVWB4R75a0dzr+kLTvTOCKiHiPpOnArC0LbcsMugVhZjbMSLXhqcB1wD4RcXhEnNdKckgWAGsiYm1EDJAllyMajpkPXA0QEauAuZK607MWbwTOSvsGIuKJFr93VOpdTF5y1MwsM9KCQW/6I669O3B/7vM64MCGY24BjgKulbQA2BOYAwwBj5INiu9P9uzFp4qSk6SFwEKA7u5uKpXKqAr79DPrAbHy1lsYWDd514To6+sb9e9ooilLrGWJE8oT63iJs50LMBfNmx0Nn08HzpS0HLgVuBmoAtOAPwE+ERG/lXQmcArwxedcMGIxsBigp6cnent7R1XY5Rf9J7CBA3v+lP33mD2qa0wElUqF0f6OJpqyxFqWOKE8sY6XONuZINYBe+Q+zwEeyB8QEU8BxwFIEnB3es0C1kXEb9OhF5MliLbxGISZ2XDtrA2vB+ZJ2isNMh8NXJY/IN2pND19PAFYGhFPRcRDwP2SXp72HQLkB7e3Ot/mamY2XNtaEBFRlXQycCXQBZwdEbdJOjHtXwTsA5wraYgsARyfu8QngPNSAllLamm0S9VPUpuZDdPOLiYiYgnZ+hH5bYty768D5jU5dznQ087y5bkFYWY2nGvDpOrZXM3MhnFtmFTT/VXT3IIwMwOcIDbybK5mZsO5NkzqXUzTuooe3zAzKx8niKRaywaos8cxzMzMCSKp1sLdS2ZmOa4Rk3oLwszMMq4Rk8GaB6jNzPJcIybVCKZN9fiDmVmdE0RSdQvCzGwY14hJNgYxedeBMDPbUk4QyaAHqc3MhnGNmAzVgul+SM7MbCMniMQtCDOz4VwjJh6kNjMbzjViUq0F05wgzMw2co2Y+ElqM7PhXCMmHoMwMxvONWJSDZjhBGFmtpFrxMRjEGZmw7lGTHwXk5nZcK4REw9Sm5kN5xoRqNWCocBdTGZmOa4RgYGhbEFqtyDMzDZpa40o6VBJqyWtkXRKwf4dJV0qaYWkZZL2ze27R9KtkpZLuqGd5awnCN/FZGa2ydR2XVhSF/Ad4K3AOuB6SZdFxO25w04FlkfEuyXtnY4/JLf/TRHxWLvKWDdQdQvCzKxRO2vEBcCaiFgbEQPAhcARDcfMB64GiIhVwFxJ3W0sU6HB1ILwGISZ2SZta0EAuwP35z6vAw5sOOYW4CjgWkkLgD2BOcDDQABXSQrgnyNicdGXSFoILATo7u6mUqlscUEfeTZLEGvvXE3l2bVbfP5E0tfXN6rf0URUlljLEieUJ9bxEmc7E0TR4grR8Pl04ExJy4FbgZuBatr3+oh4QNILgF9IWhURS59zwSxxLAbo6emJ3t7eLS7onQ8/DUuXst++r6B3/922+PyJpFKpMJrf0URUlljLEieUJ9bxEmc7E8Q6YI/c5znAA/kDIuIp4DgASQLuTi8i4oH08xFJl5J1WT0nQWwNA+5iMjN7jnbWiNcD8yTtJWk6cDRwWf4ASbPTPoATgKUR8ZSkbSU9Lx2zLfA2YGW7ClofpPZdTGZmm7StBRERVUknA1cCXcDZEXGbpBPT/kXAPsC5koaA24Hj0+ndwKVZo4KpwPkRcUW7yuq7mMzMnqudXUxExBJgScO2Rbn31wHzCs5bC+zfzrLl+UE5M7Pnco2Ib3M1MyviGpFcF5MThJnZRq4RgQ0egzAzew7XiMDgUPZ4hlsQZmabuEbEdzGZmRVxjQgMVIcAJwgzszzXiPg2VzOzIq4R2TQGMa2raPooM7NycoIgdxeTB6nNzDZyjUg2SD1VkKb2MDMznCCA7ElqDz+YmQ3napHUgvBvwsxsGFeL1BOEu5fMzPKcIMhuc53m34SZ2TCuFskShG9gMjMbztUiWRfTNHcxmZkN4wSBB6nNzIq4WiTd5uoGhJnZME4QuAVhZlbE1SL1u5jchDAzy3OCwC0IM7MirhbJWhBOEGZmw7laxE9Sm5kVcYLAXUxmZkXaWi1KOlTSaklrJJ1SsH9HSZdKWiFpmaR9G/Z3SbpZ0uXtLKdnczUze662VYuSuoDvAIcB84FjJM1vOOxUYHlE7AccC5zZsP9TwB3tKmPdQLXGNPcwmZkN086/mxcAayJibUQMABcCRzQcMx+4GiAiVgFzJXUDSJoDvAP4QRvLCMBb53fzou3dhDAzy5vaxmvvDtyf+7wOOLDhmFuAo4BrJS0A9gTmAA8DZwB/Azxvc18iaSGwEKC7u5tKpbLFBT3yhdDXt2FU5040fX19pYgTyhNrWeKE8sQ6XuJsZ4Io6rSJhs+nA2dKWg7cCtwMVCW9E3gkIm6U1Lu5L4mIxcBigJ6enujt3ezhTVUqFUZ77kRSljihPLGWJU4oT6zjJc52Joh1wB65z3OAB/IHRMRTwHEAyhaEvju9jgbeJentwExge0k/jogPtLG8ZmaW086O9+uBeZL2kjSdrNK/LH+ApNlpH8AJwNKIeCoiPh8RcyJibjrvl04OZmZjq20tiIioSjoZuBLoAs6OiNsknZj2LwL2Ac6VNATcDhzfrvKYmdmWaWcXExGxBFjSsG1R7v11wLwRrlEBKm0onpmZbYbv7TQzs0JOEGZmVsgJwszMCimi8dGEiUvSo8C9ozx9F+CxrVic8aoscUJ5Yi1LnFCeWMcyzj0j4vlFOyZVgvhjSLohIno6XY52K0ucUJ5YyxInlCfW8RKnu5jMzKyQE4SZmRVygthkcacLMEbKEieUJ9ayxAnliXVcxOkxCDMzK+QWhJmZFXKCMDOzQqVPECOtmz2RSdpD0jWS7pB0m6RPpe07SfqFpDvTzx07XdatoXEN80kc52xJF0talf7bvnYyxirpM+nf7UpJF0iaOVnilHS2pEckrcxtaxqbpM+nOmq1pD8bq3KWOkG0uG72RFYFPhsR+wCvAU5K8Z0CXB0R88iWfJ0sibFxDfPJGueZwBURsTewP1nMkypWSbsDnwR6ImJfshmhj2byxHkOcGjDtsLY0v+zRwOvSOd8N9VdbVfqBEFr62ZPWBHxYETclN4/TVaR7E4W44/SYT8CjuxIAbeiJmuYT8Y4twfeCJwFEBEDEfEEkzBWstmmt5E0FZhFtuDYpIgzIpYCf2jY3Cy2I4ALI2JDRNwNrCGru9qu7AmiaN3s3TtUlraSNBc4APgt0B0RD0KWRIAXdLBoW8sZZGuY13LbJmOcLwYeBX6YutN+IGlbJlmsEfF74J+A+4AHgScj4iomWZwNmsXWsXqq7AmilXWzJzxJ2wH/Dnw6LfM6qeTXMO90WcbAVOBPgO9FxAHAM0zcbpamUv/7EcBewG7AtpLKuqpkx+qpsieIEdfNnugkTSNLDudFxCVp88OSdk37dwUe6VT5tpLXk61hfg9ZN+GbJf2YyRcnZP9m10XEb9Pni8kSxmSL9S3A3RHxaEQMApcAr2PyxZnXLLaO1VNlTxAjrps9kUkSWV/1HRHxzdyuy4APpfcfAn461mXbmjazhvmkihMgIh4C7pf08rTpELLleidbrPcBr5E0K/07PoRsDG2yxZnXLLbLgKMlzZC0F9kqnMvGpEQRUeoX8Hbgd8BdwBc6XZ6tHNtBZE3RFcDy9Ho7sDPZXRJ3pp87dbqsWzHmXuDy9H5Sxgm8Crgh/Xf9CbDjZIwV+AqwClgJ/AswY7LECVxANrYySNZCOH5zsQFfSHXUauCwsSqnp9owM7NCZe9iMjOzJpwgzMyskBOEmZkVcoIwM7NCThBmZlbICcI6SlJI+kbu8+ckfXkrXfscSe/ZGtca4Xvem2ZVvaZg38skLUkzcd4h6SJJ3e0uUztJOnKSTWppTThBWKdtAI6StEunC5K3hbNlHg98PCLe1HCNmcB/kE2L8dLIZtX9HvD8rVfSjjiSbPZjm+ScIKzTqmTr736mcUdjC0BSX/rZK+lX6a/x30k6XdL7JS2TdKukl+Qu8xZJ/5WOe2c6v0vS1yVdL2mFpI/mrnuNpPOBWwvKc0y6/kpJX0vbvkT2QOIiSV9vOOV9wHUR8bP6hoi4JiJWprUNfpiud7OkN6XrfVjSTyT9TNLdkk6W9NfpmN9I2ikdV5F0hqRfp/IsSNt3SuevSMfvl7Z/Oa1BUJG0VtInc3F9IP3ulkv653pylNQn6R8k3ZKu1S3pdcC7gK+n418i6ZOSbk/feWEr/9Ftguj0E4V+lfsF9AHbA/cAOwCfA76c9p0DvCd/bPrZCzwB7Er2dO3vga+kfZ8CzsidfwXZH0LzyJ5YnQksBP5nOmYG2VPJe6XrPgPsVVDO3cimf3g+2YR5vwSOTPsqZOsWNJ7zTeBTTeL+LPDD9H7vdO2ZwIfJpnN+XvquJ4ET03HfIptwsf6d30/v3wisTO//L3Baev9mYHl6/2Xg1yneXYD/B0wD9gF+BkxLx30XODa9D+Dw9P4fc7+zxv8uDwAz0vvZnf435dfWe7kFYR0X2Qyz55ItENOq6yNb72ID2RQEV6XttwJzc8ddFBG1iLgTWEtWGb8NOFbScrLpz3cmSyAAyyKbc7/Rq4FKZJPHVYHzyCrm0TqIbPoIImIVcC/wsrTvmoh4OiIeJUsQ9RZIY2wXpPOXAttLmt1w3V8CO0vaIR3/H5GtKfAY2URw3WRzHP0pcH36fRxCNqU4wABweXp/Y8N3560AzkuzrVa35Jdg49vUThfALDkDuAn4YW5bldQNmiZsm57btyH3vpb7XGP4v+vGuWSCbPrkT0TElfkdknrJWhBFiqZcHsltwMGjuN4fG1uj+nH56w6lawn4UUR8vuC8wYiIhuOLvIMsWb4L+KKkV6QkahOcWxA2LkTEH4CLyAZ86+4h++sWsrUBpo3i0u+VNCWNS7yYbLKzK4GPKZsKvX6n0bYjXOe3wMGSdkl99McAvxrhnPOB10l6R32DsjXQXwksBd5f/37gRalsW+Iv0/kHkS2o82TDdXuBx2Lza4BcDbxH0gvSOTtJ2nOE732arAsMSVOAPSLiGrIFm2YD221hHDZOuQVh48k3gJNzn78P/FTSMrKKrNlf95uzmqwi7ybry++X9AOy7pKbUsvkUUZYujIiHpT0eeAasr+6l0TEZqeajoj1aWD8DElnkM3cuYJsnOS7ZAPbt5K1lD4cERuy4rTscUm/JhvD+au07ctkq82tAJ5l0/TRzcp4u6T/CVyVKvtB4CSyLq9mLgS+nwa6jwbOSt1YAr4V2RKoNgl4NlezCUhSBfhcRNzQ6bLY5OUuJjMzK+QWhJmZFXILwszMCjlBmJlZIScIMzMr5ARhZmaFnCDMzKzQ/wcmnsAqFQ2i9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming X is your standardized dataset\n",
    "pca = PCA().fit(X_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') # for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bb6e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.where(cumulative_variance > 0.95)[0][0] + 1\n",
    "print(n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3e5d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "Best number of components: 9\n",
      "RMSE: 0.008592941885868201\n"
     ]
    }
   ],
   "source": [
    "best_rmse = np.inf  # Start with infinity so that any score will be better\n",
    "best_n = 0\n",
    "\n",
    "for nn in range(1, X_train.shape[1]+1):  # Start from 1 as PCA with 0 components doesn't make sense\n",
    "    # Create a PCA object, specifying how many components you wish to keep\n",
    "    pca = PCA(n_components=nn)\n",
    "    print(nn)\n",
    "    # Fit the PCA model to your data and then apply the dimensionality reduction on train and test data\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_pca_train = pca.transform(X_train_scaled)\n",
    "    X_pca_test = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Create a RandomForestRegressor with the best parameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators= 400, \n",
    "        min_samples_split=5, \n",
    "        min_samples_leaf=1, \n",
    "        max_features=\"log2\", \n",
    "        max_depth=30, \n",
    "        bootstrap=False,\n",
    "        random_state=42,  # Seed\n",
    "        n_jobs=-1  # Use all processors\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_pca_train, Y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_pca_test)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "\n",
    "    # If this RMSE is the best we've seen, store this n_components and score\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_n = nn\n",
    "\n",
    "print(f\"Best number of components: {best_n}\")\n",
    "print(f\"RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b835922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 1.2039 - mse: 1.2039 - val_loss: 973.8994 - val_mse: 973.8994\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0548 - mse: 1.0548 - val_loss: 74092.3984 - val_mse: 74092.3984\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0485 - mse: 1.0485 - val_loss: 60200.6133 - val_mse: 60200.6133\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0389 - mse: 1.0389 - val_loss: 33763.2891 - val_mse: 33763.2891\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0311 - mse: 1.0311 - val_loss: 213556.6250 - val_mse: 213556.6250\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0208 - mse: 1.0208 - val_loss: 6671.0557 - val_mse: 6671.0557\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0165 - mse: 1.0165 - val_loss: 23967.6582 - val_mse: 23967.6582\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0049 - mse: 1.0049 - val_loss: 3555.7622 - val_mse: 3555.7622\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0081 - mse: 1.0081 - val_loss: 15368.9990 - val_mse: 15368.9990\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0060 - mse: 1.0060 - val_loss: 26776.1055 - val_mse: 26776.1055\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0106 - mse: 1.0106 - val_loss: 122547.9297 - val_mse: 122547.9297\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "2\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 5ms/step - loss: 0.8878 - mse: 0.8878 - val_loss: 1157.1656 - val_mse: 1157.1656\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.7290 - mse: 0.7290 - val_loss: 5021.1621 - val_mse: 5021.1621\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6506 - mse: 0.6506 - val_loss: 5671.0122 - val_mse: 5671.0122\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6357 - mse: 0.6357 - val_loss: 2579.4768 - val_mse: 2579.4768\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6329 - mse: 0.6329 - val_loss: 870.4768 - val_mse: 870.4768\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6139 - mse: 0.6139 - val_loss: 6316.7690 - val_mse: 6316.7690\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6045 - mse: 0.6045 - val_loss: 548.3426 - val_mse: 548.3426\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5937 - mse: 0.5937 - val_loss: 1797.1422 - val_mse: 1797.1422\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6045 - mse: 0.6045 - val_loss: 140.4327 - val_mse: 140.4327\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5947 - mse: 0.5947 - val_loss: 1005.5642 - val_mse: 1005.5642\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5808 - mse: 0.5808 - val_loss: 10179.0117 - val_mse: 10179.0117\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5837 - mse: 0.5837 - val_loss: 10.4563 - val_mse: 10.4563\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5996 - mse: 0.5996 - val_loss: 2.7651 - val_mse: 2.7651\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5913 - mse: 0.5913 - val_loss: 6323.9951 - val_mse: 6323.9951\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5881 - mse: 0.5881 - val_loss: 22928.0781 - val_mse: 22928.0781\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5606 - mse: 0.5606 - val_loss: 1359.2860 - val_mse: 1359.2860\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5878 - mse: 0.5878 - val_loss: 1026.6707 - val_mse: 1026.6707\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5846 - mse: 0.5846 - val_loss: 2130.0312 - val_mse: 2130.0312\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5548 - mse: 0.5548 - val_loss: 898.2740 - val_mse: 898.2740\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5712 - mse: 0.5712 - val_loss: 1192.3834 - val_mse: 1192.3834\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5733 - mse: 0.5733 - val_loss: 168.5705 - val_mse: 168.5705\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5478 - mse: 0.5478 - val_loss: 7361.6357 - val_mse: 7361.6357\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5713 - mse: 0.5713 - val_loss: 11917.7432 - val_mse: 11917.7432\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "3\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.8683 - mse: 0.8683 - val_loss: 3002.5383 - val_mse: 3002.5383\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.7124 - mse: 0.7124 - val_loss: 33.8167 - val_mse: 33.8167\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6524 - mse: 0.6524 - val_loss: 950.8825 - val_mse: 950.8825\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6487 - mse: 0.6487 - val_loss: 4.9086 - val_mse: 4.9086\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6558 - mse: 0.6558 - val_loss: 7351.5396 - val_mse: 7351.5396\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6338 - mse: 0.6338 - val_loss: 10405.9502 - val_mse: 10405.9502\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6310 - mse: 0.6310 - val_loss: 232.7416 - val_mse: 232.7416\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6035 - mse: 0.6035 - val_loss: 380.4215 - val_mse: 380.4215\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6146 - mse: 0.6146 - val_loss: 378.7377 - val_mse: 378.7377\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6001 - mse: 0.6001 - val_loss: 4022.8796 - val_mse: 4022.8796\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5755 - mse: 0.5755 - val_loss: 24997.2363 - val_mse: 24997.2363\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6034 - mse: 0.6034 - val_loss: 905.6945 - val_mse: 905.6945\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5889 - mse: 0.5889 - val_loss: 920.1593 - val_mse: 920.1593\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5805 - mse: 0.5805 - val_loss: 196557.9219 - val_mse: 196557.9219\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "4\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.7886 - mse: 0.7886 - val_loss: 11.7482 - val_mse: 11.7482\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6757 - mse: 0.6757 - val_loss: 1784.2843 - val_mse: 1784.2843\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6182 - mse: 0.6182 - val_loss: 1726.9247 - val_mse: 1726.9247\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6045 - mse: 0.6045 - val_loss: 559.7286 - val_mse: 559.7286\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5892 - mse: 0.5892 - val_loss: 92.5466 - val_mse: 92.5466\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5693 - mse: 0.5693 - val_loss: 10302.5723 - val_mse: 10302.5723\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5735 - mse: 0.5735 - val_loss: 12151.5234 - val_mse: 12151.5234\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5334 - mse: 0.5334 - val_loss: 481.2016 - val_mse: 481.2016\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5403 - mse: 0.5403 - val_loss: 2476.5505 - val_mse: 2476.5505\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5327 - mse: 0.5327 - val_loss: 28.1095 - val_mse: 28.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5041 - mse: 0.5041 - val_loss: 5562.3564 - val_mse: 5562.3564\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "5\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.8996 - mse: 0.8996 - val_loss: 1185.8719 - val_mse: 1185.8719\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.6904 - mse: 0.6904 - val_loss: 731.8514 - val_mse: 731.8514\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.6063 - mse: 0.6063 - val_loss: 1318.2643 - val_mse: 1318.2643\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5956 - mse: 0.5956 - val_loss: 2.3848 - val_mse: 2.3848\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5811 - mse: 0.5811 - val_loss: 4325.3657 - val_mse: 4325.3657\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5557 - mse: 0.5557 - val_loss: 10809.5752 - val_mse: 10809.5752\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5557 - mse: 0.5557 - val_loss: 21710.4199 - val_mse: 21710.4199\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5405 - mse: 0.5405 - val_loss: 1810.4785 - val_mse: 1810.4785\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5254 - mse: 0.5254 - val_loss: 2345.0754 - val_mse: 2345.0754\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5150 - mse: 0.5150 - val_loss: 45058.1758 - val_mse: 45058.1758\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4894 - mse: 0.4894 - val_loss: 12807.9258 - val_mse: 12807.9258\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5092 - mse: 0.5092 - val_loss: 430.9251 - val_mse: 430.9251\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5168 - mse: 0.5168 - val_loss: 343.0792 - val_mse: 343.0792\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5028 - mse: 0.5028 - val_loss: 6299.5356 - val_mse: 6299.5356\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "6\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.7503 - mse: 0.7503 - val_loss: 1873.8584 - val_mse: 1873.8584\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.6339 - mse: 0.6339 - val_loss: 163.9396 - val_mse: 163.9396\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5574 - mse: 0.5574 - val_loss: 5.1391 - val_mse: 5.1391\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5457 - mse: 0.5457 - val_loss: 106.5536 - val_mse: 106.5536\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5413 - mse: 0.5413 - val_loss: 8.0345 - val_mse: 8.0345\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5038 - mse: 0.5038 - val_loss: 1141.9875 - val_mse: 1141.9875\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4962 - mse: 0.4962 - val_loss: 1368.6464 - val_mse: 1368.6464\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4880 - mse: 0.4880 - val_loss: 131.3000 - val_mse: 131.3000\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4855 - mse: 0.4855 - val_loss: 416.5839 - val_mse: 416.5839\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4748 - mse: 0.4748 - val_loss: 22.8658 - val_mse: 22.8658\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4501 - mse: 0.4501 - val_loss: 2274.7705 - val_mse: 2274.7705\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4711 - mse: 0.4711 - val_loss: 1106.0074 - val_mse: 1106.0074\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4754 - mse: 0.4754 - val_loss: 1895.2605 - val_mse: 1895.2605\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "7\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.6785 - mse: 0.6785 - val_loss: 14.4517 - val_mse: 14.4517\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5824 - mse: 0.5824 - val_loss: 1947.0557 - val_mse: 1947.0557\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5431 - mse: 0.5431 - val_loss: 1365.8738 - val_mse: 1365.8738\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.5299 - mse: 0.5299 - val_loss: 230.6206 - val_mse: 230.6206\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5267 - mse: 0.5267 - val_loss: 213.2957 - val_mse: 213.2957\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5194 - mse: 0.5194 - val_loss: 367.0287 - val_mse: 367.0287\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4954 - mse: 0.4954 - val_loss: 3684.2102 - val_mse: 3684.2102\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4887 - mse: 0.4887 - val_loss: 1766.0111 - val_mse: 1766.0111\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4861 - mse: 0.4861 - val_loss: 626.6755 - val_mse: 626.6755\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4763 - mse: 0.4763 - val_loss: 435.9684 - val_mse: 435.9684\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4517 - mse: 0.4517 - val_loss: 23890.6680 - val_mse: 23890.6680\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "8\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6927 - mse: 0.6927 - val_loss: 1343.4248 - val_mse: 1343.4248\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5862 - mse: 0.5862 - val_loss: 53.2072 - val_mse: 53.2072\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5373 - mse: 0.5373 - val_loss: 897.5383 - val_mse: 897.5383\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5386 - mse: 0.5386 - val_loss: 354.4057 - val_mse: 354.4057\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5260 - mse: 0.5260 - val_loss: 86.9704 - val_mse: 86.9704\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5091 - mse: 0.5091 - val_loss: 558.5798 - val_mse: 558.5798\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4989 - mse: 0.4989 - val_loss: 732.1943 - val_mse: 732.1943\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4926 - mse: 0.4926 - val_loss: 4.0265 - val_mse: 4.0265\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4955 - mse: 0.4955 - val_loss: 1.8366 - val_mse: 1.8366\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4873 - mse: 0.4873 - val_loss: 1032.0271 - val_mse: 1032.0271\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4607 - mse: 0.4607 - val_loss: 1825.6766 - val_mse: 1825.6766\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4818 - val_loss: 41.0315 - val_mse: 41.0315\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4737 - mse: 0.4737 - val_loss: 725.9594 - val_mse: 725.9594\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4728 - mse: 0.4728 - val_loss: 1206.9502 - val_mse: 1206.9502\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4607 - mse: 0.4607 - val_loss: 896.8625 - val_mse: 896.8625\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4297 - mse: 0.4297 - val_loss: 518.2617 - val_mse: 518.2617\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4215 - mse: 0.4215 - val_loss: 3983.0654 - val_mse: 3983.0654\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4465 - mse: 0.4465 - val_loss: 1245.1732 - val_mse: 1245.1732\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4160 - mse: 0.4160 - val_loss: 1525.8885 - val_mse: 1525.8885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 0s 2ms/step\n",
      "9\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7139 - mse: 0.7139 - val_loss: 523.3874 - val_mse: 523.3874\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5658 - mse: 0.5658 - val_loss: 49.9330 - val_mse: 49.9330\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5367 - mse: 0.5367 - val_loss: 49.6529 - val_mse: 49.6529\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5238 - mse: 0.5238 - val_loss: 294.1343 - val_mse: 294.1343\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5290 - mse: 0.5290 - val_loss: 29.5503 - val_mse: 29.5503\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5054 - mse: 0.5054 - val_loss: 744.6885 - val_mse: 744.6885\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5040 - mse: 0.5040 - val_loss: 2259.6804 - val_mse: 2259.6804\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4980 - mse: 0.4980 - val_loss: 6534.6460 - val_mse: 6534.6460\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5013 - mse: 0.5013 - val_loss: 207.1767 - val_mse: 207.1767\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4907 - mse: 0.4907 - val_loss: 833.3408 - val_mse: 833.3408\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4642 - mse: 0.4642 - val_loss: 1700.3364 - val_mse: 1700.3364\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4830 - mse: 0.4830 - val_loss: 36.9702 - val_mse: 36.9702\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4983 - mse: 0.4983 - val_loss: 2.5040 - val_mse: 2.5040\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4727 - mse: 0.4727 - val_loss: 4918.1221 - val_mse: 4918.1221\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4621 - mse: 0.4621 - val_loss: 81.7550 - val_mse: 81.7550\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4320 - mse: 0.4320 - val_loss: 18.6375 - val_mse: 18.6375\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4609 - mse: 0.4609 - val_loss: 977.5470 - val_mse: 977.5470\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4479 - mse: 0.4479 - val_loss: 7265.8184 - val_mse: 7265.8184\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4453 - mse: 0.4453 - val_loss: 15.4438 - val_mse: 15.4438\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4333 - mse: 0.4333 - val_loss: 232.1929 - val_mse: 232.1929\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4219 - mse: 0.4219 - val_loss: 2.8911 - val_mse: 2.8911\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4034 - mse: 0.4034 - val_loss: 2172.7798 - val_mse: 2172.7798\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4274 - mse: 0.4274 - val_loss: 340.0444 - val_mse: 340.0444\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "10\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.7598 - mse: 0.7598 - val_loss: 9.2902 - val_mse: 9.2902\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5887 - mse: 0.5887 - val_loss: 767.2177 - val_mse: 767.2177\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5450 - mse: 0.5450 - val_loss: 0.8146 - val_mse: 0.8146\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5260 - mse: 0.5260 - val_loss: 19.2007 - val_mse: 19.2007\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5322 - mse: 0.5322 - val_loss: 334.6654 - val_mse: 334.6654\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5086 - mse: 0.5086 - val_loss: 36.4416 - val_mse: 36.4416\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.5018 - val_loss: 993.6104 - val_mse: 993.6104\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4884 - mse: 0.4884 - val_loss: 2409.9810 - val_mse: 2409.9810\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5099 - mse: 0.5099 - val_loss: 28.4492 - val_mse: 28.4492\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4828 - mse: 0.4828 - val_loss: 3022.2947 - val_mse: 3022.2947\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4539 - mse: 0.4539 - val_loss: 3927.7261 - val_mse: 3927.7261\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4775 - mse: 0.4775 - val_loss: 3060.8921 - val_mse: 3060.8921\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4697 - mse: 0.4697 - val_loss: 62.8909 - val_mse: 62.8909\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "11\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7310 - mse: 0.7310 - val_loss: 923.6305 - val_mse: 923.6305\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5854 - mse: 0.5854 - val_loss: 745.7667 - val_mse: 745.7667\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5207 - mse: 0.5207 - val_loss: 1035.4274 - val_mse: 1035.4274\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5084 - mse: 0.5084 - val_loss: 691.6239 - val_mse: 691.6239\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5013 - mse: 0.5013 - val_loss: 128.5023 - val_mse: 128.5023\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4864 - mse: 0.4864 - val_loss: 82.8549 - val_mse: 82.8549\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4841 - mse: 0.4841 - val_loss: 4709.3999 - val_mse: 4709.3999\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4712 - mse: 0.4712 - val_loss: 2120.1489 - val_mse: 2120.1489\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4931 - mse: 0.4931 - val_loss: 76.5174 - val_mse: 76.5174\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4591 - mse: 0.4591 - val_loss: 2120.8604 - val_mse: 2120.8604\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4312 - mse: 0.4312 - val_loss: 5578.8252 - val_mse: 5578.8252\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4612 - mse: 0.4612 - val_loss: 644.9313 - val_mse: 644.9313\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4251 - mse: 0.4251 - val_loss: 395.9427 - val_mse: 395.9427\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4298 - mse: 0.4298 - val_loss: 2605.5754 - val_mse: 2605.5754\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4233 - mse: 0.4233 - val_loss: 2375.4563 - val_mse: 2375.4563\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3752 - mse: 0.3752 - val_loss: 1903.9598 - val_mse: 1903.9598\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4019 - mse: 0.4019 - val_loss: 2790.0813 - val_mse: 2790.0813\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4058 - mse: 0.4058 - val_loss: 16102.2529 - val_mse: 16102.2529\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4039 - mse: 0.4039 - val_loss: 127.4595 - val_mse: 127.4595\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "12\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7452 - mse: 0.7452 - val_loss: 28.7944 - val_mse: 28.7944\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5656 - mse: 0.5656 - val_loss: 29.7785 - val_mse: 29.7785\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5231 - mse: 0.5231 - val_loss: 12.7388 - val_mse: 12.7388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4958 - mse: 0.4958 - val_loss: 108.2016 - val_mse: 108.2016\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5015 - mse: 0.5015 - val_loss: 275.2032 - val_mse: 275.2032\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4693 - mse: 0.4693 - val_loss: 782.1884 - val_mse: 782.1884\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4643 - mse: 0.4643 - val_loss: 663.6257 - val_mse: 663.6257\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4436 - mse: 0.4436 - val_loss: 332.0081 - val_mse: 332.0081\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4632 - mse: 0.4632 - val_loss: 29.1468 - val_mse: 29.1468\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4412 - mse: 0.4412 - val_loss: 2044.2184 - val_mse: 2044.2184\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4149 - mse: 0.4149 - val_loss: 413.8312 - val_mse: 413.8312\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4186 - mse: 0.4186 - val_loss: 748.8674 - val_mse: 748.8674\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4044 - mse: 0.4044 - val_loss: 8218.8486 - val_mse: 8218.8486\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "13\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7656 - mse: 0.7656 - val_loss: 673.7238 - val_mse: 673.7238\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5587 - mse: 0.5587 - val_loss: 111.5228 - val_mse: 111.5228\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5109 - mse: 0.5109 - val_loss: 8.3186 - val_mse: 8.3186\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4732 - mse: 0.4732 - val_loss: 295.4095 - val_mse: 295.4095\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5088 - mse: 0.5088 - val_loss: 25.8346 - val_mse: 25.8346\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4772 - mse: 0.4772 - val_loss: 410.0269 - val_mse: 410.0269\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4671 - mse: 0.4671 - val_loss: 86.9349 - val_mse: 86.9349\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4432 - mse: 0.4432 - val_loss: 1049.8533 - val_mse: 1049.8533\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4538 - mse: 0.4538 - val_loss: 109.6026 - val_mse: 109.6026\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4314 - mse: 0.4314 - val_loss: 1131.9437 - val_mse: 1131.9437\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4204 - mse: 0.4204 - val_loss: 4424.6934 - val_mse: 4424.6934\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4045 - mse: 0.4045 - val_loss: 464.2236 - val_mse: 464.2236\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4164 - mse: 0.4164 - val_loss: 487.7104 - val_mse: 487.7104\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "14\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7333 - mse: 0.7333 - val_loss: 1048.8633 - val_mse: 1048.8633\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5516 - mse: 0.5516 - val_loss: 5.0775 - val_mse: 5.0775\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5019 - mse: 0.5019 - val_loss: 1.5788 - val_mse: 1.5788\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4698 - mse: 0.4698 - val_loss: 368.2100 - val_mse: 368.2100\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4881 - mse: 0.4881 - val_loss: 326.0115 - val_mse: 326.0115\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4406 - mse: 0.4406 - val_loss: 645.5862 - val_mse: 645.5862\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4363 - mse: 0.4363 - val_loss: 10320.3457 - val_mse: 10320.3457\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4260 - mse: 0.4260 - val_loss: 528.0586 - val_mse: 528.0586\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4296 - mse: 0.4296 - val_loss: 47.3006 - val_mse: 47.3006\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4081 - mse: 0.4081 - val_loss: 5597.7363 - val_mse: 5597.7363\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3848 - mse: 0.3848 - val_loss: 38550.2344 - val_mse: 38550.2344\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3945 - mse: 0.3945 - val_loss: 535.9433 - val_mse: 535.9433\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3756 - mse: 0.3756 - val_loss: 131.2998 - val_mse: 131.2998\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "15\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.7187 - mse: 0.7187 - val_loss: 86.5447 - val_mse: 86.5447\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5642 - mse: 0.5642 - val_loss: 4.5969 - val_mse: 4.5969\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5038 - mse: 0.5038 - val_loss: 3195.4897 - val_mse: 3195.4897\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4869 - mse: 0.4869 - val_loss: 85.8195 - val_mse: 85.8195\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4808 - mse: 0.4808 - val_loss: 348.2567 - val_mse: 348.2567\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4488 - mse: 0.4488 - val_loss: 1106.9874 - val_mse: 1106.9874\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4775 - mse: 0.4775 - val_loss: 210.5409 - val_mse: 210.5409\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4433 - mse: 0.4433 - val_loss: 319.2195 - val_mse: 319.2195\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4411 - mse: 0.4411 - val_loss: 193.3265 - val_mse: 193.3265\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4166 - mse: 0.4166 - val_loss: 4636.6807 - val_mse: 4636.6807\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3966 - mse: 0.3966 - val_loss: 20056.2305 - val_mse: 20056.2305\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4060 - mse: 0.4060 - val_loss: 989.0764 - val_mse: 989.0764\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "16\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6250 - mse: 0.6250 - val_loss: 11.3212 - val_mse: 11.3212\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5156 - mse: 0.5156 - val_loss: 144.3937 - val_mse: 144.3937\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4847 - mse: 0.4847 - val_loss: 257.0355 - val_mse: 257.0355\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4540 - mse: 0.4540 - val_loss: 1321.4546 - val_mse: 1321.4546\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4721 - mse: 0.4721 - val_loss: 0.5606 - val_mse: 0.5606\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4271 - mse: 0.4271 - val_loss: 6604.2671 - val_mse: 6604.2671\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4342 - mse: 0.4342 - val_loss: 1546.0850 - val_mse: 1546.0850\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3992 - mse: 0.3992 - val_loss: 45733.5664 - val_mse: 45733.5664\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4247 - mse: 0.4247 - val_loss: 440.2243 - val_mse: 440.2243\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3847 - mse: 0.3847 - val_loss: 1916.3628 - val_mse: 1916.3628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3619 - mse: 0.3619 - val_loss: 64494.3359 - val_mse: 64494.3359\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3601 - mse: 0.3601 - val_loss: 659.0420 - val_mse: 659.0420\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 1951.8297 - val_mse: 1951.8297\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3435 - mse: 0.3435 - val_loss: 58.8888 - val_mse: 58.8888\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3459 - mse: 0.3459 - val_loss: 8.5236 - val_mse: 8.5236\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "17\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7233 - mse: 0.7233 - val_loss: 321.9875 - val_mse: 321.9875\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5427 - mse: 0.5427 - val_loss: 46.8831 - val_mse: 46.8831\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5169 - mse: 0.5169 - val_loss: 23.1465 - val_mse: 23.1465\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4759 - mse: 0.4759 - val_loss: 253.8166 - val_mse: 253.8166\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4825 - mse: 0.4825 - val_loss: 190.1996 - val_mse: 190.1996\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4526 - mse: 0.4526 - val_loss: 22.6841 - val_mse: 22.6841\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4472 - mse: 0.4472 - val_loss: 25.7190 - val_mse: 25.7190\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4323 - mse: 0.4323 - val_loss: 5341.6221 - val_mse: 5341.6221\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4359 - mse: 0.4359 - val_loss: 427.9099 - val_mse: 427.9099\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3893 - mse: 0.3893 - val_loss: 7809.5024 - val_mse: 7809.5024\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4048 - mse: 0.4048 - val_loss: 28235.8984 - val_mse: 28235.8984\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4175 - mse: 0.4175 - val_loss: 391.8208 - val_mse: 391.8208\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3972 - mse: 0.3972 - val_loss: 4939.5938 - val_mse: 4939.5938\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3763 - mse: 0.3763 - val_loss: 7187.6182 - val_mse: 7187.6182\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3858 - mse: 0.3858 - val_loss: 375.8860 - val_mse: 375.8860\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3295 - mse: 0.3295 - val_loss: 2289.9507 - val_mse: 2289.9507\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "18\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.7345 - mse: 0.7345 - val_loss: 294.2423 - val_mse: 294.2423\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5500 - mse: 0.5500 - val_loss: 272.4296 - val_mse: 272.4296\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5027 - mse: 0.5027 - val_loss: 46.9766 - val_mse: 46.9766\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.4747 - mse: 0.4747 - val_loss: 6.0575 - val_mse: 6.0575\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4733 - mse: 0.4733 - val_loss: 317.6420 - val_mse: 317.6420\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4719 - mse: 0.4719 - val_loss: 237.8780 - val_mse: 237.8780\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.4606 - mse: 0.4606 - val_loss: 398.4533 - val_mse: 398.4533\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.4155 - mse: 0.4155 - val_loss: 1114.8530 - val_mse: 1114.8530\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.4368 - mse: 0.4368 - val_loss: 333.3647 - val_mse: 333.3647\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.3982 - mse: 0.3982 - val_loss: 287.4253 - val_mse: 287.4253\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.3818 - mse: 0.3818 - val_loss: 6458.5063 - val_mse: 6458.5063\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.4216 - mse: 0.4216 - val_loss: 103.3226 - val_mse: 103.3226\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.3864 - mse: 0.3864 - val_loss: 938.8675 - val_mse: 938.8675\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.3688 - mse: 0.3688 - val_loss: 214.2371 - val_mse: 214.2371\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "19\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.6990 - mse: 0.6990 - val_loss: 2112.8127 - val_mse: 2112.8127\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5309 - mse: 0.5309 - val_loss: 278.6573 - val_mse: 278.6573\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5049 - mse: 0.5049 - val_loss: 0.7385 - val_mse: 0.7385\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4596 - mse: 0.4596 - val_loss: 92.9442 - val_mse: 92.9442\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4632 - mse: 0.4632 - val_loss: 32.6471 - val_mse: 32.6471\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4466 - mse: 0.4466 - val_loss: 25.0135 - val_mse: 25.0135\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4281 - mse: 0.4281 - val_loss: 6243.5859 - val_mse: 6243.5859\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4288 - mse: 0.4288 - val_loss: 1198.4401 - val_mse: 1198.4401\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4395 - mse: 0.4395 - val_loss: 16.6617 - val_mse: 16.6617\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4149 - mse: 0.4149 - val_loss: 2296.2944 - val_mse: 2296.2944\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.3997 - mse: 0.3997 - val_loss: 15524.8203 - val_mse: 15524.8203\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4092 - mse: 0.4092 - val_loss: 144.3983 - val_mse: 144.3983\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.3810 - mse: 0.3810 - val_loss: 2859.1655 - val_mse: 2859.1655\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "20\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.7154 - mse: 0.7154 - val_loss: 66.3362 - val_mse: 66.3362\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5556 - mse: 0.5556 - val_loss: 117.6515 - val_mse: 117.6515\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5093 - mse: 0.5093 - val_loss: 15.3910 - val_mse: 15.3910\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4729 - mse: 0.4729 - val_loss: 265.6132 - val_mse: 265.6132\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4842 - mse: 0.4842 - val_loss: 147.5320 - val_mse: 147.5320\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4614 - mse: 0.4614 - val_loss: 387.4583 - val_mse: 387.4583\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4607 - mse: 0.4607 - val_loss: 20.8662 - val_mse: 20.8662\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4434 - mse: 0.4434 - val_loss: 56.8736 - val_mse: 56.8736\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4573 - mse: 0.4573 - val_loss: 244.2321 - val_mse: 244.2321\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4243 - mse: 0.4243 - val_loss: 159.1790 - val_mse: 159.1790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.4066 - mse: 0.4066 - val_loss: 17179.3789 - val_mse: 17179.3789\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 5ms/step - loss: 0.4074 - mse: 0.4074 - val_loss: 39.3318 - val_mse: 39.3318\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.3832 - mse: 0.3832 - val_loss: 120.6587 - val_mse: 120.6587\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "21\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6821 - mse: 0.6821 - val_loss: 168.6985 - val_mse: 168.6985\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5463 - mse: 0.5463 - val_loss: 163.9210 - val_mse: 163.9210\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4907 - mse: 0.4907 - val_loss: 160.7252 - val_mse: 160.7252\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4658 - mse: 0.4658 - val_loss: 9.1555 - val_mse: 9.1555\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4726 - mse: 0.4726 - val_loss: 474.3079 - val_mse: 474.3079\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.4471 - mse: 0.4471 - val_loss: 375.8393 - val_mse: 375.8393\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4513 - mse: 0.4513 - val_loss: 5457.6807 - val_mse: 5457.6807\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4063 - mse: 0.4063 - val_loss: 330.9510 - val_mse: 330.9510\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4348 - mse: 0.4348 - val_loss: 69.7028 - val_mse: 69.7028\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3986 - mse: 0.3986 - val_loss: 204.4031 - val_mse: 204.4031\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3731 - mse: 0.3731 - val_loss: 2667.9573 - val_mse: 2667.9573\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3978 - mse: 0.3978 - val_loss: 2377.7166 - val_mse: 2377.7166\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3638 - mse: 0.3638 - val_loss: 6695.1626 - val_mse: 6695.1626\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3575 - mse: 0.3575 - val_loss: 851.9748 - val_mse: 851.9748\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "22\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7212 - mse: 0.7212 - val_loss: 11.6193 - val_mse: 11.6193\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5418 - mse: 0.5418 - val_loss: 1.1798 - val_mse: 1.1798\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4817 - mse: 0.4817 - val_loss: 45.7547 - val_mse: 45.7547\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4485 - mse: 0.4485 - val_loss: 122.3708 - val_mse: 122.3708\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4562 - mse: 0.4562 - val_loss: 67.6899 - val_mse: 67.6899\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3968 - mse: 0.3968 - val_loss: 4390.0068 - val_mse: 4390.0068\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4027 - mse: 0.4027 - val_loss: 21796.5586 - val_mse: 21796.5586\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3606 - mse: 0.3606 - val_loss: 31693.0039 - val_mse: 31693.0039\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3832 - mse: 0.3832 - val_loss: 3.4907 - val_mse: 3.4907\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3479 - mse: 0.3479 - val_loss: 186.4613 - val_mse: 186.4613\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3359 - mse: 0.3359 - val_loss: 13423.3545 - val_mse: 13423.3545\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3408 - mse: 0.3408 - val_loss: 268.6339 - val_mse: 268.6339\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "23\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7259 - mse: 0.7259 - val_loss: 246.4744 - val_mse: 246.4744\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5025 - mse: 0.5025 - val_loss: 7.2160 - val_mse: 7.2160\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4424 - mse: 0.4424 - val_loss: 9.9634 - val_mse: 9.9634\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4083 - mse: 0.4083 - val_loss: 184.3277 - val_mse: 184.3277\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4071 - mse: 0.4071 - val_loss: 18.2091 - val_mse: 18.2091\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3565 - mse: 0.3565 - val_loss: 28703.2285 - val_mse: 28703.2285\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3453 - mse: 0.3453 - val_loss: 2.8673 - val_mse: 2.8673\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2999 - mse: 0.2999 - val_loss: 33367.2852 - val_mse: 33367.2852\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3289 - mse: 0.3289 - val_loss: 17.7575 - val_mse: 17.7575\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3015 - mse: 0.3015 - val_loss: 549.4461 - val_mse: 549.4461\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2864 - mse: 0.2864 - val_loss: 101727.9297 - val_mse: 101727.9297\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2795 - mse: 0.2795 - val_loss: 504.8953 - val_mse: 504.8953\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2655 - mse: 0.2655 - val_loss: 28534.4766 - val_mse: 28534.4766\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2604 - mse: 0.2604 - val_loss: 594.4484 - val_mse: 594.4484\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2516 - mse: 0.2516 - val_loss: 30.9163 - val_mse: 30.9163\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2277 - mse: 0.2277 - val_loss: 220.4021 - val_mse: 220.4021\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2487 - mse: 0.2487 - val_loss: 289.0705 - val_mse: 289.0705\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "24\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6552 - mse: 0.6552 - val_loss: 322.7616 - val_mse: 322.7616\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5113 - mse: 0.5113 - val_loss: 40.4393 - val_mse: 40.4393\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4548 - mse: 0.4548 - val_loss: 343.2481 - val_mse: 343.2481\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3900 - mse: 0.3900 - val_loss: 133.5899 - val_mse: 133.5899\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3857 - mse: 0.3857 - val_loss: 62.6505 - val_mse: 62.6505\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3550 - mse: 0.3550 - val_loss: 23338.4688 - val_mse: 23338.4688\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3474 - mse: 0.3474 - val_loss: 717.0159 - val_mse: 717.0159\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3207 - mse: 0.3207 - val_loss: 11507.5049 - val_mse: 11507.5049\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3099 - mse: 0.3099 - val_loss: 8.7701 - val_mse: 8.7701\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2947 - mse: 0.2947 - val_loss: 97.1771 - val_mse: 97.1771\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2665 - mse: 0.2665 - val_loss: 40173.7188 - val_mse: 40173.7188\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2856 - mse: 0.2856 - val_loss: 1556.8101 - val_mse: 1556.8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2875 - mse: 0.2875 - val_loss: 6453.2988 - val_mse: 6453.2988\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2697 - mse: 0.2697 - val_loss: 5123.7700 - val_mse: 5123.7700\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2691 - mse: 0.2691 - val_loss: 0.6499 - val_mse: 0.6499\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 224.8473 - val_mse: 224.8473\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2348 - mse: 0.2348 - val_loss: 8309.7490 - val_mse: 8309.7490\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2454 - mse: 0.2454 - val_loss: 4990.9370 - val_mse: 4990.9370\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 2946.2014 - val_mse: 2946.2014\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 27.5653 - val_mse: 27.5653\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1849 - mse: 0.1849 - val_loss: 134.7678 - val_mse: 134.7678\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1925 - mse: 0.1925 - val_loss: 173.1409 - val_mse: 173.1409\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2055 - mse: 0.2055 - val_loss: 162.4038 - val_mse: 162.4038\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2071 - mse: 0.2071 - val_loss: 1.7828 - val_mse: 1.7828\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 76.6957 - val_mse: 76.6957\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "25\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.6673 - mse: 0.6673 - val_loss: 685.3668 - val_mse: 685.3668\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4861 - mse: 0.4861 - val_loss: 1211.0563 - val_mse: 1211.0563\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4597 - mse: 0.4597 - val_loss: 4105.8506 - val_mse: 4105.8506\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4091 - mse: 0.4091 - val_loss: 757.8702 - val_mse: 757.8702\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4065 - mse: 0.4065 - val_loss: 282.6335 - val_mse: 282.6335\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3628 - mse: 0.3628 - val_loss: 1584.8759 - val_mse: 1584.8759\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3502 - mse: 0.3502 - val_loss: 326.8257 - val_mse: 326.8257\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3147 - mse: 0.3147 - val_loss: 19848.8457 - val_mse: 19848.8457\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3443 - mse: 0.3443 - val_loss: 32.8674 - val_mse: 32.8674\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2868 - mse: 0.2868 - val_loss: 492.6572 - val_mse: 492.6572\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2833 - mse: 0.2833 - val_loss: 147.7366 - val_mse: 147.7366\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2645 - mse: 0.2645 - val_loss: 342.4875 - val_mse: 342.4875\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3047 - mse: 0.3047 - val_loss: 23784.5820 - val_mse: 23784.5820\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2603 - mse: 0.2603 - val_loss: 248.5955 - val_mse: 248.5955\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2533 - mse: 0.2533 - val_loss: 1.7527 - val_mse: 1.7527\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 1.1133 - val_mse: 1.1133\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2357 - mse: 0.2357 - val_loss: 2653.2202 - val_mse: 2653.2202\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2214 - mse: 0.2214 - val_loss: 5918.1133 - val_mse: 5918.1133\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 77.4802 - val_mse: 77.4802\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2342 - mse: 0.2342 - val_loss: 2501.3269 - val_mse: 2501.3269\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2180 - mse: 0.2180 - val_loss: 287.8804 - val_mse: 287.8804\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1967 - mse: 0.1967 - val_loss: 137.3146 - val_mse: 137.3146\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1994 - mse: 0.1994 - val_loss: 3018.6978 - val_mse: 3018.6978\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1951 - mse: 0.1951 - val_loss: 165.9873 - val_mse: 165.9873\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1874 - mse: 0.1874 - val_loss: 5.4867 - val_mse: 5.4867\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1796 - mse: 0.1796 - val_loss: 38686.1641 - val_mse: 38686.1641\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "26\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 6ms/step - loss: 0.7251 - mse: 0.7251 - val_loss: 8863.2676 - val_mse: 8863.2676\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4924 - mse: 0.4924 - val_loss: 10412.3545 - val_mse: 10412.3545\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4400 - mse: 0.4400 - val_loss: 2705.4302 - val_mse: 2705.4302\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3751 - mse: 0.3751 - val_loss: 526.3783 - val_mse: 526.3783\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3661 - mse: 0.3661 - val_loss: 11.0149 - val_mse: 11.0149\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3139 - mse: 0.3139 - val_loss: 2285.8020 - val_mse: 2285.8020\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3049 - mse: 0.3049 - val_loss: 34.8597 - val_mse: 34.8597\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2749 - mse: 0.2749 - val_loss: 12881.8311 - val_mse: 12881.8311\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2960 - mse: 0.2960 - val_loss: 19.5490 - val_mse: 19.5490\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2627 - mse: 0.2627 - val_loss: 664.0516 - val_mse: 664.0516\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2641 - mse: 0.2641 - val_loss: 13853.6836 - val_mse: 13853.6836\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2610 - mse: 0.2610 - val_loss: 350.3416 - val_mse: 350.3416\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2410 - mse: 0.2410 - val_loss: 20434.8027 - val_mse: 20434.8027\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2315 - mse: 0.2315 - val_loss: 17306.8711 - val_mse: 17306.8711\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2391 - mse: 0.2391 - val_loss: 57.8549 - val_mse: 57.8549\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "27\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6531 - mse: 0.6531 - val_loss: 2612.0205 - val_mse: 2612.0205\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4546 - mse: 0.4546 - val_loss: 946.2236 - val_mse: 946.2236\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3859 - mse: 0.3859 - val_loss: 7.5465 - val_mse: 7.5465\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3399 - mse: 0.3399 - val_loss: 83.9277 - val_mse: 83.9277\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3170 - mse: 0.3170 - val_loss: 78.1053 - val_mse: 78.1053\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2874 - mse: 0.2874 - val_loss: 34287.3945 - val_mse: 34287.3945\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2986 - mse: 0.2986 - val_loss: 7.3174 - val_mse: 7.3174\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2714 - mse: 0.2714 - val_loss: 16727.9551 - val_mse: 16727.9551\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2940 - mse: 0.2940 - val_loss: 15.2499 - val_mse: 15.2499\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2436 - mse: 0.2436 - val_loss: 5.4472 - val_mse: 5.4472\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2375 - mse: 0.2375 - val_loss: 71097.1328 - val_mse: 71097.1328\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 9.6830 - val_mse: 9.6830\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2162 - mse: 0.2162 - val_loss: 3819.4272 - val_mse: 3819.4272\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2060 - mse: 0.2060 - val_loss: 39249.8008 - val_mse: 39249.8008\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2221 - mse: 0.2221 - val_loss: 1.0427 - val_mse: 1.0427\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1912 - mse: 0.1912 - val_loss: 0.8752 - val_mse: 0.8752\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2163 - mse: 0.2163 - val_loss: 5158.4844 - val_mse: 5158.4844\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1932 - mse: 0.1932 - val_loss: 2075.8362 - val_mse: 2075.8362\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2152 - mse: 0.2152 - val_loss: 5169.6118 - val_mse: 5169.6118\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 37.9267 - val_mse: 37.9267\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1676 - mse: 0.1676 - val_loss: 13005.1875 - val_mse: 13005.1875\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1874 - mse: 0.1874 - val_loss: 31.2156 - val_mse: 31.2156\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1757 - mse: 0.1757 - val_loss: 16923.0996 - val_mse: 16923.0996\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1750 - mse: 0.1750 - val_loss: 9.7309 - val_mse: 9.7309\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 138.3313 - val_mse: 138.3313\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 5073.3525 - val_mse: 5073.3525\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "28\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6702 - mse: 0.6702 - val_loss: 5809.3989 - val_mse: 5809.3989\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4463 - mse: 0.4463 - val_loss: 71.3083 - val_mse: 71.3083\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3721 - mse: 0.3721 - val_loss: 529.3696 - val_mse: 529.3696\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3344 - mse: 0.3344 - val_loss: 6.3828 - val_mse: 6.3828\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3415 - mse: 0.3415 - val_loss: 978.0116 - val_mse: 978.0116\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3037 - mse: 0.3037 - val_loss: 11076.6240 - val_mse: 11076.6240\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3013 - mse: 0.3013 - val_loss: 67.2271 - val_mse: 67.2271\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2790 - mse: 0.2790 - val_loss: 19210.9961 - val_mse: 19210.9961\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2790 - mse: 0.2790 - val_loss: 1.0918 - val_mse: 1.0918\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2513 - mse: 0.2513 - val_loss: 478.9173 - val_mse: 478.9173\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2436 - mse: 0.2436 - val_loss: 19587.5078 - val_mse: 19587.5078\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 198.3574 - val_mse: 198.3574\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2203 - mse: 0.2203 - val_loss: 5335.9243 - val_mse: 5335.9243\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2307 - mse: 0.2307 - val_loss: 132.1013 - val_mse: 132.1013\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2394 - mse: 0.2394 - val_loss: 49.4965 - val_mse: 49.4965\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2045 - mse: 0.2045 - val_loss: 2.2877 - val_mse: 2.2877\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2229 - mse: 0.2229 - val_loss: 21984.6426 - val_mse: 21984.6426\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1946 - mse: 0.1946 - val_loss: 543.9827 - val_mse: 543.9827\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2164 - mse: 0.2164 - val_loss: 877.9682 - val_mse: 877.9682\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "29\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.6672 - mse: 0.6672 - val_loss: 15.0192 - val_mse: 15.0192\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4824 - mse: 0.4824 - val_loss: 2956.2686 - val_mse: 2956.2686\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3941 - mse: 0.3941 - val_loss: 11.4204 - val_mse: 11.4204\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3436 - mse: 0.3436 - val_loss: 133.3328 - val_mse: 133.3328\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3124 - mse: 0.3124 - val_loss: 194.1381 - val_mse: 194.1381\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2982 - mse: 0.2982 - val_loss: 6586.6274 - val_mse: 6586.6274\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2920 - mse: 0.2920 - val_loss: 3292.3418 - val_mse: 3292.3418\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2456 - mse: 0.2456 - val_loss: 10753.0098 - val_mse: 10753.0098\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2763 - mse: 0.2763 - val_loss: 8.7219 - val_mse: 8.7219\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2643 - mse: 0.2643 - val_loss: 168.9693 - val_mse: 168.9693\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2300 - mse: 0.2300 - val_loss: 37600.8203 - val_mse: 37600.8203\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2231 - mse: 0.2231 - val_loss: 482.6209 - val_mse: 482.6209\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2235 - mse: 0.2235 - val_loss: 16988.6719 - val_mse: 16988.6719\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2013 - mse: 0.2013 - val_loss: 37409.3477 - val_mse: 37409.3477\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2277 - mse: 0.2277 - val_loss: 15.3439 - val_mse: 15.3439\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1949 - mse: 0.1949 - val_loss: 1.0857 - val_mse: 1.0857\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1905 - mse: 0.1905 - val_loss: 2192.0996 - val_mse: 2192.0996\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1871 - mse: 0.1871 - val_loss: 18102.1953 - val_mse: 18102.1953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2132 - mse: 0.2132 - val_loss: 13998.5674 - val_mse: 13998.5674\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2354 - mse: 0.2354 - val_loss: 39.3143 - val_mse: 39.3143\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1688 - mse: 0.1688 - val_loss: 16.1955 - val_mse: 16.1955\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 1174.5867 - val_mse: 1174.5867\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1734 - mse: 0.1734 - val_loss: 20.3889 - val_mse: 20.3889\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1697 - mse: 0.1697 - val_loss: 50.0866 - val_mse: 50.0866\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1708 - mse: 0.1708 - val_loss: 87.6513 - val_mse: 87.6513\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1759 - mse: 0.1759 - val_loss: 42690.9844 - val_mse: 42690.9844\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "30\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6867 - mse: 0.6867 - val_loss: 4362.0239 - val_mse: 4362.0239\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4492 - mse: 0.4492 - val_loss: 597.6912 - val_mse: 597.6912\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3724 - mse: 0.3724 - val_loss: 105.9928 - val_mse: 105.9928\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3432 - mse: 0.3432 - val_loss: 206.9825 - val_mse: 206.9825\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3430 - mse: 0.3430 - val_loss: 1892.5708 - val_mse: 1892.5708\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3131 - mse: 0.3131 - val_loss: 18190.4141 - val_mse: 18190.4141\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2906 - mse: 0.2906 - val_loss: 259.1761 - val_mse: 259.1761\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2615 - mse: 0.2615 - val_loss: 8795.2354 - val_mse: 8795.2354\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2849 - mse: 0.2849 - val_loss: 32.4914 - val_mse: 32.4914\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2581 - mse: 0.2581 - val_loss: 67.4360 - val_mse: 67.4360\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2296 - mse: 0.2296 - val_loss: 40075.1562 - val_mse: 40075.1562\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2341 - mse: 0.2341 - val_loss: 406.9983 - val_mse: 406.9983\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 12591.1465 - val_mse: 12591.1465\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2350 - mse: 0.2350 - val_loss: 7.0917 - val_mse: 7.0917\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2353 - mse: 0.2353 - val_loss: 7.0156 - val_mse: 7.0156\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2012 - mse: 0.2012 - val_loss: 648.4288 - val_mse: 648.4288\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2091 - mse: 0.2091 - val_loss: 7857.5825 - val_mse: 7857.5825\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2157 - mse: 0.2157 - val_loss: 3206.0483 - val_mse: 3206.0483\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2153 - mse: 0.2153 - val_loss: 1.8017 - val_mse: 1.8017\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2335 - mse: 0.2335 - val_loss: 3153.4558 - val_mse: 3153.4558\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1749 - mse: 0.1749 - val_loss: 1266.1969 - val_mse: 1266.1969\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 1176.1777 - val_mse: 1176.1777\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1759 - mse: 0.1759 - val_loss: 101.8671 - val_mse: 101.8671\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1671 - mse: 0.1671 - val_loss: 48.6684 - val_mse: 48.6684\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1732 - mse: 0.1732 - val_loss: 418.7569 - val_mse: 418.7569\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1771 - mse: 0.1771 - val_loss: 2394.2749 - val_mse: 2394.2749\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1760 - mse: 0.1760 - val_loss: 51.6868 - val_mse: 51.6868\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1757 - mse: 0.1757 - val_loss: 6.7004 - val_mse: 6.7004\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1562 - mse: 0.1562 - val_loss: 0.7139 - val_mse: 0.7139\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1786 - mse: 0.1786 - val_loss: 1.1500 - val_mse: 1.1500\n",
      "Epoch 31/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1859 - mse: 0.1859 - val_loss: 3154.9314 - val_mse: 3154.9314\n",
      "Epoch 32/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1533 - mse: 0.1533 - val_loss: 1454.1743 - val_mse: 1454.1743\n",
      "Epoch 33/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1506 - mse: 0.1506 - val_loss: 11.8527 - val_mse: 11.8527\n",
      "Epoch 34/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1645 - mse: 0.1645 - val_loss: 4.2152 - val_mse: 4.2152\n",
      "Epoch 35/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1479 - mse: 0.1479 - val_loss: 146.3921 - val_mse: 146.3921\n",
      "Epoch 36/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1696 - mse: 0.1696 - val_loss: 61012.1094 - val_mse: 61012.1094\n",
      "Epoch 37/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1644 - mse: 0.1644 - val_loss: 17.6993 - val_mse: 17.6993\n",
      "Epoch 38/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1443 - mse: 0.1443 - val_loss: 0.7548 - val_mse: 0.7548\n",
      "Epoch 39/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1388 - mse: 0.1388 - val_loss: 186.1799 - val_mse: 186.1799\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "31\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 8059.2275 - val_mse: 8059.2275\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5232 - mse: 0.5232 - val_loss: 3228.8181 - val_mse: 3228.8181\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4359 - mse: 0.4359 - val_loss: 381.3189 - val_mse: 381.3189\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3946 - mse: 0.3946 - val_loss: 55.1278 - val_mse: 55.1278\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3554 - mse: 0.3554 - val_loss: 128.6242 - val_mse: 128.6242\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3331 - mse: 0.3331 - val_loss: 15512.3555 - val_mse: 15512.3555\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2958 - mse: 0.2958 - val_loss: 51.9492 - val_mse: 51.9492\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2784 - mse: 0.2784 - val_loss: 38997.0625 - val_mse: 38997.0625\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2963 - mse: 0.2963 - val_loss: 77.2219 - val_mse: 77.2219\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2600 - mse: 0.2600 - val_loss: 0.8105 - val_mse: 0.8105\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2427 - mse: 0.2427 - val_loss: 26063.3652 - val_mse: 26063.3652\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 1011.2791 - val_mse: 1011.2791\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2298 - mse: 0.2298 - val_loss: 30074.4688 - val_mse: 30074.4688\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 12342.1797 - val_mse: 12342.1797\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2387 - mse: 0.2387 - val_loss: 234.3899 - val_mse: 234.3899\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2077 - mse: 0.2077 - val_loss: 28.4225 - val_mse: 28.4225\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2204 - mse: 0.2204 - val_loss: 1541.1582 - val_mse: 1541.1582\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1959 - mse: 0.1959 - val_loss: 8554.2188 - val_mse: 8554.2188\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2041 - mse: 0.2041 - val_loss: 66.1192 - val_mse: 66.1192\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2092 - mse: 0.2092 - val_loss: 33.9209 - val_mse: 33.9209\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "32\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6490 - mse: 0.6490 - val_loss: 1479.1104 - val_mse: 1479.1104\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4318 - mse: 0.4318 - val_loss: 6722.5693 - val_mse: 6722.5693\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3781 - mse: 0.3781 - val_loss: 14410.3838 - val_mse: 14410.3838\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3264 - mse: 0.3264 - val_loss: 64.5623 - val_mse: 64.5623\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3132 - mse: 0.3132 - val_loss: 136.0531 - val_mse: 136.0531\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2766 - mse: 0.2766 - val_loss: 7676.6978 - val_mse: 7676.6978\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2898 - mse: 0.2898 - val_loss: 36.7021 - val_mse: 36.7021\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2519 - mse: 0.2519 - val_loss: 20582.5098 - val_mse: 20582.5098\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2903 - mse: 0.2903 - val_loss: 34.7831 - val_mse: 34.7831\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2342 - mse: 0.2342 - val_loss: 306.9260 - val_mse: 306.9260\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 4722.1934 - val_mse: 4722.1934\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2397 - mse: 0.2397 - val_loss: 928.1763 - val_mse: 928.1763\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 2145.9475 - val_mse: 2145.9475\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2231 - mse: 0.2231 - val_loss: 16471.0059 - val_mse: 16471.0059\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2167 - mse: 0.2167 - val_loss: 136.5236 - val_mse: 136.5236\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1887 - mse: 0.1887 - val_loss: 1.1590 - val_mse: 1.1590\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1921 - mse: 0.1921 - val_loss: 483.0001 - val_mse: 483.0001\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2064 - mse: 0.2064 - val_loss: 36334.5820 - val_mse: 36334.5820\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2093 - mse: 0.2093 - val_loss: 5306.5928 - val_mse: 5306.5928\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1939 - mse: 0.1939 - val_loss: 1.8752 - val_mse: 1.8752\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1964 - mse: 0.1964 - val_loss: 1438.0370 - val_mse: 1438.0370\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1810 - mse: 0.1810 - val_loss: 116.4591 - val_mse: 116.4591\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1707 - mse: 0.1707 - val_loss: 64.3994 - val_mse: 64.3994\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1665 - mse: 0.1665 - val_loss: 20.1599 - val_mse: 20.1599\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1591 - mse: 0.1591 - val_loss: 2.0431 - val_mse: 2.0431\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1719 - mse: 0.1719 - val_loss: 35184.4883 - val_mse: 35184.4883\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "33\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7255 - mse: 0.7255 - val_loss: 109.7807 - val_mse: 109.7807\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.5088 - mse: 0.5088 - val_loss: 5274.2549 - val_mse: 5274.2549\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4208 - mse: 0.4208 - val_loss: 188.3559 - val_mse: 188.3559\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3588 - mse: 0.3588 - val_loss: 227.0064 - val_mse: 227.0064\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3335 - mse: 0.3335 - val_loss: 61.8236 - val_mse: 61.8236\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3102 - mse: 0.3102 - val_loss: 8822.0645 - val_mse: 8822.0645\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3270 - mse: 0.3270 - val_loss: 4048.5520 - val_mse: 4048.5520\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2761 - mse: 0.2761 - val_loss: 9247.7559 - val_mse: 9247.7559\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2983 - mse: 0.2983 - val_loss: 3.2710 - val_mse: 3.2710\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2579 - mse: 0.2579 - val_loss: 11.6864 - val_mse: 11.6864\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2333 - mse: 0.2333 - val_loss: 25033.8770 - val_mse: 25033.8770\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 6.8128 - val_mse: 6.8128\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2293 - mse: 0.2293 - val_loss: 6938.1982 - val_mse: 6938.1982\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2083 - mse: 0.2083 - val_loss: 60684.5820 - val_mse: 60684.5820\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2492 - mse: 0.2492 - val_loss: 0.8404 - val_mse: 0.8404\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2109 - mse: 0.2109 - val_loss: 133.8814 - val_mse: 133.8814\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2091 - mse: 0.2091 - val_loss: 3396.2068 - val_mse: 3396.2068\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1978 - mse: 0.1978 - val_loss: 9133.0107 - val_mse: 9133.0107\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2104 - mse: 0.2104 - val_loss: 4019.0784 - val_mse: 4019.0784\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2183 - mse: 0.2183 - val_loss: 1177.8077 - val_mse: 1177.8077\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1885 - mse: 0.1885 - val_loss: 12.2169 - val_mse: 12.2169\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1882 - mse: 0.1882 - val_loss: 2115.4106 - val_mse: 2115.4106\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1677 - mse: 0.1677 - val_loss: 1599.0482 - val_mse: 1599.0482\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1684 - mse: 0.1684 - val_loss: 57.0520 - val_mse: 57.0520\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1860 - mse: 0.1860 - val_loss: 2932.0291 - val_mse: 2932.0291\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "34\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6775 - mse: 0.6775 - val_loss: 5981.6099 - val_mse: 5981.6099\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4447 - mse: 0.4447 - val_loss: 470.3816 - val_mse: 470.3816\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3587 - mse: 0.3587 - val_loss: 503.3683 - val_mse: 503.3683\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3380 - mse: 0.3380 - val_loss: 33.7900 - val_mse: 33.7900\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3409 - mse: 0.3409 - val_loss: 135.2609 - val_mse: 135.2609\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3020 - mse: 0.3020 - val_loss: 1311.2328 - val_mse: 1311.2328\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2931 - mse: 0.2931 - val_loss: 31.6671 - val_mse: 31.6671\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2542 - mse: 0.2542 - val_loss: 7157.5142 - val_mse: 7157.5142\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2682 - mse: 0.2682 - val_loss: 0.9699 - val_mse: 0.9699\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2498 - mse: 0.2498 - val_loss: 4.2479 - val_mse: 4.2479\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2387 - mse: 0.2387 - val_loss: 48704.1758 - val_mse: 48704.1758\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2312 - mse: 0.2312 - val_loss: 69.8610 - val_mse: 69.8610\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 19503.3496 - val_mse: 19503.3496\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2353 - mse: 0.2353 - val_loss: 3478.2720 - val_mse: 3478.2720\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2347 - mse: 0.2347 - val_loss: 4.6054 - val_mse: 4.6054\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1959 - mse: 0.1959 - val_loss: 6.5247 - val_mse: 6.5247\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2174 - mse: 0.2174 - val_loss: 7473.5820 - val_mse: 7473.5820\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1956 - mse: 0.1956 - val_loss: 7909.4683 - val_mse: 7909.4683\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2031 - mse: 0.2031 - val_loss: 99.4212 - val_mse: 99.4212\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "35\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6807 - mse: 0.6807 - val_loss: 5345.0454 - val_mse: 5345.0454\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4553 - mse: 0.4553 - val_loss: 5720.7983 - val_mse: 5720.7983\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3716 - mse: 0.3716 - val_loss: 10408.2129 - val_mse: 10408.2129\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3207 - mse: 0.3207 - val_loss: 1.5129 - val_mse: 1.5129\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3125 - mse: 0.3125 - val_loss: 117.4307 - val_mse: 117.4307\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3047 - mse: 0.3047 - val_loss: 17462.6016 - val_mse: 17462.6016\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2672 - mse: 0.2672 - val_loss: 620.4193 - val_mse: 620.4193\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2412 - mse: 0.2412 - val_loss: 21640.6230 - val_mse: 21640.6230\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2390 - mse: 0.2390 - val_loss: 18.8006 - val_mse: 18.8006\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2321 - mse: 0.2321 - val_loss: 0.9079 - val_mse: 0.9079\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2185 - mse: 0.2185 - val_loss: 38539.4258 - val_mse: 38539.4258\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2198 - mse: 0.2198 - val_loss: 695.9357 - val_mse: 695.9357\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2198 - mse: 0.2198 - val_loss: 9137.3838 - val_mse: 9137.3838\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2076 - mse: 0.2076 - val_loss: 10904.0156 - val_mse: 10904.0156\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2419 - mse: 0.2419 - val_loss: 25.7799 - val_mse: 25.7799\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1910 - mse: 0.1910 - val_loss: 14.0181 - val_mse: 14.0181\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1917 - mse: 0.1917 - val_loss: 17438.9375 - val_mse: 17438.9375\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1867 - mse: 0.1867 - val_loss: 3965.6169 - val_mse: 3965.6169\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1918 - mse: 0.1918 - val_loss: 149.6505 - val_mse: 149.6505\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2111 - mse: 0.2111 - val_loss: 7799.4297 - val_mse: 7799.4297\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "36\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6538 - mse: 0.6538 - val_loss: 1667.8077 - val_mse: 1667.8077\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4791 - mse: 0.4791 - val_loss: 44.3421 - val_mse: 44.3421\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3758 - mse: 0.3758 - val_loss: 292.4174 - val_mse: 292.4174\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3299 - mse: 0.3299 - val_loss: 166.2792 - val_mse: 166.2792\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3241 - mse: 0.3241 - val_loss: 80.5255 - val_mse: 80.5255\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3057 - mse: 0.3057 - val_loss: 47114.2773 - val_mse: 47114.2773\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3121 - mse: 0.3121 - val_loss: 69.6653 - val_mse: 69.6653\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2710 - mse: 0.2710 - val_loss: 8757.6865 - val_mse: 8757.6865\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2633 - mse: 0.2633 - val_loss: 265.2520 - val_mse: 265.2520\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2525 - mse: 0.2525 - val_loss: 329.1296 - val_mse: 329.1296\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 28846.9199 - val_mse: 28846.9199\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2431 - mse: 0.2431 - val_loss: 362.0095 - val_mse: 362.0095\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "37\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6280 - mse: 0.6280 - val_loss: 5620.4297 - val_mse: 5620.4297\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4421 - mse: 0.4421 - val_loss: 2388.9744 - val_mse: 2388.9744\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3709 - mse: 0.3709 - val_loss: 893.4536 - val_mse: 893.4536\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3333 - mse: 0.3333 - val_loss: 441.2845 - val_mse: 441.2845\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3140 - mse: 0.3140 - val_loss: 134.7107 - val_mse: 134.7107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2908 - mse: 0.2908 - val_loss: 11883.9844 - val_mse: 11883.9844\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2719 - mse: 0.2719 - val_loss: 4963.7090 - val_mse: 4963.7090\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2473 - mse: 0.2473 - val_loss: 15146.3037 - val_mse: 15146.3037\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2561 - mse: 0.2561 - val_loss: 414.7767 - val_mse: 414.7767\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2414 - mse: 0.2414 - val_loss: 444.6939 - val_mse: 444.6939\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2438 - mse: 0.2438 - val_loss: 38424.3203 - val_mse: 38424.3203\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2312 - mse: 0.2312 - val_loss: 187.8990 - val_mse: 187.8990\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2198 - mse: 0.2198 - val_loss: 32.2484 - val_mse: 32.2484\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2055 - mse: 0.2055 - val_loss: 27578.3691 - val_mse: 27578.3691\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 9.9074 - val_mse: 9.9074\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1973 - mse: 0.1973 - val_loss: 4.0667 - val_mse: 4.0667\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2009 - mse: 0.2009 - val_loss: 4323.2617 - val_mse: 4323.2617\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1809 - mse: 0.1809 - val_loss: 912.6479 - val_mse: 912.6479\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2024 - mse: 0.2024 - val_loss: 254.7488 - val_mse: 254.7488\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2108 - mse: 0.2108 - val_loss: 563.5998 - val_mse: 563.5998\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1736 - mse: 0.1736 - val_loss: 6721.4893 - val_mse: 6721.4893\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1836 - mse: 0.1836 - val_loss: 4241.2808 - val_mse: 4241.2808\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1694 - mse: 0.1694 - val_loss: 5.8588 - val_mse: 5.8588\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1657 - mse: 0.1657 - val_loss: 38.1745 - val_mse: 38.1745\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2006 - mse: 0.2006 - val_loss: 11272.4229 - val_mse: 11272.4229\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1837 - mse: 0.1837 - val_loss: 63.0966 - val_mse: 63.0966\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "38\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6724 - mse: 0.6724 - val_loss: 1446.5763 - val_mse: 1446.5763\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4583 - mse: 0.4583 - val_loss: 1516.0155 - val_mse: 1516.0155\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3872 - mse: 0.3872 - val_loss: 460.1117 - val_mse: 460.1117\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3297 - mse: 0.3297 - val_loss: 1.1570 - val_mse: 1.1570\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3142 - mse: 0.3142 - val_loss: 10.6479 - val_mse: 10.6479\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3006 - mse: 0.3006 - val_loss: 69748.6797 - val_mse: 69748.6797\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2771 - mse: 0.2771 - val_loss: 9.9845 - val_mse: 9.9845\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2673 - mse: 0.2673 - val_loss: 13078.2822 - val_mse: 13078.2822\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2635 - mse: 0.2635 - val_loss: 9.6847 - val_mse: 9.6847\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2571 - mse: 0.2571 - val_loss: 323.1098 - val_mse: 323.1098\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2309 - mse: 0.2309 - val_loss: 78229.5547 - val_mse: 78229.5547\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2440 - mse: 0.2440 - val_loss: 116.1247 - val_mse: 116.1247\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 1299.6217 - val_mse: 1299.6217\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2027 - mse: 0.2027 - val_loss: 6339.9619 - val_mse: 6339.9619\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "39\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7418 - mse: 0.7418 - val_loss: 4977.1328 - val_mse: 4977.1328\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4769 - mse: 0.4769 - val_loss: 8608.4854 - val_mse: 8608.4854\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3913 - mse: 0.3913 - val_loss: 4464.2983 - val_mse: 4464.2983\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3623 - mse: 0.3623 - val_loss: 7.1715 - val_mse: 7.1715\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3258 - mse: 0.3258 - val_loss: 2.8931 - val_mse: 2.8931\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3224 - mse: 0.3224 - val_loss: 21189.8086 - val_mse: 21189.8086\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2707 - mse: 0.2707 - val_loss: 26.9254 - val_mse: 26.9254\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2568 - mse: 0.2568 - val_loss: 11841.0098 - val_mse: 11841.0098\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2677 - mse: 0.2677 - val_loss: 53.7361 - val_mse: 53.7361\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2339 - mse: 0.2339 - val_loss: 397.8009 - val_mse: 397.8009\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2216 - mse: 0.2216 - val_loss: 27749.2539 - val_mse: 27749.2539\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2035 - mse: 0.2035 - val_loss: 81.5587 - val_mse: 81.5587\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2005 - mse: 0.2005 - val_loss: 4990.8237 - val_mse: 4990.8237\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1996 - mse: 0.1996 - val_loss: 29638.4316 - val_mse: 29638.4316\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2062 - mse: 0.2062 - val_loss: 19.8104 - val_mse: 19.8104\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "40\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6968 - mse: 0.6968 - val_loss: 4145.0586 - val_mse: 4145.0586\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4485 - mse: 0.4485 - val_loss: 381.3526 - val_mse: 381.3526\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3967 - mse: 0.3967 - val_loss: 125.4806 - val_mse: 125.4806\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3410 - mse: 0.3410 - val_loss: 44.8338 - val_mse: 44.8338\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3228 - mse: 0.3228 - val_loss: 37.3305 - val_mse: 37.3305\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2924 - mse: 0.2924 - val_loss: 10753.3438 - val_mse: 10753.3438\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2983 - mse: 0.2983 - val_loss: 2561.9624 - val_mse: 2561.9624\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2692 - mse: 0.2692 - val_loss: 9948.5156 - val_mse: 9948.5156\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2729 - mse: 0.2729 - val_loss: 25.9229 - val_mse: 25.9229\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2488 - mse: 0.2488 - val_loss: 1.9887 - val_mse: 1.9887\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2579 - mse: 0.2579 - val_loss: 35663.8398 - val_mse: 35663.8398\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2359 - mse: 0.2359 - val_loss: 56.8185 - val_mse: 56.8185\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2168 - mse: 0.2168 - val_loss: 191.6963 - val_mse: 191.6963\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2209 - mse: 0.2209 - val_loss: 10629.0947 - val_mse: 10629.0947\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2380 - mse: 0.2380 - val_loss: 2031.1412 - val_mse: 2031.1412\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2023 - mse: 0.2023 - val_loss: 496.7962 - val_mse: 496.7962\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 15500.4502 - val_mse: 15500.4502\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1993 - mse: 0.1993 - val_loss: 1651.4590 - val_mse: 1651.4590\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2056 - mse: 0.2056 - val_loss: 443.8455 - val_mse: 443.8455\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2231 - mse: 0.2231 - val_loss: 1399.7012 - val_mse: 1399.7012\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "41\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.6874 - mse: 0.6874 - val_loss: 4278.8198 - val_mse: 4278.8198\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4528 - mse: 0.4528 - val_loss: 791.3947 - val_mse: 791.3947\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3910 - mse: 0.3910 - val_loss: 432.8675 - val_mse: 432.8675\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3690 - mse: 0.3690 - val_loss: 20.1513 - val_mse: 20.1513\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3582 - mse: 0.3582 - val_loss: 0.6031 - val_mse: 0.6031\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3127 - mse: 0.3127 - val_loss: 28270.1562 - val_mse: 28270.1562\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3103 - mse: 0.3103 - val_loss: 1914.7368 - val_mse: 1914.7368\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2708 - mse: 0.2708 - val_loss: 29316.2695 - val_mse: 29316.2695\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2896 - mse: 0.2896 - val_loss: 8.5658 - val_mse: 8.5658\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2571 - mse: 0.2571 - val_loss: 169.0724 - val_mse: 169.0724\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2480 - mse: 0.2480 - val_loss: 26022.7207 - val_mse: 26022.7207\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2434 - mse: 0.2434 - val_loss: 47.5399 - val_mse: 47.5399\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2215 - mse: 0.2215 - val_loss: 542.1063 - val_mse: 542.1063\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2228 - mse: 0.2228 - val_loss: 30196.1367 - val_mse: 30196.1367\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2406 - mse: 0.2406 - val_loss: 4.7829 - val_mse: 4.7829\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "42\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7100 - mse: 0.7100 - val_loss: 924.0581 - val_mse: 924.0581\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4696 - mse: 0.4696 - val_loss: 1353.7661 - val_mse: 1353.7661\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3886 - mse: 0.3886 - val_loss: 207.6288 - val_mse: 207.6288\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3563 - mse: 0.3563 - val_loss: 691.3967 - val_mse: 691.3967\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3571 - mse: 0.3571 - val_loss: 31.5966 - val_mse: 31.5966\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3080 - mse: 0.3080 - val_loss: 6609.0381 - val_mse: 6609.0381\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2896 - mse: 0.2896 - val_loss: 528.7014 - val_mse: 528.7014\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2567 - mse: 0.2567 - val_loss: 14122.1855 - val_mse: 14122.1855\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2580 - mse: 0.2580 - val_loss: 3.4831 - val_mse: 3.4831\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2461 - mse: 0.2461 - val_loss: 1.5854 - val_mse: 1.5854\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 17971.0059 - val_mse: 17971.0059\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2380 - mse: 0.2380 - val_loss: 50.8275 - val_mse: 50.8275\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2282 - mse: 0.2282 - val_loss: 24045.0820 - val_mse: 24045.0820\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 5719.3291 - val_mse: 5719.3291\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2221 - mse: 0.2221 - val_loss: 8.3299 - val_mse: 8.3299\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2006 - mse: 0.2006 - val_loss: 2.2472 - val_mse: 2.2472\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1817 - mse: 0.1817 - val_loss: 3319.3374 - val_mse: 3319.3374\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2066 - mse: 0.2066 - val_loss: 25091.4004 - val_mse: 25091.4004\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2142 - mse: 0.2142 - val_loss: 332.1703 - val_mse: 332.1703\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2327 - mse: 0.2327 - val_loss: 2311.1252 - val_mse: 2311.1252\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "43\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7411 - mse: 0.7411 - val_loss: 779.5908 - val_mse: 779.5908\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4844 - mse: 0.4844 - val_loss: 63.8350 - val_mse: 63.8350\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4340 - mse: 0.4340 - val_loss: 4750.4751 - val_mse: 4750.4751\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3897 - mse: 0.3897 - val_loss: 1050.3231 - val_mse: 1050.3231\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3798 - mse: 0.3798 - val_loss: 96.4470 - val_mse: 96.4470\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3355 - mse: 0.3355 - val_loss: 2170.1929 - val_mse: 2170.1929\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3262 - mse: 0.3262 - val_loss: 10672.1289 - val_mse: 10672.1289\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2801 - mse: 0.2801 - val_loss: 7030.0015 - val_mse: 7030.0015\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2888 - mse: 0.2888 - val_loss: 361.1352 - val_mse: 361.1352\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2648 - mse: 0.2648 - val_loss: 166.6341 - val_mse: 166.6341\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2533 - mse: 0.2533 - val_loss: 9064.6572 - val_mse: 9064.6572\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2567 - mse: 0.2567 - val_loss: 11.4294 - val_mse: 11.4294\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2358 - mse: 0.2358 - val_loss: 15703.5381 - val_mse: 15703.5381\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2231 - mse: 0.2231 - val_loss: 47962.1406 - val_mse: 47962.1406\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2739 - mse: 0.2739 - val_loss: 218.4643 - val_mse: 218.4643\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1999 - mse: 0.1999 - val_loss: 46.9430 - val_mse: 46.9430\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2107 - mse: 0.2107 - val_loss: 9948.1699 - val_mse: 9948.1699\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1997 - mse: 0.1997 - val_loss: 1887.0221 - val_mse: 1887.0221\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2210 - mse: 0.2210 - val_loss: 0.4027 - val_mse: 0.4027\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2212 - mse: 0.2212 - val_loss: 328.4717 - val_mse: 328.4717\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1750 - mse: 0.1750 - val_loss: 447.0716 - val_mse: 447.0716\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1906 - mse: 0.1906 - val_loss: 120.3255 - val_mse: 120.3255\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1741 - mse: 0.1741 - val_loss: 1347.7062 - val_mse: 1347.7062\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1712 - mse: 0.1712 - val_loss: 4.4955 - val_mse: 4.4955\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1580 - mse: 0.1580 - val_loss: 33.7415 - val_mse: 33.7415\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1697 - mse: 0.1697 - val_loss: 45553.4570 - val_mse: 45553.4570\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1616 - mse: 0.1616 - val_loss: 7.5703 - val_mse: 7.5703\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1754 - mse: 0.1754 - val_loss: 8.7032 - val_mse: 8.7032\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1569 - mse: 0.1569 - val_loss: 3909.1626 - val_mse: 3909.1626\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "44\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6214 - mse: 0.6214 - val_loss: 3859.0410 - val_mse: 3859.0410\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4337 - mse: 0.4337 - val_loss: 8822.5566 - val_mse: 8822.5566\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3606 - mse: 0.3606 - val_loss: 5164.3921 - val_mse: 5164.3921\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3333 - mse: 0.3333 - val_loss: 319.7912 - val_mse: 319.7912\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3224 - mse: 0.3224 - val_loss: 2017.7947 - val_mse: 2017.7947\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2910 - mse: 0.2910 - val_loss: 39722.4609 - val_mse: 39722.4609\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3036 - mse: 0.3036 - val_loss: 63.4561 - val_mse: 63.4561\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2667 - mse: 0.2667 - val_loss: 63241.3359 - val_mse: 63241.3359\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2821 - mse: 0.2821 - val_loss: 1.1659 - val_mse: 1.1659\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2413 - mse: 0.2413 - val_loss: 84.5359 - val_mse: 84.5359\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2331 - mse: 0.2331 - val_loss: 1283.1990 - val_mse: 1283.1990\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2463 - mse: 0.2463 - val_loss: 1.9519 - val_mse: 1.9519\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2133 - mse: 0.2133 - val_loss: 676.9483 - val_mse: 676.9483\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2035 - mse: 0.2035 - val_loss: 11882.3672 - val_mse: 11882.3672\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 196.2905 - val_mse: 196.2905\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1944 - mse: 0.1944 - val_loss: 42.2997 - val_mse: 42.2997\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1892 - mse: 0.1892 - val_loss: 636.2350 - val_mse: 636.2350\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1744 - mse: 0.1744 - val_loss: 3255.0466 - val_mse: 3255.0466\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2120 - mse: 0.2120 - val_loss: 422.2175 - val_mse: 422.2175\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "45\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6303 - mse: 0.6303 - val_loss: 5176.1636 - val_mse: 5176.1636\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4225 - mse: 0.4225 - val_loss: 2072.1206 - val_mse: 2072.1206\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3594 - mse: 0.3594 - val_loss: 448.2298 - val_mse: 448.2298\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3169 - mse: 0.3169 - val_loss: 37.3963 - val_mse: 37.3963\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3158 - mse: 0.3158 - val_loss: 1205.4421 - val_mse: 1205.4421\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2729 - mse: 0.2729 - val_loss: 1580.2958 - val_mse: 1580.2958\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2530 - mse: 0.2530 - val_loss: 1.0338 - val_mse: 1.0338\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2532 - mse: 0.2532 - val_loss: 3485.4478 - val_mse: 3485.4478\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2551 - mse: 0.2551 - val_loss: 29.0975 - val_mse: 29.0975\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2776 - mse: 0.2776 - val_loss: 310.0084 - val_mse: 310.0084\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 17064.8164 - val_mse: 17064.8164\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2044 - mse: 0.2044 - val_loss: 172.1057 - val_mse: 172.1057\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2082 - mse: 0.2082 - val_loss: 842.1583 - val_mse: 842.1583\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2170 - mse: 0.2170 - val_loss: 14505.0254 - val_mse: 14505.0254\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.6408 - val_mse: 0.6408\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1866 - mse: 0.1866 - val_loss: 53.1086 - val_mse: 53.1086\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1871 - mse: 0.1871 - val_loss: 17.0162 - val_mse: 17.0162\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1733 - mse: 0.1733 - val_loss: 8178.4688 - val_mse: 8178.4688\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2042 - mse: 0.2042 - val_loss: 1006.4916 - val_mse: 1006.4916\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2143 - mse: 0.2143 - val_loss: 4064.1826 - val_mse: 4064.1826\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 2116.8706 - val_mse: 2116.8706\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1745 - mse: 0.1745 - val_loss: 2543.2073 - val_mse: 2543.2073\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1522 - mse: 0.1522 - val_loss: 1149.7921 - val_mse: 1149.7921\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1539 - mse: 0.1539 - val_loss: 18.4715 - val_mse: 18.4715\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1586 - mse: 0.1586 - val_loss: 11.2418 - val_mse: 11.2418\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "46\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.6811 - mse: 0.6811 - val_loss: 3916.6196 - val_mse: 3916.6196\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4525 - mse: 0.4525 - val_loss: 3641.2100 - val_mse: 3641.2100\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3676 - mse: 0.3676 - val_loss: 1947.3751 - val_mse: 1947.3751\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3521 - mse: 0.3521 - val_loss: 36.5910 - val_mse: 36.5910\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3317 - mse: 0.3317 - val_loss: 8.0065 - val_mse: 8.0065\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3038 - mse: 0.3038 - val_loss: 38778.5469 - val_mse: 38778.5469\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2839 - mse: 0.2839 - val_loss: 5.3587 - val_mse: 5.3587\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2852 - mse: 0.2852 - val_loss: 12399.9580 - val_mse: 12399.9580\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2528 - mse: 0.2528 - val_loss: 1.0501 - val_mse: 1.0501\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2435 - mse: 0.2435 - val_loss: 18.0822 - val_mse: 18.0822\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2454 - mse: 0.2454 - val_loss: 31919.6543 - val_mse: 31919.6543\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2307 - mse: 0.2307 - val_loss: 23.7926 - val_mse: 23.7926\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2334 - mse: 0.2334 - val_loss: 22062.2598 - val_mse: 22062.2598\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2292 - mse: 0.2292 - val_loss: 18237.8535 - val_mse: 18237.8535\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2410 - mse: 0.2410 - val_loss: 17.0793 - val_mse: 17.0793\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2053 - mse: 0.2053 - val_loss: 44.6372 - val_mse: 44.6372\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2124 - mse: 0.2124 - val_loss: 3777.5076 - val_mse: 3777.5076\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1827 - mse: 0.1827 - val_loss: 8560.3232 - val_mse: 8560.3232\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1917 - mse: 0.1917 - val_loss: 1571.1536 - val_mse: 1571.1536\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "47\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.6700 - mse: 0.6700 - val_loss: 3462.7351 - val_mse: 3462.7351\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4153 - mse: 0.4153 - val_loss: 3882.8608 - val_mse: 3882.8608\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3666 - mse: 0.3666 - val_loss: 10295.0996 - val_mse: 10295.0996\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3334 - mse: 0.3334 - val_loss: 385.9024 - val_mse: 385.9024\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3166 - mse: 0.3166 - val_loss: 24.9008 - val_mse: 24.9008\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2819 - mse: 0.2819 - val_loss: 22861.0430 - val_mse: 22861.0430\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2805 - mse: 0.2805 - val_loss: 127.3588 - val_mse: 127.3588\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2658 - mse: 0.2658 - val_loss: 7981.9009 - val_mse: 7981.9009\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2642 - mse: 0.2642 - val_loss: 36.4097 - val_mse: 36.4097\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2508 - mse: 0.2508 - val_loss: 131.6231 - val_mse: 131.6231\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 52115.5742 - val_mse: 52115.5742\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2146 - mse: 0.2146 - val_loss: 76.2159 - val_mse: 76.2159\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2163 - mse: 0.2163 - val_loss: 1510.4180 - val_mse: 1510.4180\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2232 - mse: 0.2232 - val_loss: 24193.4004 - val_mse: 24193.4004\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 243.2315 - val_mse: 243.2315\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "48\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.7230 - mse: 0.7230 - val_loss: 388.3080 - val_mse: 388.3080\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4652 - mse: 0.4652 - val_loss: 188.1703 - val_mse: 188.1703\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4038 - mse: 0.4038 - val_loss: 3137.3708 - val_mse: 3137.3708\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3417 - mse: 0.3417 - val_loss: 108.0737 - val_mse: 108.0737\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3208 - mse: 0.3208 - val_loss: 60.8908 - val_mse: 60.8908\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3086 - mse: 0.3086 - val_loss: 2818.1992 - val_mse: 2818.1992\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2990 - mse: 0.2990 - val_loss: 1330.1893 - val_mse: 1330.1893\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2736 - mse: 0.2736 - val_loss: 12743.9990 - val_mse: 12743.9990\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2644 - mse: 0.2644 - val_loss: 138.0005 - val_mse: 138.0005\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2347 - mse: 0.2347 - val_loss: 515.5477 - val_mse: 515.5477\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2299 - mse: 0.2299 - val_loss: 19621.1172 - val_mse: 19621.1172\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2409 - mse: 0.2409 - val_loss: 151.0468 - val_mse: 151.0468\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2391 - mse: 0.2391 - val_loss: 38013.4531 - val_mse: 38013.4531\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2191 - mse: 0.2191 - val_loss: 852.9996 - val_mse: 852.9996\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2323 - mse: 0.2323 - val_loss: 1645.2183 - val_mse: 1645.2183\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "49\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6409 - mse: 0.6409 - val_loss: 8694.9277 - val_mse: 8694.9277\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4153 - mse: 0.4153 - val_loss: 2437.8972 - val_mse: 2437.8972\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3675 - mse: 0.3675 - val_loss: 1339.3608 - val_mse: 1339.3608\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3445 - mse: 0.3445 - val_loss: 12.8023 - val_mse: 12.8023\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3145 - mse: 0.3145 - val_loss: 2.2888 - val_mse: 2.2888\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2813 - mse: 0.2813 - val_loss: 17972.9766 - val_mse: 17972.9766\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2923 - mse: 0.2923 - val_loss: 1507.2283 - val_mse: 1507.2283\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2612 - mse: 0.2612 - val_loss: 14465.1035 - val_mse: 14465.1035\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2565 - mse: 0.2565 - val_loss: 1.0489 - val_mse: 1.0489\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2757 - mse: 0.2757 - val_loss: 2.7096 - val_mse: 2.7096\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2349 - mse: 0.2349 - val_loss: 4583.3696 - val_mse: 4583.3696\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2232 - mse: 0.2232 - val_loss: 2.7820 - val_mse: 2.7820\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2063 - mse: 0.2063 - val_loss: 1163.6018 - val_mse: 1163.6018\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2060 - mse: 0.2060 - val_loss: 35607.6094 - val_mse: 35607.6094\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2004 - mse: 0.2004 - val_loss: 191.5390 - val_mse: 191.5390\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1872 - mse: 0.1872 - val_loss: 124.1564 - val_mse: 124.1564\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1919 - mse: 0.1919 - val_loss: 2177.9941 - val_mse: 2177.9941\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1765 - mse: 0.1765 - val_loss: 21538.4453 - val_mse: 21538.4453\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2035 - mse: 0.2035 - val_loss: 6900.1973 - val_mse: 6900.1973\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "50\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6324 - mse: 0.6324 - val_loss: 382.1300 - val_mse: 382.1300\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4492 - mse: 0.4492 - val_loss: 2180.4255 - val_mse: 2180.4255\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3724 - mse: 0.3724 - val_loss: 579.7586 - val_mse: 579.7586\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3363 - mse: 0.3363 - val_loss: 90.7899 - val_mse: 90.7899\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3170 - mse: 0.3170 - val_loss: 147.1336 - val_mse: 147.1336\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2918 - mse: 0.2918 - val_loss: 31924.1855 - val_mse: 31924.1855\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2953 - mse: 0.2953 - val_loss: 171.5718 - val_mse: 171.5718\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2633 - mse: 0.2633 - val_loss: 25076.6465 - val_mse: 25076.6465\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2709 - mse: 0.2709 - val_loss: 1.7035 - val_mse: 1.7035\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2640 - mse: 0.2640 - val_loss: 1449.2625 - val_mse: 1449.2625\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2313 - mse: 0.2313 - val_loss: 34382.9258 - val_mse: 34382.9258\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 389.7392 - val_mse: 389.7392\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2116 - mse: 0.2116 - val_loss: 10195.1055 - val_mse: 10195.1055\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1969 - mse: 0.1969 - val_loss: 11007.4688 - val_mse: 11007.4688\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2056 - mse: 0.2056 - val_loss: 46.2929 - val_mse: 46.2929\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1939 - mse: 0.1939 - val_loss: 302.3092 - val_mse: 302.3092\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2034 - mse: 0.2034 - val_loss: 5233.3003 - val_mse: 5233.3003\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1838 - mse: 0.1838 - val_loss: 4615.6689 - val_mse: 4615.6689\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1834 - mse: 0.1834 - val_loss: 1653.0404 - val_mse: 1653.0404\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "51\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6386 - mse: 0.6386 - val_loss: 9379.1016 - val_mse: 9379.1016\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4373 - mse: 0.4373 - val_loss: 7561.5781 - val_mse: 7561.5781\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3733 - mse: 0.3733 - val_loss: 6075.0942 - val_mse: 6075.0942\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3412 - mse: 0.3412 - val_loss: 0.8222 - val_mse: 0.8222\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3253 - mse: 0.3253 - val_loss: 143.6266 - val_mse: 143.6266\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2947 - mse: 0.2947 - val_loss: 37218.0430 - val_mse: 37218.0430\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3020 - mse: 0.3020 - val_loss: 1905.9698 - val_mse: 1905.9698\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2582 - mse: 0.2582 - val_loss: 4460.1743 - val_mse: 4460.1743\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2551 - mse: 0.2551 - val_loss: 104.2038 - val_mse: 104.2038\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2485 - mse: 0.2485 - val_loss: 12.7871 - val_mse: 12.7871\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2204 - mse: 0.2204 - val_loss: 73969.4531 - val_mse: 73969.4531\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2232 - mse: 0.2232 - val_loss: 1.1664 - val_mse: 1.1664\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2031 - mse: 0.2031 - val_loss: 20216.9473 - val_mse: 20216.9473\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1924 - mse: 0.1924 - val_loss: 1657.6219 - val_mse: 1657.6219\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "52\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7162 - mse: 0.7162 - val_loss: 7952.5635 - val_mse: 7952.5635\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4607 - mse: 0.4607 - val_loss: 88.3545 - val_mse: 88.3545\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 197.4977 - val_mse: 197.4977\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3505 - mse: 0.3505 - val_loss: 303.9848 - val_mse: 303.9848\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3317 - mse: 0.3317 - val_loss: 45.8137 - val_mse: 45.8137\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3064 - mse: 0.3064 - val_loss: 32702.9609 - val_mse: 32702.9609\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2829 - mse: 0.2829 - val_loss: 4123.3442 - val_mse: 4123.3442\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2700 - mse: 0.2700 - val_loss: 13573.5254 - val_mse: 13573.5254\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2850 - mse: 0.2850 - val_loss: 10.1921 - val_mse: 10.1921\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2482 - mse: 0.2482 - val_loss: 3473.8892 - val_mse: 3473.8892\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2299 - mse: 0.2299 - val_loss: 83157.7266 - val_mse: 83157.7266\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2059 - mse: 0.2059 - val_loss: 38.2120 - val_mse: 38.2120\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1965 - mse: 0.1965 - val_loss: 63.2880 - val_mse: 63.2880\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1989 - mse: 0.1989 - val_loss: 13214.5898 - val_mse: 13214.5898\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2085 - mse: 0.2085 - val_loss: 1.1309 - val_mse: 1.1309\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1839 - mse: 0.1839 - val_loss: 35.8351 - val_mse: 35.8351\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1710 - mse: 0.1710 - val_loss: 25.7367 - val_mse: 25.7367\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1842 - mse: 0.1842 - val_loss: 134963.5625 - val_mse: 134963.5625\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 482.4362 - val_mse: 482.4362\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1998 - mse: 0.1998 - val_loss: 86.4058 - val_mse: 86.4058\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1614 - mse: 0.1614 - val_loss: 4267.4341 - val_mse: 4267.4341\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1714 - mse: 0.1714 - val_loss: 9.8156 - val_mse: 9.8156\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1483 - mse: 0.1483 - val_loss: 338.7337 - val_mse: 338.7337\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1520 - mse: 0.1520 - val_loss: 44.6903 - val_mse: 44.6903\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2075 - mse: 0.2075 - val_loss: 31231.1738 - val_mse: 31231.1738\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "53\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 6ms/step - loss: 0.6244 - mse: 0.6244 - val_loss: 2358.9041 - val_mse: 2358.9041\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4300 - mse: 0.4300 - val_loss: 1154.8992 - val_mse: 1154.8992\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3423 - mse: 0.3423 - val_loss: 435.2429 - val_mse: 435.2429\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3287 - mse: 0.3287 - val_loss: 227.2239 - val_mse: 227.2239\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2866 - mse: 0.2866 - val_loss: 78.8625 - val_mse: 78.8625\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2743 - mse: 0.2743 - val_loss: 10619.6152 - val_mse: 10619.6152\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2703 - mse: 0.2703 - val_loss: 1447.9487 - val_mse: 1447.9487\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2332 - mse: 0.2332 - val_loss: 22055.3965 - val_mse: 22055.3965\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2589 - mse: 0.2589 - val_loss: 70.2931 - val_mse: 70.2931\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2242 - mse: 0.2242 - val_loss: 126.3152 - val_mse: 126.3152\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2299 - mse: 0.2299 - val_loss: 87946.0938 - val_mse: 87946.0938\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2327 - mse: 0.2327 - val_loss: 4.4584 - val_mse: 4.4584\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 18.6807 - val_mse: 18.6807\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1752 - mse: 0.1752 - val_loss: 2976.4744 - val_mse: 2976.4744\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2011 - mse: 0.2011 - val_loss: 45.5765 - val_mse: 45.5765\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1923 - mse: 0.1923 - val_loss: 21.5727 - val_mse: 21.5727\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1915 - mse: 0.1915 - val_loss: 5103.2241 - val_mse: 5103.2241\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1767 - mse: 0.1767 - val_loss: 9977.1328 - val_mse: 9977.1328\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1865 - mse: 0.1865 - val_loss: 3925.3542 - val_mse: 3925.3542\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1899 - mse: 0.1899 - val_loss: 137.4213 - val_mse: 137.4213\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1486 - mse: 0.1486 - val_loss: 518.3495 - val_mse: 518.3495\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1659 - mse: 0.1659 - val_loss: 20064.0254 - val_mse: 20064.0254\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "54\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7296 - mse: 0.7296 - val_loss: 2012.2695 - val_mse: 2012.2695\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4583 - mse: 0.4583 - val_loss: 2290.2185 - val_mse: 2290.2185\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3805 - mse: 0.3805 - val_loss: 675.5164 - val_mse: 675.5164\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3282 - mse: 0.3282 - val_loss: 13.0258 - val_mse: 13.0258\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3010 - mse: 0.3010 - val_loss: 6.2368 - val_mse: 6.2368\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2915 - mse: 0.2915 - val_loss: 37397.5898 - val_mse: 37397.5898\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2770 - mse: 0.2770 - val_loss: 1738.9218 - val_mse: 1738.9218\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2693 - mse: 0.2693 - val_loss: 12276.8730 - val_mse: 12276.8730\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2534 - mse: 0.2534 - val_loss: 13.2453 - val_mse: 13.2453\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2593 - mse: 0.2593 - val_loss: 238.6231 - val_mse: 238.6231\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2235 - mse: 0.2235 - val_loss: 59985.0195 - val_mse: 59985.0195\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2303 - mse: 0.2303 - val_loss: 64.8817 - val_mse: 64.8817\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2316 - mse: 0.2316 - val_loss: 23157.5586 - val_mse: 23157.5586\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2016 - mse: 0.2016 - val_loss: 11688.2217 - val_mse: 11688.2217\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2099 - mse: 0.2099 - val_loss: 157.8625 - val_mse: 157.8625\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "55\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6533 - mse: 0.6533 - val_loss: 8320.2471 - val_mse: 8320.2471\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4017 - mse: 0.4017 - val_loss: 3556.9595 - val_mse: 3556.9595\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3596 - mse: 0.3596 - val_loss: 17469.9512 - val_mse: 17469.9512\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3018 - mse: 0.3018 - val_loss: 31.6720 - val_mse: 31.6720\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2737 - mse: 0.2737 - val_loss: 171.8006 - val_mse: 171.8006\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2645 - mse: 0.2645 - val_loss: 36597.7109 - val_mse: 36597.7109\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2812 - mse: 0.2812 - val_loss: 6.7980 - val_mse: 6.7980\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2417 - mse: 0.2417 - val_loss: 10458.4531 - val_mse: 10458.4531\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2361 - mse: 0.2361 - val_loss: 8950.2607 - val_mse: 8950.2607\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2168 - mse: 0.2168 - val_loss: 575.3323 - val_mse: 575.3323\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2130 - mse: 0.2130 - val_loss: 91342.7734 - val_mse: 91342.7734\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2232 - mse: 0.2232 - val_loss: 675.1362 - val_mse: 675.1362\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1909 - mse: 0.1909 - val_loss: 7012.9795 - val_mse: 7012.9795\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1773 - mse: 0.1773 - val_loss: 11993.8496 - val_mse: 11993.8496\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1820 - mse: 0.1820 - val_loss: 3.2500 - val_mse: 3.2500\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1829 - mse: 0.1829 - val_loss: 3227.5640 - val_mse: 3227.5640\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1770 - mse: 0.1770 - val_loss: 20777.6953 - val_mse: 20777.6953\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1744 - mse: 0.1744 - val_loss: 483.3903 - val_mse: 483.3903\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1757 - mse: 0.1757 - val_loss: 866.1229 - val_mse: 866.1229\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1747 - mse: 0.1747 - val_loss: 129.8159 - val_mse: 129.8159\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1652 - mse: 0.1652 - val_loss: 4.4123 - val_mse: 4.4123\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1671 - mse: 0.1671 - val_loss: 9721.3037 - val_mse: 9721.3037\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1402 - mse: 0.1402 - val_loss: 3264.2656 - val_mse: 3264.2656\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1497 - mse: 0.1497 - val_loss: 106.3808 - val_mse: 106.3808\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1512 - mse: 0.1512 - val_loss: 16332.6504 - val_mse: 16332.6504\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "56\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6432 - mse: 0.6432 - val_loss: 4429.6753 - val_mse: 4429.6753\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4238 - mse: 0.4238 - val_loss: 95.1554 - val_mse: 95.1554\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3595 - mse: 0.3595 - val_loss: 2424.0530 - val_mse: 2424.0530\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3167 - mse: 0.3167 - val_loss: 5.8098 - val_mse: 5.8098\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3042 - mse: 0.3042 - val_loss: 56.1767 - val_mse: 56.1767\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2753 - mse: 0.2753 - val_loss: 24548.4336 - val_mse: 24548.4336\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2730 - mse: 0.2730 - val_loss: 0.5508 - val_mse: 0.5508\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2533 - mse: 0.2533 - val_loss: 12336.3828 - val_mse: 12336.3828\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2620 - mse: 0.2620 - val_loss: 1.8845 - val_mse: 1.8845\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2325 - mse: 0.2325 - val_loss: 4407.5669 - val_mse: 4407.5669\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2207 - mse: 0.2207 - val_loss: 29067.6543 - val_mse: 29067.6543\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2065 - mse: 0.2065 - val_loss: 1.3794 - val_mse: 1.3794\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1975 - mse: 0.1975 - val_loss: 14687.7695 - val_mse: 14687.7695\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1882 - mse: 0.1882 - val_loss: 6856.7339 - val_mse: 6856.7339\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2043 - mse: 0.2043 - val_loss: 3.2355 - val_mse: 3.2355\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1867 - mse: 0.1867 - val_loss: 3.5495 - val_mse: 3.5495\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1738 - mse: 0.1738 - val_loss: 4270.9531 - val_mse: 4270.9531\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "57\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6891 - mse: 0.6891 - val_loss: 1943.4800 - val_mse: 1943.4800\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4304 - mse: 0.4304 - val_loss: 4005.3564 - val_mse: 4005.3564\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3507 - mse: 0.3507 - val_loss: 1087.1587 - val_mse: 1087.1587\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3024 - mse: 0.3024 - val_loss: 2.1237 - val_mse: 2.1237\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2825 - mse: 0.2825 - val_loss: 234.1914 - val_mse: 234.1914\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2675 - mse: 0.2675 - val_loss: 11252.8379 - val_mse: 11252.8379\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2592 - mse: 0.2592 - val_loss: 10.5522 - val_mse: 10.5522\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2353 - mse: 0.2353 - val_loss: 2126.2185 - val_mse: 2126.2185\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2614 - mse: 0.2614 - val_loss: 164.4155 - val_mse: 164.4155\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1944 - mse: 0.1944 - val_loss: 1641.5885 - val_mse: 1641.5885\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2062 - mse: 0.2062 - val_loss: 16792.9297 - val_mse: 16792.9297\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2049 - mse: 0.2049 - val_loss: 85.1316 - val_mse: 85.1316\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1974 - mse: 0.1974 - val_loss: 12038.7480 - val_mse: 12038.7480\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1918 - mse: 0.1918 - val_loss: 14224.3809 - val_mse: 14224.3809\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "58\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6351 - mse: 0.6351 - val_loss: 608.7281 - val_mse: 608.7281\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4319 - mse: 0.4319 - val_loss: 1227.8113 - val_mse: 1227.8113\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3646 - mse: 0.3646 - val_loss: 1552.4159 - val_mse: 1552.4159\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3082 - mse: 0.3082 - val_loss: 26.5180 - val_mse: 26.5180\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2760 - mse: 0.2760 - val_loss: 348.0081 - val_mse: 348.0081\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2498 - mse: 0.2498 - val_loss: 27895.7422 - val_mse: 27895.7422\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2563 - mse: 0.2563 - val_loss: 1.6833 - val_mse: 1.6833\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2315 - mse: 0.2315 - val_loss: 2386.2273 - val_mse: 2386.2273\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2229 - mse: 0.2229 - val_loss: 12203.5000 - val_mse: 12203.5000\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1866 - mse: 0.1866 - val_loss: 3095.8696 - val_mse: 3095.8696\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2024 - mse: 0.2024 - val_loss: 6472.0620 - val_mse: 6472.0620\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2006 - mse: 0.2006 - val_loss: 1.2914 - val_mse: 1.2914\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1918 - mse: 0.1918 - val_loss: 4274.8569 - val_mse: 4274.8569\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1841 - mse: 0.1841 - val_loss: 68.4452 - val_mse: 68.4452\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1871 - mse: 0.1871 - val_loss: 224.7189 - val_mse: 224.7189\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1816 - mse: 0.1816 - val_loss: 15.8207 - val_mse: 15.8207\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1561 - mse: 0.1561 - val_loss: 536.5167 - val_mse: 536.5167\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1630 - mse: 0.1630 - val_loss: 37762.8359 - val_mse: 37762.8359\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1992 - mse: 0.1992 - val_loss: 26.7577 - val_mse: 26.7577\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1649 - mse: 0.1649 - val_loss: 332.4831 - val_mse: 332.4831\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1513 - mse: 0.1513 - val_loss: 2037.2931 - val_mse: 2037.2931\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1642 - mse: 0.1642 - val_loss: 1984.5610 - val_mse: 1984.5610\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "59\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6821 - mse: 0.6821 - val_loss: 3476.0049 - val_mse: 3476.0049\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4270 - mse: 0.4270 - val_loss: 280.3404 - val_mse: 280.3404\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3523 - mse: 0.3523 - val_loss: 18473.3242 - val_mse: 18473.3242\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3182 - mse: 0.3182 - val_loss: 7.3056 - val_mse: 7.3056\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2844 - mse: 0.2844 - val_loss: 4244.0117 - val_mse: 4244.0117\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2610 - mse: 0.2610 - val_loss: 14624.7764 - val_mse: 14624.7764\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2731 - mse: 0.2731 - val_loss: 18.6965 - val_mse: 18.6965\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 5543.7446 - val_mse: 5543.7446\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2218 - mse: 0.2218 - val_loss: 5065.5430 - val_mse: 5065.5430\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2066 - mse: 0.2066 - val_loss: 11261.5850 - val_mse: 11261.5850\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 36220.7617 - val_mse: 36220.7617\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1980 - mse: 0.1980 - val_loss: 8.1940 - val_mse: 8.1940\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1905 - mse: 0.1905 - val_loss: 4643.2324 - val_mse: 4643.2324\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1905 - mse: 0.1905 - val_loss: 6394.4526 - val_mse: 6394.4526\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "60\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6339 - mse: 0.6339 - val_loss: 946.5954 - val_mse: 946.5954\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3870 - mse: 0.3870 - val_loss: 2824.7595 - val_mse: 2824.7595\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3334 - mse: 0.3334 - val_loss: 5150.1489 - val_mse: 5150.1489\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2821 - mse: 0.2821 - val_loss: 4.1049 - val_mse: 4.1049\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2705 - mse: 0.2705 - val_loss: 5251.8325 - val_mse: 5251.8325\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2419 - mse: 0.2419 - val_loss: 29981.7910 - val_mse: 29981.7910\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2514 - mse: 0.2514 - val_loss: 15.6693 - val_mse: 15.6693\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2049 - mse: 0.2049 - val_loss: 7562.0381 - val_mse: 7562.0381\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 38807.2734 - val_mse: 38807.2734\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1816 - mse: 0.1816 - val_loss: 88.5359 - val_mse: 88.5359\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1949 - mse: 0.1949 - val_loss: 43801.4062 - val_mse: 43801.4062\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 3.6324 - val_mse: 3.6324\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1824 - mse: 0.1824 - val_loss: 33990.8242 - val_mse: 33990.8242\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1934 - mse: 0.1934 - val_loss: 103281.6719 - val_mse: 103281.6719\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2141 - mse: 0.2141 - val_loss: 3.0053 - val_mse: 3.0053\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1679 - mse: 0.1679 - val_loss: 1830.3000 - val_mse: 1830.3000\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1594 - mse: 0.1594 - val_loss: 6.2878 - val_mse: 6.2878\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1513 - mse: 0.1513 - val_loss: 21.9451 - val_mse: 21.9451\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1604 - mse: 0.1604 - val_loss: 7.8842 - val_mse: 7.8842\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1736 - mse: 0.1736 - val_loss: 3495.8174 - val_mse: 3495.8174\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1472 - mse: 0.1472 - val_loss: 4.7236 - val_mse: 4.7236\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1697 - mse: 0.1697 - val_loss: 31.8693 - val_mse: 31.8693\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1364 - mse: 0.1364 - val_loss: 6312.2310 - val_mse: 6312.2310\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1664 - mse: 0.1664 - val_loss: 799.7452 - val_mse: 799.7452\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1642 - mse: 0.1642 - val_loss: 6482.4590 - val_mse: 6482.4590\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "61\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6468 - mse: 0.6468 - val_loss: 1663.8872 - val_mse: 1663.8872\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3938 - mse: 0.3938 - val_loss: 1310.1799 - val_mse: 1310.1799\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3337 - mse: 0.3337 - val_loss: 2843.4048 - val_mse: 2843.4048\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2921 - mse: 0.2921 - val_loss: 24.7271 - val_mse: 24.7271\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2732 - mse: 0.2732 - val_loss: 1262.9279 - val_mse: 1262.9279\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2578 - mse: 0.2578 - val_loss: 20339.0137 - val_mse: 20339.0137\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2557 - mse: 0.2557 - val_loss: 339.0409 - val_mse: 339.0409\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2235 - mse: 0.2235 - val_loss: 8498.4111 - val_mse: 8498.4111\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2450 - mse: 0.2450 - val_loss: 41.3797 - val_mse: 41.3797\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1855 - mse: 0.1855 - val_loss: 4148.3325 - val_mse: 4148.3325\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1937 - mse: 0.1937 - val_loss: 14029.6729 - val_mse: 14029.6729\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1946 - mse: 0.1946 - val_loss: 4.6457 - val_mse: 4.6457\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1836 - mse: 0.1836 - val_loss: 2240.5562 - val_mse: 2240.5562\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1857 - mse: 0.1857 - val_loss: 17986.3496 - val_mse: 17986.3496\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1863 - mse: 0.1863 - val_loss: 134.2543 - val_mse: 134.2543\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1596 - mse: 0.1596 - val_loss: 19.9175 - val_mse: 19.9175\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1576 - mse: 0.1576 - val_loss: 301.9629 - val_mse: 301.9629\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1731 - mse: 0.1731 - val_loss: 59693.0234 - val_mse: 59693.0234\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1739 - mse: 0.1739 - val_loss: 4156.3096 - val_mse: 4156.3096\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1791 - mse: 0.1791 - val_loss: 2.3845 - val_mse: 2.3845\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1436 - mse: 0.1436 - val_loss: 57.3276 - val_mse: 57.3276\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1887 - mse: 0.1887 - val_loss: 19.8832 - val_mse: 19.8832\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1496 - mse: 0.1496 - val_loss: 17558.5508 - val_mse: 17558.5508\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 2.7295 - val_mse: 2.7295\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1358 - mse: 0.1358 - val_loss: 274.2552 - val_mse: 274.2552\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1600 - mse: 0.1600 - val_loss: 36131.6914 - val_mse: 36131.6914\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1328 - mse: 0.1328 - val_loss: 1341.9674 - val_mse: 1341.9674\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1485 - mse: 0.1485 - val_loss: 33.4582 - val_mse: 33.4582\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1292 - mse: 0.1292 - val_loss: 30.1746 - val_mse: 30.1746\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1344 - mse: 0.1344 - val_loss: 3279.5259 - val_mse: 3279.5259\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "62\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7429 - mse: 0.7429 - val_loss: 16.5684 - val_mse: 16.5684\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4300 - mse: 0.4300 - val_loss: 1345.2935 - val_mse: 1345.2935\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3549 - mse: 0.3549 - val_loss: 2865.6899 - val_mse: 2865.6899\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3014 - mse: 0.3014 - val_loss: 280.1846 - val_mse: 280.1846\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2887 - mse: 0.2887 - val_loss: 1452.3206 - val_mse: 1452.3206\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2572 - mse: 0.2572 - val_loss: 35106.2422 - val_mse: 35106.2422\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2626 - mse: 0.2626 - val_loss: 1427.7700 - val_mse: 1427.7700\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2199 - mse: 0.2199 - val_loss: 9358.8604 - val_mse: 9358.8604\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 1886.4935 - val_mse: 1886.4935\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2092 - mse: 0.2092 - val_loss: 1912.1971 - val_mse: 1912.1971\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2106 - mse: 0.2106 - val_loss: 25801.2461 - val_mse: 25801.2461\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "63\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6581 - mse: 0.6581 - val_loss: 4193.2495 - val_mse: 4193.2495\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3872 - mse: 0.3872 - val_loss: 2517.0330 - val_mse: 2517.0330\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3344 - mse: 0.3344 - val_loss: 625.0068 - val_mse: 625.0068\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2851 - mse: 0.2851 - val_loss: 15.8765 - val_mse: 15.8765\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2701 - mse: 0.2701 - val_loss: 119.2439 - val_mse: 119.2439\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2637 - mse: 0.2637 - val_loss: 19800.1172 - val_mse: 19800.1172\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2564 - mse: 0.2564 - val_loss: 341.0078 - val_mse: 341.0078\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 1800.2727 - val_mse: 1800.2727\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 4701.2852 - val_mse: 4701.2852\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1919 - mse: 0.1919 - val_loss: 53.8492 - val_mse: 53.8492\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2002 - mse: 0.2002 - val_loss: 38068.6719 - val_mse: 38068.6719\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1914 - mse: 0.1914 - val_loss: 40.5735 - val_mse: 40.5735\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1867 - mse: 0.1867 - val_loss: 4088.9897 - val_mse: 4088.9897\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1753 - mse: 0.1753 - val_loss: 10275.6084 - val_mse: 10275.6084\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "64\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6393 - mse: 0.6393 - val_loss: 3161.2061 - val_mse: 3161.2061\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3767 - mse: 0.3767 - val_loss: 4321.7793 - val_mse: 4321.7793\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3315 - mse: 0.3315 - val_loss: 10485.6494 - val_mse: 10485.6494\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2933 - mse: 0.2933 - val_loss: 6.4733 - val_mse: 6.4733\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2703 - mse: 0.2703 - val_loss: 740.7056 - val_mse: 740.7056\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2567 - mse: 0.2567 - val_loss: 2653.3230 - val_mse: 2653.3230\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2532 - mse: 0.2532 - val_loss: 325.9046 - val_mse: 325.9046\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2134 - mse: 0.2134 - val_loss: 2061.0305 - val_mse: 2061.0305\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2295 - mse: 0.2295 - val_loss: 323.6039 - val_mse: 323.6039\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1981 - mse: 0.1981 - val_loss: 236.5394 - val_mse: 236.5394\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2011 - mse: 0.2011 - val_loss: 13915.4092 - val_mse: 13915.4092\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1896 - mse: 0.1896 - val_loss: 56.4841 - val_mse: 56.4841\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1897 - mse: 0.1897 - val_loss: 1665.8733 - val_mse: 1665.8733\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1850 - mse: 0.1850 - val_loss: 232.9333 - val_mse: 232.9333\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "65\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7689 - mse: 0.7689 - val_loss: 949.7296 - val_mse: 949.7296\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4546 - mse: 0.4546 - val_loss: 4599.2319 - val_mse: 4599.2319\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3422 - mse: 0.3422 - val_loss: 2324.4204 - val_mse: 2324.4204\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3186 - mse: 0.3186 - val_loss: 7.4883 - val_mse: 7.4883\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2906 - mse: 0.2906 - val_loss: 198.7891 - val_mse: 198.7891\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2645 - mse: 0.2645 - val_loss: 10090.7891 - val_mse: 10090.7891\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2715 - mse: 0.2715 - val_loss: 41.4399 - val_mse: 41.4399\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2337 - mse: 0.2337 - val_loss: 109.4749 - val_mse: 109.4749\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2643 - mse: 0.2643 - val_loss: 1733.3616 - val_mse: 1733.3616\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1986 - mse: 0.1986 - val_loss: 3740.4990 - val_mse: 3740.4990\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2116 - mse: 0.2116 - val_loss: 30145.7637 - val_mse: 30145.7637\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1891 - mse: 0.1891 - val_loss: 1.0912 - val_mse: 1.0912\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1866 - mse: 0.1866 - val_loss: 1492.6461 - val_mse: 1492.6461\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1889 - mse: 0.1889 - val_loss: 632.3936 - val_mse: 632.3936\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1981 - mse: 0.1981 - val_loss: 4.3209 - val_mse: 4.3209\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1712 - mse: 0.1712 - val_loss: 1.0001 - val_mse: 1.0001\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1524 - mse: 0.1524 - val_loss: 3.2134 - val_mse: 3.2134\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1675 - mse: 0.1675 - val_loss: 4645.9980 - val_mse: 4645.9980\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2013 - mse: 0.2013 - val_loss: 33.8246 - val_mse: 33.8246\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2061 - mse: 0.2061 - val_loss: 3042.8132 - val_mse: 3042.8132\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1583 - mse: 0.1583 - val_loss: 4.0411 - val_mse: 4.0411\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1521 - mse: 0.1521 - val_loss: 1593.5754 - val_mse: 1593.5754\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1309 - mse: 0.1309 - val_loss: 221.4971 - val_mse: 221.4971\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1343 - mse: 0.1343 - val_loss: 0.9073 - val_mse: 0.9073\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1470 - mse: 0.1470 - val_loss: 7264.6025 - val_mse: 7264.6025\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1490 - mse: 0.1490 - val_loss: 6453.0649 - val_mse: 6453.0649\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1295 - mse: 0.1295 - val_loss: 776.9922 - val_mse: 776.9922\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1406 - mse: 0.1406 - val_loss: 7.4237 - val_mse: 7.4237\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1295 - mse: 0.1295 - val_loss: 31.0194 - val_mse: 31.0194\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1326 - mse: 0.1326 - val_loss: 3122.6951 - val_mse: 3122.6951\n",
      "Epoch 31/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1368 - mse: 0.1368 - val_loss: 17587.8926 - val_mse: 17587.8926\n",
      "Epoch 32/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1324 - mse: 0.1324 - val_loss: 17897.9551 - val_mse: 17897.9551\n",
      "Epoch 33/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1412 - mse: 0.1412 - val_loss: 829.5157 - val_mse: 829.5157\n",
      "Epoch 34/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 2063.4229 - val_mse: 2063.4229\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "66\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6851 - mse: 0.6851 - val_loss: 820.4962 - val_mse: 820.4962\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4077 - mse: 0.4077 - val_loss: 534.1196 - val_mse: 534.1196\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3319 - mse: 0.3319 - val_loss: 100.9337 - val_mse: 100.9337\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3141 - mse: 0.3141 - val_loss: 98.4610 - val_mse: 98.4610\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2943 - mse: 0.2943 - val_loss: 9.7839 - val_mse: 9.7839\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2515 - mse: 0.2515 - val_loss: 16351.4736 - val_mse: 16351.4736\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2706 - mse: 0.2706 - val_loss: 16.7853 - val_mse: 16.7853\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2402 - mse: 0.2402 - val_loss: 10745.7969 - val_mse: 10745.7969\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2444 - mse: 0.2444 - val_loss: 7186.5273 - val_mse: 7186.5273\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2012 - mse: 0.2012 - val_loss: 1434.0789 - val_mse: 1434.0789\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2045 - mse: 0.2045 - val_loss: 5173.9360 - val_mse: 5173.9360\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2016 - mse: 0.2016 - val_loss: 87.9651 - val_mse: 87.9651\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1842 - mse: 0.1842 - val_loss: 14895.8516 - val_mse: 14895.8516\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1866 - mse: 0.1866 - val_loss: 35501.5977 - val_mse: 35501.5977\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1864 - mse: 0.1864 - val_loss: 3.6712 - val_mse: 3.6712\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1723 - mse: 0.1723 - val_loss: 86.9106 - val_mse: 86.9106\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1607 - mse: 0.1607 - val_loss: 0.6285 - val_mse: 0.6285\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1619 - mse: 0.1619 - val_loss: 17981.5781 - val_mse: 17981.5781\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1776 - mse: 0.1776 - val_loss: 20.9336 - val_mse: 20.9336\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1675 - mse: 0.1675 - val_loss: 462.8898 - val_mse: 462.8898\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1500 - mse: 0.1500 - val_loss: 45.5223 - val_mse: 45.5223\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1480 - mse: 0.1480 - val_loss: 280.6399 - val_mse: 280.6399\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1390 - mse: 0.1390 - val_loss: 3590.2795 - val_mse: 3590.2795\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1456 - mse: 0.1456 - val_loss: 20.1717 - val_mse: 20.1717\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1447 - mse: 0.1447 - val_loss: 508.3859 - val_mse: 508.3859\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1496 - mse: 0.1496 - val_loss: 640.3354 - val_mse: 640.3354\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1316 - mse: 0.1316 - val_loss: 224.2819 - val_mse: 224.2819\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "67\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6637 - mse: 0.6637 - val_loss: 3.6893 - val_mse: 3.6893\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3917 - mse: 0.3917 - val_loss: 334.9693 - val_mse: 334.9693\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3360 - mse: 0.3360 - val_loss: 8322.1699 - val_mse: 8322.1699\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2897 - mse: 0.2897 - val_loss: 36.9687 - val_mse: 36.9687\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2816 - mse: 0.2816 - val_loss: 652.3244 - val_mse: 652.3244\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2594 - mse: 0.2594 - val_loss: 12791.8242 - val_mse: 12791.8242\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2440 - mse: 0.2440 - val_loss: 221.1144 - val_mse: 221.1144\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2190 - mse: 0.2190 - val_loss: 6230.7256 - val_mse: 6230.7256\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2128 - mse: 0.2128 - val_loss: 11633.4004 - val_mse: 11633.4004\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1988 - mse: 0.1988 - val_loss: 12.8561 - val_mse: 12.8561\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1973 - mse: 0.1973 - val_loss: 23827.0273 - val_mse: 23827.0273\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "68\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6736 - mse: 0.6736 - val_loss: 168.2446 - val_mse: 168.2446\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4341 - mse: 0.4341 - val_loss: 0.6493 - val_mse: 0.6493\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3396 - mse: 0.3396 - val_loss: 375.1797 - val_mse: 375.1797\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3157 - mse: 0.3157 - val_loss: 32.3997 - val_mse: 32.3997\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2782 - mse: 0.2782 - val_loss: 4637.0435 - val_mse: 4637.0435\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2546 - mse: 0.2546 - val_loss: 9566.4443 - val_mse: 9566.4443\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2693 - mse: 0.2693 - val_loss: 10.1468 - val_mse: 10.1468\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2230 - mse: 0.2230 - val_loss: 10693.8467 - val_mse: 10693.8467\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2207 - mse: 0.2207 - val_loss: 1296.8237 - val_mse: 1296.8237\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1969 - mse: 0.1969 - val_loss: 3.1209 - val_mse: 3.1209\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1969 - mse: 0.1969 - val_loss: 11445.6826 - val_mse: 11445.6826\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1913 - mse: 0.1913 - val_loss: 212.4510 - val_mse: 212.4510\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "69\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7460 - mse: 0.7460 - val_loss: 591.0266 - val_mse: 591.0266\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4223 - mse: 0.4223 - val_loss: 988.1517 - val_mse: 988.1517\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3463 - mse: 0.3463 - val_loss: 12.9787 - val_mse: 12.9787\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2933 - mse: 0.2933 - val_loss: 4.6740 - val_mse: 4.6740\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2802 - mse: 0.2802 - val_loss: 700.0341 - val_mse: 700.0341\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2596 - mse: 0.2596 - val_loss: 11514.8223 - val_mse: 11514.8223\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2538 - mse: 0.2538 - val_loss: 516.4786 - val_mse: 516.4786\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2329 - mse: 0.2329 - val_loss: 15595.5869 - val_mse: 15595.5869\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2237 - mse: 0.2237 - val_loss: 475.0316 - val_mse: 475.0316\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1913 - mse: 0.1913 - val_loss: 125.6065 - val_mse: 125.6065\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2061 - mse: 0.2061 - val_loss: 25133.6543 - val_mse: 25133.6543\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1799 - mse: 0.1799 - val_loss: 439.4286 - val_mse: 439.4286\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1711 - mse: 0.1711 - val_loss: 2067.0083 - val_mse: 2067.0083\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1689 - mse: 0.1689 - val_loss: 13935.4717 - val_mse: 13935.4717\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "70\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 8ms/step - loss: 0.7093 - mse: 0.7093 - val_loss: 23.9597 - val_mse: 23.9597\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4086 - mse: 0.4086 - val_loss: 6.7524 - val_mse: 6.7524\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3399 - mse: 0.3399 - val_loss: 4.7418 - val_mse: 4.7418\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2954 - mse: 0.2954 - val_loss: 60.7187 - val_mse: 60.7187\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2750 - mse: 0.2750 - val_loss: 10.6867 - val_mse: 10.6867\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2660 - mse: 0.2660 - val_loss: 38040.0820 - val_mse: 38040.0820\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2590 - mse: 0.2590 - val_loss: 6.2485 - val_mse: 6.2485\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2184 - mse: 0.2184 - val_loss: 1139.7018 - val_mse: 1139.7018\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2421 - mse: 0.2421 - val_loss: 1.8557 - val_mse: 1.8557\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1765 - mse: 0.1765 - val_loss: 3.2189 - val_mse: 3.2189\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1909 - mse: 0.1909 - val_loss: 17401.0332 - val_mse: 17401.0332\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1893 - mse: 0.1893 - val_loss: 322.2755 - val_mse: 322.2755\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1758 - mse: 0.1758 - val_loss: 7236.8872 - val_mse: 7236.8872\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1580 - mse: 0.1580 - val_loss: 2017.3822 - val_mse: 2017.3822\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1655 - mse: 0.1655 - val_loss: 264.1493 - val_mse: 264.1493\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1633 - mse: 0.1633 - val_loss: 11.0059 - val_mse: 11.0059\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1559 - mse: 0.1559 - val_loss: 6962.7158 - val_mse: 6962.7158\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1561 - mse: 0.1561 - val_loss: 0.4793 - val_mse: 0.4793\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1669 - mse: 0.1669 - val_loss: 21295.5234 - val_mse: 21295.5234\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1618 - mse: 0.1618 - val_loss: 828.7077 - val_mse: 828.7077\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1678 - mse: 0.1678 - val_loss: 2484.0327 - val_mse: 2484.0327\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1367 - mse: 0.1367 - val_loss: 3306.1211 - val_mse: 3306.1211\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 17579.5293 - val_mse: 17579.5293\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1403 - mse: 0.1403 - val_loss: 159.5980 - val_mse: 159.5980\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1445 - mse: 0.1445 - val_loss: 9643.0537 - val_mse: 9643.0537\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1414 - mse: 0.1414 - val_loss: 89.0489 - val_mse: 89.0489\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1238 - mse: 0.1238 - val_loss: 1.2326 - val_mse: 1.2326\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1363 - mse: 0.1363 - val_loss: 25.0558 - val_mse: 25.0558\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "71\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6485 - mse: 0.6485 - val_loss: 653.9493 - val_mse: 653.9493\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4094 - mse: 0.4094 - val_loss: 808.6725 - val_mse: 808.6725\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3202 - mse: 0.3202 - val_loss: 105.5676 - val_mse: 105.5676\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2946 - mse: 0.2946 - val_loss: 27.3108 - val_mse: 27.3108\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2664 - mse: 0.2664 - val_loss: 2743.1565 - val_mse: 2743.1565\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2613 - mse: 0.2613 - val_loss: 18295.3301 - val_mse: 18295.3301\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 389.2304 - val_mse: 389.2304\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2287 - mse: 0.2287 - val_loss: 13762.0508 - val_mse: 13762.0508\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2600 - mse: 0.2600 - val_loss: 1278.6626 - val_mse: 1278.6626\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1820 - mse: 0.1820 - val_loss: 199.9564 - val_mse: 199.9564\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1919 - mse: 0.1919 - val_loss: 23620.6895 - val_mse: 23620.6895\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1865 - mse: 0.1865 - val_loss: 0.8730 - val_mse: 0.8730\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1666 - mse: 0.1666 - val_loss: 1409.2457 - val_mse: 1409.2457\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1649 - mse: 0.1649 - val_loss: 26201.9805 - val_mse: 26201.9805\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1703 - mse: 0.1703 - val_loss: 14.6939 - val_mse: 14.6939\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1544 - mse: 0.1544 - val_loss: 123.8999 - val_mse: 123.8999\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1490 - mse: 0.1490 - val_loss: 847.5190 - val_mse: 847.5190\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1447 - mse: 0.1447 - val_loss: 74414.5469 - val_mse: 74414.5469\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1617 - mse: 0.1617 - val_loss: 10373.1377 - val_mse: 10373.1377\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1715 - mse: 0.1715 - val_loss: 2188.9041 - val_mse: 2188.9041\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1630 - mse: 0.1630 - val_loss: 365.0525 - val_mse: 365.0525\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1394 - mse: 0.1394 - val_loss: 15.3694 - val_mse: 15.3694\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "72\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6414 - mse: 0.6414 - val_loss: 1142.3691 - val_mse: 1142.3691\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4123 - mse: 0.4123 - val_loss: 8.4373 - val_mse: 8.4373\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3314 - mse: 0.3314 - val_loss: 209.4563 - val_mse: 209.4563\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3150 - mse: 0.3150 - val_loss: 2.3757 - val_mse: 2.3757\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2670 - mse: 0.2670 - val_loss: 3128.7295 - val_mse: 3128.7295\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2608 - mse: 0.2608 - val_loss: 34858.7773 - val_mse: 34858.7773\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2498 - mse: 0.2498 - val_loss: 5.7805 - val_mse: 5.7805\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2151 - mse: 0.2151 - val_loss: 8029.3691 - val_mse: 8029.3691\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2200 - mse: 0.2200 - val_loss: 3769.7144 - val_mse: 3769.7144\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1861 - mse: 0.1861 - val_loss: 16.4474 - val_mse: 16.4474\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1821 - mse: 0.1821 - val_loss: 11579.4326 - val_mse: 11579.4326\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1768 - mse: 0.1768 - val_loss: 7.7604 - val_mse: 7.7604\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1634 - mse: 0.1634 - val_loss: 6050.8579 - val_mse: 6050.8579\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1933 - mse: 0.1933 - val_loss: 1165.9629 - val_mse: 1165.9629\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "73\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7273 - mse: 0.7273 - val_loss: 594.9814 - val_mse: 594.9814\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3694 - mse: 0.3694 - val_loss: 144.6876 - val_mse: 144.6876\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3156 - mse: 0.3156 - val_loss: 2338.3022 - val_mse: 2338.3022\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2720 - mse: 0.2720 - val_loss: 7.1931 - val_mse: 7.1931\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2494 - mse: 0.2494 - val_loss: 1013.2685 - val_mse: 1013.2685\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2322 - mse: 0.2322 - val_loss: 15795.2393 - val_mse: 15795.2393\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2479 - mse: 0.2479 - val_loss: 5.0474 - val_mse: 5.0474\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2077 - mse: 0.2077 - val_loss: 12119.8770 - val_mse: 12119.8770\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2088 - mse: 0.2088 - val_loss: 3189.4526 - val_mse: 3189.4526\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1701 - mse: 0.1701 - val_loss: 20.2081 - val_mse: 20.2081\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1908 - mse: 0.1908 - val_loss: 6492.7554 - val_mse: 6492.7554\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1681 - mse: 0.1681 - val_loss: 597.7515 - val_mse: 597.7515\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1472 - mse: 0.1472 - val_loss: 799.8135 - val_mse: 799.8135\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1624 - mse: 0.1624 - val_loss: 31598.4863 - val_mse: 31598.4863\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1652 - mse: 0.1652 - val_loss: 244.4272 - val_mse: 244.4272\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1612 - mse: 0.1612 - val_loss: 36.6805 - val_mse: 36.6805\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1603 - mse: 0.1603 - val_loss: 12150.0234 - val_mse: 12150.0234\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "74\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6284 - mse: 0.6284 - val_loss: 0.7388 - val_mse: 0.7388\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4123 - mse: 0.4123 - val_loss: 3.4371 - val_mse: 3.4371\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3326 - mse: 0.3326 - val_loss: 544.2364 - val_mse: 544.2364\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2922 - mse: 0.2922 - val_loss: 19.7386 - val_mse: 19.7386\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2882 - mse: 0.2882 - val_loss: 58.0992 - val_mse: 58.0992\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2486 - mse: 0.2486 - val_loss: 16053.1934 - val_mse: 16053.1934\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2495 - mse: 0.2495 - val_loss: 125.2136 - val_mse: 125.2136\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2154 - mse: 0.2154 - val_loss: 2038.8353 - val_mse: 2038.8353\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2174 - mse: 0.2174 - val_loss: 1799.0314 - val_mse: 1799.0314\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1701 - mse: 0.1701 - val_loss: 208.7126 - val_mse: 208.7126\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1953 - mse: 0.1953 - val_loss: 5475.4595 - val_mse: 5475.4595\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "75\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6668 - mse: 0.6668 - val_loss: 4.9951 - val_mse: 4.9951\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4070 - mse: 0.4070 - val_loss: 2920.6201 - val_mse: 2920.6201\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3367 - mse: 0.3367 - val_loss: 74.5557 - val_mse: 74.5557\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3061 - mse: 0.3061 - val_loss: 11.7410 - val_mse: 11.7410\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2840 - mse: 0.2840 - val_loss: 1965.7725 - val_mse: 1965.7725\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2637 - mse: 0.2637 - val_loss: 39.7994 - val_mse: 39.7994\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2588 - mse: 0.2588 - val_loss: 23.0702 - val_mse: 23.0702\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2200 - mse: 0.2200 - val_loss: 1267.5592 - val_mse: 1267.5592\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2347 - mse: 0.2347 - val_loss: 2968.4878 - val_mse: 2968.4878\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1748 - mse: 0.1748 - val_loss: 104.4396 - val_mse: 104.4396\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1980 - mse: 0.1980 - val_loss: 14528.5459 - val_mse: 14528.5459\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "76\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6235 - mse: 0.6235 - val_loss: 72.1088 - val_mse: 72.1088\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3871 - mse: 0.3871 - val_loss: 108.3472 - val_mse: 108.3472\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3280 - mse: 0.3280 - val_loss: 231.0656 - val_mse: 231.0656\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2785 - mse: 0.2785 - val_loss: 10.5824 - val_mse: 10.5824\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2772 - mse: 0.2772 - val_loss: 590.4921 - val_mse: 590.4921\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 5882.7690 - val_mse: 5882.7690\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2283 - mse: 0.2283 - val_loss: 11.1466 - val_mse: 11.1466\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2218 - mse: 0.2218 - val_loss: 761.2880 - val_mse: 761.2880\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.7710 - val_mse: 0.7710\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1853 - mse: 0.1853 - val_loss: 100.0884 - val_mse: 100.0884\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1851 - mse: 0.1851 - val_loss: 3754.4558 - val_mse: 3754.4558\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 26.7854 - val_mse: 26.7854\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1699 - mse: 0.1699 - val_loss: 5171.6221 - val_mse: 5171.6221\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1612 - mse: 0.1612 - val_loss: 55554.1562 - val_mse: 55554.1562\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1780 - mse: 0.1780 - val_loss: 3.9140 - val_mse: 3.9140\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1567 - mse: 0.1567 - val_loss: 4.4148 - val_mse: 4.4148\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1446 - mse: 0.1446 - val_loss: 576.5601 - val_mse: 576.5601\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1478 - mse: 0.1478 - val_loss: 47796.0469 - val_mse: 47796.0469\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1546 - mse: 0.1546 - val_loss: 786.4236 - val_mse: 786.4236\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "77\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.5949 - mse: 0.5949 - val_loss: 5467.7402 - val_mse: 5467.7402\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3969 - mse: 0.3969 - val_loss: 897.5427 - val_mse: 897.5427\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3286 - mse: 0.3286 - val_loss: 690.7261 - val_mse: 690.7261\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2752 - mse: 0.2752 - val_loss: 0.6792 - val_mse: 0.6792\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2696 - mse: 0.2696 - val_loss: 135.4494 - val_mse: 135.4494\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2440 - mse: 0.2440 - val_loss: 22520.3340 - val_mse: 22520.3340\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2623 - mse: 0.2623 - val_loss: 15.9093 - val_mse: 15.9093\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2103 - mse: 0.2103 - val_loss: 9843.6816 - val_mse: 9843.6816\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2347 - mse: 0.2347 - val_loss: 5331.3545 - val_mse: 5331.3545\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1718 - mse: 0.1718 - val_loss: 2.9705 - val_mse: 2.9705\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1889 - mse: 0.1889 - val_loss: 32246.1426 - val_mse: 32246.1426\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1815 - mse: 0.1815 - val_loss: 0.8881 - val_mse: 0.8881\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1609 - mse: 0.1609 - val_loss: 7797.2681 - val_mse: 7797.2681\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1807 - mse: 0.1807 - val_loss: 22536.0801 - val_mse: 22536.0801\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "78\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6808 - mse: 0.6808 - val_loss: 116.1831 - val_mse: 116.1831\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4220 - mse: 0.4220 - val_loss: 1459.5625 - val_mse: 1459.5625\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3361 - mse: 0.3361 - val_loss: 206.2756 - val_mse: 206.2756\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3150 - mse: 0.3150 - val_loss: 2.9082 - val_mse: 2.9082\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2792 - mse: 0.2792 - val_loss: 19.2662 - val_mse: 19.2662\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2612 - mse: 0.2612 - val_loss: 4890.8911 - val_mse: 4890.8911\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2542 - mse: 0.2542 - val_loss: 742.1451 - val_mse: 742.1451\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2215 - mse: 0.2215 - val_loss: 7002.5869 - val_mse: 7002.5869\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2429 - mse: 0.2429 - val_loss: 2391.5210 - val_mse: 2391.5210\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2036 - mse: 0.2036 - val_loss: 67.6315 - val_mse: 67.6315\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2005 - mse: 0.2005 - val_loss: 12637.6191 - val_mse: 12637.6191\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1751 - mse: 0.1751 - val_loss: 7.2100 - val_mse: 7.2100\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1673 - mse: 0.1673 - val_loss: 3656.5703 - val_mse: 3656.5703\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1547 - mse: 0.1547 - val_loss: 10135.4375 - val_mse: 10135.4375\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "79\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6514 - mse: 0.6514 - val_loss: 31.3645 - val_mse: 31.3645\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3845 - mse: 0.3845 - val_loss: 35.6691 - val_mse: 35.6691\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3075 - mse: 0.3075 - val_loss: 929.1078 - val_mse: 929.1078\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2792 - mse: 0.2792 - val_loss: 284.0416 - val_mse: 284.0416\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2698 - mse: 0.2698 - val_loss: 1543.1296 - val_mse: 1543.1296\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2358 - mse: 0.2358 - val_loss: 23976.4473 - val_mse: 23976.4473\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2215 - mse: 0.2215 - val_loss: 0.7198 - val_mse: 0.7198\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2056 - mse: 0.2056 - val_loss: 4661.9731 - val_mse: 4661.9731\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2186 - mse: 0.2186 - val_loss: 54.4771 - val_mse: 54.4771\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1731 - mse: 0.1731 - val_loss: 243.8822 - val_mse: 243.8822\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1754 - mse: 0.1754 - val_loss: 5524.7559 - val_mse: 5524.7559\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1782 - mse: 0.1782 - val_loss: 35.8753 - val_mse: 35.8753\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1695 - mse: 0.1695 - val_loss: 11659.2871 - val_mse: 11659.2871\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1704 - mse: 0.1704 - val_loss: 26341.6855 - val_mse: 26341.6855\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1684 - mse: 0.1684 - val_loss: 19.3072 - val_mse: 19.3072\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1572 - mse: 0.1572 - val_loss: 4.7955 - val_mse: 4.7955\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1469 - mse: 0.1469 - val_loss: 133.4016 - val_mse: 133.4016\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "80\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6633 - mse: 0.6633 - val_loss: 270.7430 - val_mse: 270.7430\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3877 - mse: 0.3877 - val_loss: 269.4755 - val_mse: 269.4755\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3303 - mse: 0.3303 - val_loss: 1817.0776 - val_mse: 1817.0776\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2925 - mse: 0.2925 - val_loss: 84.8162 - val_mse: 84.8162\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2730 - mse: 0.2730 - val_loss: 252.4670 - val_mse: 252.4670\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2723 - mse: 0.2723 - val_loss: 4181.0239 - val_mse: 4181.0239\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2381 - mse: 0.2381 - val_loss: 979.6873 - val_mse: 979.6873\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2173 - mse: 0.2173 - val_loss: 988.9843 - val_mse: 988.9843\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2159 - mse: 0.2159 - val_loss: 523.3326 - val_mse: 523.3326\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1859 - mse: 0.1859 - val_loss: 17.1290 - val_mse: 17.1290\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2002 - mse: 0.2002 - val_loss: 24409.3145 - val_mse: 24409.3145\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1849 - mse: 0.1849 - val_loss: 107.8232 - val_mse: 107.8232\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1736 - mse: 0.1736 - val_loss: 15571.3760 - val_mse: 15571.3760\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1643 - mse: 0.1643 - val_loss: 5399.9321 - val_mse: 5399.9321\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1781 - mse: 0.1781 - val_loss: 3.3682 - val_mse: 3.3682\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1736 - mse: 0.1736 - val_loss: 26.7630 - val_mse: 26.7630\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1670 - mse: 0.1670 - val_loss: 2740.7290 - val_mse: 2740.7290\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1535 - mse: 0.1535 - val_loss: 22963.3672 - val_mse: 22963.3672\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1832 - mse: 0.1832 - val_loss: 5646.6553 - val_mse: 5646.6553\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1654 - mse: 0.1654 - val_loss: 138.7206 - val_mse: 138.7206\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1433 - mse: 0.1433 - val_loss: 3.6036 - val_mse: 3.6036\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1509 - mse: 0.1509 - val_loss: 330.8807 - val_mse: 330.8807\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1310 - mse: 0.1310 - val_loss: 1985.6979 - val_mse: 1985.6979\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 2.0606 - val_mse: 2.0606\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1454 - mse: 0.1454 - val_loss: 114.0347 - val_mse: 114.0347\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1470 - mse: 0.1470 - val_loss: 5304.7725 - val_mse: 5304.7725\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1395 - mse: 0.1395 - val_loss: 423.9380 - val_mse: 423.9380\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1243 - mse: 0.1243 - val_loss: 2.2397 - val_mse: 2.2397\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1288 - mse: 0.1288 - val_loss: 2825.6616 - val_mse: 2825.6616\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1313 - mse: 0.1313 - val_loss: 1135.2358 - val_mse: 1135.2358\n",
      "Epoch 31/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1296 - mse: 0.1296 - val_loss: 154.2642 - val_mse: 154.2642\n",
      "Epoch 32/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1274 - mse: 0.1274 - val_loss: 973.0746 - val_mse: 973.0746\n",
      "Epoch 33/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1235 - mse: 0.1235 - val_loss: 972.9105 - val_mse: 972.9105\n",
      "Epoch 34/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 5.1418 - val_mse: 5.1418\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "81\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.7095 - mse: 0.7095 - val_loss: 3.8540 - val_mse: 3.8540\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4112 - mse: 0.4112 - val_loss: 15.5939 - val_mse: 15.5939\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3473 - mse: 0.3473 - val_loss: 1362.6356 - val_mse: 1362.6356\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2985 - mse: 0.2985 - val_loss: 12.3507 - val_mse: 12.3507\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2698 - mse: 0.2698 - val_loss: 762.4974 - val_mse: 762.4974\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2581 - mse: 0.2581 - val_loss: 6403.6328 - val_mse: 6403.6328\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2673 - mse: 0.2673 - val_loss: 1.1278 - val_mse: 1.1278\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2121 - mse: 0.2121 - val_loss: 295.0193 - val_mse: 295.0193\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2198 - mse: 0.2198 - val_loss: 72.9323 - val_mse: 72.9323\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1809 - mse: 0.1809 - val_loss: 606.2031 - val_mse: 606.2031\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1965 - mse: 0.1965 - val_loss: 19939.4512 - val_mse: 19939.4512\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1725 - mse: 0.1725 - val_loss: 59.1923 - val_mse: 59.1923\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1549 - mse: 0.1549 - val_loss: 910.7590 - val_mse: 910.7590\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1581 - mse: 0.1581 - val_loss: 2858.6782 - val_mse: 2858.6782\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1622 - mse: 0.1622 - val_loss: 12.9146 - val_mse: 12.9146\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1657 - mse: 0.1657 - val_loss: 116.2982 - val_mse: 116.2982\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1757 - mse: 0.1757 - val_loss: 25073.3926 - val_mse: 25073.3926\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "82\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 8ms/step - loss: 0.6160 - mse: 0.6160 - val_loss: 178.9108 - val_mse: 178.9108\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.4093 - mse: 0.4093 - val_loss: 3.2088 - val_mse: 3.2088\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3318 - mse: 0.3318 - val_loss: 470.6779 - val_mse: 470.6779\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2989 - mse: 0.2989 - val_loss: 2.2635 - val_mse: 2.2635\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2658 - mse: 0.2658 - val_loss: 4.5582 - val_mse: 4.5582\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2426 - mse: 0.2426 - val_loss: 13076.7441 - val_mse: 13076.7441\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2610 - mse: 0.2610 - val_loss: 67.4863 - val_mse: 67.4863\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2284 - mse: 0.2284 - val_loss: 1488.9255 - val_mse: 1488.9255\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2241 - mse: 0.2241 - val_loss: 118.0233 - val_mse: 118.0233\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1751 - mse: 0.1751 - val_loss: 675.5425 - val_mse: 675.5425\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1894 - mse: 0.1894 - val_loss: 8524.7695 - val_mse: 8524.7695\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1695 - mse: 0.1695 - val_loss: 23.8800 - val_mse: 23.8800\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1637 - mse: 0.1637 - val_loss: 576.3877 - val_mse: 576.3877\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1558 - mse: 0.1558 - val_loss: 932.9316 - val_mse: 932.9316\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "83\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6720 - mse: 0.6720 - val_loss: 480.3448 - val_mse: 480.3448\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3905 - mse: 0.3905 - val_loss: 301.1326 - val_mse: 301.1326\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3123 - mse: 0.3123 - val_loss: 3494.0762 - val_mse: 3494.0762\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2930 - mse: 0.2930 - val_loss: 11.0964 - val_mse: 11.0964\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2709 - mse: 0.2709 - val_loss: 22.2168 - val_mse: 22.2168\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2342 - mse: 0.2342 - val_loss: 5187.8516 - val_mse: 5187.8516\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2330 - mse: 0.2330 - val_loss: 153.9623 - val_mse: 153.9623\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2153 - mse: 0.2153 - val_loss: 586.7548 - val_mse: 586.7548\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2476 - mse: 0.2476 - val_loss: 21.8096 - val_mse: 21.8096\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1855 - mse: 0.1855 - val_loss: 58.9065 - val_mse: 58.9065\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1823 - mse: 0.1823 - val_loss: 6170.6748 - val_mse: 6170.6748\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1776 - mse: 0.1776 - val_loss: 0.7707 - val_mse: 0.7707\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1702 - mse: 0.1702 - val_loss: 1324.4258 - val_mse: 1324.4258\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1628 - mse: 0.1628 - val_loss: 2532.5239 - val_mse: 2532.5239\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1689 - mse: 0.1689 - val_loss: 41.8295 - val_mse: 41.8295\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1672 - mse: 0.1672 - val_loss: 211.3879 - val_mse: 211.3879\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1410 - mse: 0.1410 - val_loss: 120.2072 - val_mse: 120.2072\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1440 - mse: 0.1440 - val_loss: 19.6140 - val_mse: 19.6140\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1498 - mse: 0.1498 - val_loss: 1207.6638 - val_mse: 1207.6638\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1508 - mse: 0.1508 - val_loss: 2293.5603 - val_mse: 2293.5603\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1267 - mse: 0.1267 - val_loss: 117.3996 - val_mse: 117.3996\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1604 - mse: 0.1604 - val_loss: 240.5431 - val_mse: 240.5431\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "84\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6401 - mse: 0.6401 - val_loss: 454.8435 - val_mse: 454.8435\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3949 - mse: 0.3949 - val_loss: 211.9776 - val_mse: 211.9776\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3457 - mse: 0.3457 - val_loss: 269.5949 - val_mse: 269.5949\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3062 - mse: 0.3062 - val_loss: 141.0499 - val_mse: 141.0499\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2678 - mse: 0.2678 - val_loss: 1323.2092 - val_mse: 1323.2092\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2493 - mse: 0.2493 - val_loss: 5204.6343 - val_mse: 5204.6343\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2431 - mse: 0.2431 - val_loss: 43.4730 - val_mse: 43.4730\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 787.3801 - val_mse: 787.3801\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2523 - mse: 0.2523 - val_loss: 54.4074 - val_mse: 54.4074\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1840 - mse: 0.1840 - val_loss: 45.3901 - val_mse: 45.3901\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1915 - mse: 0.1915 - val_loss: 12000.2607 - val_mse: 12000.2607\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1770 - mse: 0.1770 - val_loss: 3.0554 - val_mse: 3.0554\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1656 - mse: 0.1656 - val_loss: 8759.7842 - val_mse: 8759.7842\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1572 - mse: 0.1572 - val_loss: 263.0647 - val_mse: 263.0647\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1752 - mse: 0.1752 - val_loss: 7.2676 - val_mse: 7.2676\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1634 - mse: 0.1634 - val_loss: 5.8239 - val_mse: 5.8239\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1463 - mse: 0.1463 - val_loss: 408.7058 - val_mse: 408.7058\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1397 - mse: 0.1397 - val_loss: 2601.3159 - val_mse: 2601.3159\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1647 - mse: 0.1647 - val_loss: 15.4469 - val_mse: 15.4469\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1548 - mse: 0.1548 - val_loss: 50.5766 - val_mse: 50.5766\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1352 - mse: 0.1352 - val_loss: 0.9903 - val_mse: 0.9903\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1409 - mse: 0.1409 - val_loss: 1.6713 - val_mse: 1.6713\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1345 - mse: 0.1345 - val_loss: 7772.0659 - val_mse: 7772.0659\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1285 - mse: 0.1285 - val_loss: 10.2848 - val_mse: 10.2848\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1283 - mse: 0.1283 - val_loss: 22705.6445 - val_mse: 22705.6445\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1378 - mse: 0.1378 - val_loss: 17.7289 - val_mse: 17.7289\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1141 - mse: 0.1141 - val_loss: 18.0219 - val_mse: 18.0219\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1257 - mse: 0.1257 - val_loss: 7.2209 - val_mse: 7.2209\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1230 - mse: 0.1230 - val_loss: 984.6532 - val_mse: 984.6532\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1230 - mse: 0.1230 - val_loss: 336.2653 - val_mse: 336.2653\n",
      "Epoch 31/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1299 - mse: 0.1299 - val_loss: 1808.8628 - val_mse: 1808.8628\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "85\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6698 - mse: 0.6698 - val_loss: 182.3372 - val_mse: 182.3372\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4079 - mse: 0.4079 - val_loss: 0.6319 - val_mse: 0.6319\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3288 - mse: 0.3288 - val_loss: 948.4868 - val_mse: 948.4868\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2974 - mse: 0.2974 - val_loss: 87.8923 - val_mse: 87.8923\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2661 - mse: 0.2661 - val_loss: 25.5101 - val_mse: 25.5101\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2518 - mse: 0.2518 - val_loss: 10504.3291 - val_mse: 10504.3291\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2366 - mse: 0.2366 - val_loss: 25.7547 - val_mse: 25.7547\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2091 - mse: 0.2091 - val_loss: 2419.2407 - val_mse: 2419.2407\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2310 - mse: 0.2310 - val_loss: 232.9491 - val_mse: 232.9491\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2037 - mse: 0.2037 - val_loss: 32.4157 - val_mse: 32.4157\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1993 - mse: 0.1993 - val_loss: 12306.5322 - val_mse: 12306.5322\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1737 - mse: 0.1737 - val_loss: 1.5757 - val_mse: 1.5757\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "86\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.5997 - mse: 0.5997 - val_loss: 7626.6870 - val_mse: 7626.6870\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4013 - mse: 0.4013 - val_loss: 3.0689 - val_mse: 3.0689\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3227 - mse: 0.3227 - val_loss: 337.5193 - val_mse: 337.5193\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2809 - mse: 0.2809 - val_loss: 57.8003 - val_mse: 57.8003\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2613 - mse: 0.2613 - val_loss: 241.8239 - val_mse: 241.8239\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2459 - mse: 0.2459 - val_loss: 25207.1035 - val_mse: 25207.1035\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2485 - mse: 0.2485 - val_loss: 17.5734 - val_mse: 17.5734\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2055 - mse: 0.2055 - val_loss: 1388.6455 - val_mse: 1388.6455\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2370 - mse: 0.2370 - val_loss: 87.3133 - val_mse: 87.3133\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1955 - mse: 0.1955 - val_loss: 335.6990 - val_mse: 335.6990\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1941 - mse: 0.1941 - val_loss: 9087.3740 - val_mse: 9087.3740\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1845 - mse: 0.1845 - val_loss: 189.0276 - val_mse: 189.0276\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "87\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 8ms/step - loss: 0.6560 - mse: 0.6560 - val_loss: 2003.9739 - val_mse: 2003.9739\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3860 - mse: 0.3860 - val_loss: 1532.7026 - val_mse: 1532.7026\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3185 - mse: 0.3185 - val_loss: 785.7867 - val_mse: 785.7867\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2747 - mse: 0.2747 - val_loss: 0.8868 - val_mse: 0.8868\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2638 - mse: 0.2638 - val_loss: 97.7175 - val_mse: 97.7175\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2289 - mse: 0.2289 - val_loss: 12529.6279 - val_mse: 12529.6279\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2433 - mse: 0.2433 - val_loss: 6.4792 - val_mse: 6.4792\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2075 - mse: 0.2075 - val_loss: 121.3964 - val_mse: 121.3964\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2235 - mse: 0.2235 - val_loss: 4673.9282 - val_mse: 4673.9282\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1788 - mse: 0.1788 - val_loss: 83.4633 - val_mse: 83.4633\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1733 - mse: 0.1733 - val_loss: 12768.5850 - val_mse: 12768.5850\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1674 - mse: 0.1674 - val_loss: 60.8801 - val_mse: 60.8801\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1541 - mse: 0.1541 - val_loss: 438.4739 - val_mse: 438.4739\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1516 - mse: 0.1516 - val_loss: 258.3791 - val_mse: 258.3791\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "88\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6067 - mse: 0.6067 - val_loss: 28.3735 - val_mse: 28.3735\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3748 - mse: 0.3748 - val_loss: 569.7915 - val_mse: 569.7915\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3235 - mse: 0.3235 - val_loss: 405.5246 - val_mse: 405.5246\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2782 - mse: 0.2782 - val_loss: 130.0328 - val_mse: 130.0328\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2548 - mse: 0.2548 - val_loss: 66.3028 - val_mse: 66.3028\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2424 - mse: 0.2424 - val_loss: 13272.7725 - val_mse: 13272.7725\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2230 - mse: 0.2230 - val_loss: 479.2495 - val_mse: 479.2495\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1941 - mse: 0.1941 - val_loss: 2416.5669 - val_mse: 2416.5669\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1974 - mse: 0.1974 - val_loss: 6180.8667 - val_mse: 6180.8667\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1562 - mse: 0.1562 - val_loss: 9.7021 - val_mse: 9.7021\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1732 - mse: 0.1732 - val_loss: 10535.7295 - val_mse: 10535.7295\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1585 - mse: 0.1585 - val_loss: 52.9965 - val_mse: 52.9965\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1467 - mse: 0.1467 - val_loss: 2183.6370 - val_mse: 2183.6370\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1632 - mse: 0.1632 - val_loss: 84209.1328 - val_mse: 84209.1328\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2184 - mse: 0.2184 - val_loss: 0.5144 - val_mse: 0.5144\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1512 - mse: 0.1512 - val_loss: 19.6294 - val_mse: 19.6294\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1517 - mse: 0.1517 - val_loss: 2.1503 - val_mse: 2.1503\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1383 - mse: 0.1383 - val_loss: 575.9118 - val_mse: 575.9118\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1460 - mse: 0.1460 - val_loss: 44.2528 - val_mse: 44.2528\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1489 - mse: 0.1489 - val_loss: 277.8851 - val_mse: 277.8851\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 108.7751 - val_mse: 108.7751\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1315 - mse: 0.1315 - val_loss: 2397.5117 - val_mse: 2397.5117\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1259 - mse: 0.1259 - val_loss: 9.1145 - val_mse: 9.1145\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1308 - mse: 0.1308 - val_loss: 6.1669 - val_mse: 6.1669\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 8737.7773 - val_mse: 8737.7773\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "89\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 3s 7ms/step - loss: 0.6439 - mse: 0.6439 - val_loss: 590.8834 - val_mse: 590.8834\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4158 - mse: 0.4158 - val_loss: 213.0918 - val_mse: 213.0918\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3389 - mse: 0.3389 - val_loss: 70.1420 - val_mse: 70.1420\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2920 - mse: 0.2920 - val_loss: 20.4299 - val_mse: 20.4299\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2659 - mse: 0.2659 - val_loss: 2878.2578 - val_mse: 2878.2578\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2533 - mse: 0.2533 - val_loss: 13123.6631 - val_mse: 13123.6631\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2606 - mse: 0.2606 - val_loss: 67.7558 - val_mse: 67.7558\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2149 - mse: 0.2149 - val_loss: 2642.5300 - val_mse: 2642.5300\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2149 - mse: 0.2149 - val_loss: 78.8744 - val_mse: 78.8744\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1772 - mse: 0.1772 - val_loss: 136.3987 - val_mse: 136.3987\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1860 - mse: 0.1860 - val_loss: 5936.0435 - val_mse: 5936.0435\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1660 - mse: 0.1660 - val_loss: 3.2582 - val_mse: 3.2582\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1440 - mse: 0.1440 - val_loss: 3966.8450 - val_mse: 3966.8450\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1506 - mse: 0.1506 - val_loss: 4236.8223 - val_mse: 4236.8223\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1751 - mse: 0.1751 - val_loss: 187.6865 - val_mse: 187.6865\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1514 - mse: 0.1514 - val_loss: 26.3684 - val_mse: 26.3684\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1434 - mse: 0.1434 - val_loss: 1379.2654 - val_mse: 1379.2654\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1459 - mse: 0.1459 - val_loss: 12016.0049 - val_mse: 12016.0049\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1676 - mse: 0.1676 - val_loss: 7594.3760 - val_mse: 7594.3760\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1609 - mse: 0.1609 - val_loss: 319.2324 - val_mse: 319.2324\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 39.7223 - val_mse: 39.7223\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1431 - mse: 0.1431 - val_loss: 6.3031 - val_mse: 6.3031\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "90\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6653 - mse: 0.6653 - val_loss: 669.0011 - val_mse: 669.0011\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3940 - mse: 0.3940 - val_loss: 1057.5214 - val_mse: 1057.5214\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3366 - mse: 0.3366 - val_loss: 97.1465 - val_mse: 97.1465\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2979 - mse: 0.2979 - val_loss: 89.1261 - val_mse: 89.1261\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2710 - mse: 0.2710 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2330 - mse: 0.2330 - val_loss: 14286.4160 - val_mse: 14286.4160\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2424 - mse: 0.2424 - val_loss: 84.5348 - val_mse: 84.5348\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2015 - mse: 0.2015 - val_loss: 2406.0103 - val_mse: 2406.0103\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2273 - mse: 0.2273 - val_loss: 16.5355 - val_mse: 16.5355\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1834 - mse: 0.1834 - val_loss: 988.7133 - val_mse: 988.7133\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1910 - mse: 0.1910 - val_loss: 19331.4707 - val_mse: 19331.4707\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1737 - mse: 0.1737 - val_loss: 1.8687 - val_mse: 1.8687\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1609 - mse: 0.1609 - val_loss: 18343.9355 - val_mse: 18343.9355\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1504 - mse: 0.1504 - val_loss: 31989.0117 - val_mse: 31989.0117\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1604 - mse: 0.1604 - val_loss: 30.8308 - val_mse: 30.8308\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "91\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6644 - mse: 0.6644 - val_loss: 26.2100 - val_mse: 26.2100\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3907 - mse: 0.3907 - val_loss: 104.9858 - val_mse: 104.9858\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3162 - mse: 0.3162 - val_loss: 3.8831 - val_mse: 3.8831\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2945 - mse: 0.2945 - val_loss: 31.1220 - val_mse: 31.1220\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2637 - mse: 0.2637 - val_loss: 5.5413 - val_mse: 5.5413\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2421 - mse: 0.2421 - val_loss: 20227.8242 - val_mse: 20227.8242\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2424 - mse: 0.2424 - val_loss: 6.9028 - val_mse: 6.9028\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2102 - mse: 0.2102 - val_loss: 9308.0723 - val_mse: 9308.0723\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2143 - mse: 0.2143 - val_loss: 201.5975 - val_mse: 201.5975\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 843.2680 - val_mse: 843.2680\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1953 - mse: 0.1953 - val_loss: 1635.0525 - val_mse: 1635.0525\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1779 - mse: 0.1779 - val_loss: 0.7539 - val_mse: 0.7539\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1639 - mse: 0.1639 - val_loss: 3614.8618 - val_mse: 3614.8618\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1566 - mse: 0.1566 - val_loss: 228.7356 - val_mse: 228.7356\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1656 - mse: 0.1656 - val_loss: 0.9808 - val_mse: 0.9808\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1513 - mse: 0.1513 - val_loss: 0.7401 - val_mse: 0.7401\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1407 - mse: 0.1407 - val_loss: 440.2851 - val_mse: 440.2851\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1435 - mse: 0.1435 - val_loss: 25542.7656 - val_mse: 25542.7656\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1692 - mse: 0.1692 - val_loss: 8888.9990 - val_mse: 8888.9990\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1590 - mse: 0.1590 - val_loss: 0.8121 - val_mse: 0.8121\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1254 - mse: 0.1254 - val_loss: 6.6942 - val_mse: 6.6942\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1382 - mse: 0.1382 - val_loss: 302.3774 - val_mse: 302.3774\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1249 - mse: 0.1249 - val_loss: 19.0690 - val_mse: 19.0690\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1245 - mse: 0.1245 - val_loss: 19.5737 - val_mse: 19.5737\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1259 - mse: 0.1259 - val_loss: 4.1922 - val_mse: 4.1922\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1413 - mse: 0.1413 - val_loss: 8169.6250 - val_mse: 8169.6250\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "92\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6298 - mse: 0.6298 - val_loss: 735.8492 - val_mse: 735.8492\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3969 - mse: 0.3969 - val_loss: 565.2990 - val_mse: 565.2990\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3346 - mse: 0.3346 - val_loss: 567.4766 - val_mse: 567.4766\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2739 - mse: 0.2739 - val_loss: 0.8753 - val_mse: 0.8753\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2876 - mse: 0.2876 - val_loss: 4.4512 - val_mse: 4.4512\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2404 - mse: 0.2404 - val_loss: 8255.3467 - val_mse: 8255.3467\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2586 - mse: 0.2586 - val_loss: 69.3040 - val_mse: 69.3040\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2082 - mse: 0.2082 - val_loss: 8626.0498 - val_mse: 8626.0498\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2226 - mse: 0.2226 - val_loss: 7697.1069 - val_mse: 7697.1069\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1961 - mse: 0.1961 - val_loss: 94.5263 - val_mse: 94.5263\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1918 - mse: 0.1918 - val_loss: 21127.9629 - val_mse: 21127.9629\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1723 - mse: 0.1723 - val_loss: 1.3028 - val_mse: 1.3028\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1588 - mse: 0.1588 - val_loss: 95.9021 - val_mse: 95.9021\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1546 - mse: 0.1546 - val_loss: 6537.5488 - val_mse: 6537.5488\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "93\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 8ms/step - loss: 0.6492 - mse: 0.6492 - val_loss: 98.9009 - val_mse: 98.9009\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3810 - mse: 0.3810 - val_loss: 379.6190 - val_mse: 379.6190\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3341 - mse: 0.3341 - val_loss: 207.7263 - val_mse: 207.7263\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2917 - mse: 0.2917 - val_loss: 12.9053 - val_mse: 12.9053\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2676 - mse: 0.2676 - val_loss: 742.1850 - val_mse: 742.1850\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2471 - mse: 0.2471 - val_loss: 14249.7129 - val_mse: 14249.7129\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2707 - mse: 0.2707 - val_loss: 9.0198 - val_mse: 9.0198\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2037 - mse: 0.2037 - val_loss: 430.6528 - val_mse: 430.6528\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2049 - mse: 0.2049 - val_loss: 1587.3519 - val_mse: 1587.3519\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2043 - mse: 0.2043 - val_loss: 40.2196 - val_mse: 40.2196\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1969 - mse: 0.1969 - val_loss: 29720.9121 - val_mse: 29720.9121\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1689 - mse: 0.1689 - val_loss: 29.5299 - val_mse: 29.5299\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1462 - mse: 0.1462 - val_loss: 6992.1206 - val_mse: 6992.1206\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1597 - mse: 0.1597 - val_loss: 209.0296 - val_mse: 209.0296\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1725 - mse: 0.1725 - val_loss: 38.8014 - val_mse: 38.8014\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1588 - mse: 0.1588 - val_loss: 87.3935 - val_mse: 87.3935\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1850 - mse: 0.1850 - val_loss: 949.9160 - val_mse: 949.9160\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "94\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.5928 - mse: 0.5928 - val_loss: 9.6650 - val_mse: 9.6650\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3665 - mse: 0.3665 - val_loss: 15.8523 - val_mse: 15.8523\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3129 - mse: 0.3129 - val_loss: 24.6731 - val_mse: 24.6731\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2879 - mse: 0.2879 - val_loss: 1.0573 - val_mse: 1.0573\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2738 - mse: 0.2738 - val_loss: 33.5189 - val_mse: 33.5189\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 29381.7695 - val_mse: 29381.7695\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2399 - mse: 0.2399 - val_loss: 13.2513 - val_mse: 13.2513\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2164 - mse: 0.2164 - val_loss: 1877.5845 - val_mse: 1877.5845\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2192 - mse: 0.2192 - val_loss: 2696.1040 - val_mse: 2696.1040\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1708 - mse: 0.1708 - val_loss: 19.1601 - val_mse: 19.1601\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1905 - mse: 0.1905 - val_loss: 61465.2070 - val_mse: 61465.2070\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1859 - mse: 0.1859 - val_loss: 7.3806 - val_mse: 7.3806\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1628 - mse: 0.1628 - val_loss: 2781.9475 - val_mse: 2781.9475\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1625 - mse: 0.1625 - val_loss: 50674.2305 - val_mse: 50674.2305\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "95\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6255 - mse: 0.6255 - val_loss: 61.8671 - val_mse: 61.8671\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.4184 - mse: 0.4184 - val_loss: 390.3665 - val_mse: 390.3665\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3191 - mse: 0.3191 - val_loss: 8.8496 - val_mse: 8.8496\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2987 - mse: 0.2987 - val_loss: 21.6568 - val_mse: 21.6568\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2631 - mse: 0.2631 - val_loss: 4135.2441 - val_mse: 4135.2441\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2491 - mse: 0.2491 - val_loss: 6871.6206 - val_mse: 6871.6206\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2405 - mse: 0.2405 - val_loss: 38.5932 - val_mse: 38.5932\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 4507.2759 - val_mse: 4507.2759\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2137 - mse: 0.2137 - val_loss: 879.5290 - val_mse: 879.5290\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1780 - mse: 0.1780 - val_loss: 42.9792 - val_mse: 42.9792\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1872 - mse: 0.1872 - val_loss: 15392.7891 - val_mse: 15392.7891\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1824 - mse: 0.1824 - val_loss: 41.7899 - val_mse: 41.7899\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1555 - mse: 0.1555 - val_loss: 5451.4878 - val_mse: 5451.4878\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "96\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6389 - mse: 0.6389 - val_loss: 599.4333 - val_mse: 599.4333\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3891 - mse: 0.3891 - val_loss: 365.5770 - val_mse: 365.5770\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3296 - mse: 0.3296 - val_loss: 1421.7200 - val_mse: 1421.7200\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2756 - mse: 0.2756 - val_loss: 72.3841 - val_mse: 72.3841\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2552 - mse: 0.2552 - val_loss: 427.5082 - val_mse: 427.5082\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2237 - mse: 0.2237 - val_loss: 9874.8125 - val_mse: 9874.8125\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2476 - mse: 0.2476 - val_loss: 12.1696 - val_mse: 12.1696\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2011 - mse: 0.2011 - val_loss: 4193.6636 - val_mse: 4193.6636\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1985 - mse: 0.1985 - val_loss: 3542.9475 - val_mse: 3542.9475\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1828 - mse: 0.1828 - val_loss: 59.5468 - val_mse: 59.5468\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1774 - mse: 0.1774 - val_loss: 4167.7109 - val_mse: 4167.7109\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1633 - mse: 0.1633 - val_loss: 2.1316 - val_mse: 2.1316\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1566 - mse: 0.1566 - val_loss: 20170.9121 - val_mse: 20170.9121\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1543 - mse: 0.1543 - val_loss: 1533.9540 - val_mse: 1533.9540\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1614 - mse: 0.1614 - val_loss: 8.8165 - val_mse: 8.8165\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1496 - mse: 0.1496 - val_loss: 44.9019 - val_mse: 44.9019\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1388 - mse: 0.1388 - val_loss: 43.2156 - val_mse: 43.2156\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1350 - mse: 0.1350 - val_loss: 28109.7676 - val_mse: 28109.7676\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1375 - mse: 0.1375 - val_loss: 4292.4146 - val_mse: 4292.4146\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1454 - mse: 0.1454 - val_loss: 698.1846 - val_mse: 698.1846\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1227 - mse: 0.1227 - val_loss: 12.8949 - val_mse: 12.8949\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1373 - mse: 0.1373 - val_loss: 1564.8138 - val_mse: 1564.8138\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "97\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6286 - mse: 0.6286 - val_loss: 1765.3013 - val_mse: 1765.3013\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3840 - mse: 0.3840 - val_loss: 924.8531 - val_mse: 924.8531\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3073 - mse: 0.3073 - val_loss: 366.7061 - val_mse: 366.7061\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2781 - mse: 0.2781 - val_loss: 9.4976 - val_mse: 9.4976\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2595 - mse: 0.2595 - val_loss: 1453.3208 - val_mse: 1453.3208\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2296 - mse: 0.2296 - val_loss: 5098.2075 - val_mse: 5098.2075\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2383 - mse: 0.2383 - val_loss: 13.0214 - val_mse: 13.0214\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2034 - mse: 0.2034 - val_loss: 540.3070 - val_mse: 540.3070\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2064 - mse: 0.2064 - val_loss: 2121.8008 - val_mse: 2121.8008\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1832 - mse: 0.1832 - val_loss: 0.9300 - val_mse: 0.9300\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1912 - mse: 0.1912 - val_loss: 50883.3789 - val_mse: 50883.3789\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1826 - mse: 0.1826 - val_loss: 4.4518 - val_mse: 4.4518\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1562 - mse: 0.1562 - val_loss: 1421.2413 - val_mse: 1421.2413\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1599 - mse: 0.1599 - val_loss: 5897.7422 - val_mse: 5897.7422\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1617 - mse: 0.1617 - val_loss: 0.7766 - val_mse: 0.7766\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1524 - mse: 0.1524 - val_loss: 0.6058 - val_mse: 0.6058\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1392 - mse: 0.1392 - val_loss: 3.2812 - val_mse: 3.2812\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1455 - mse: 0.1455 - val_loss: 9.8099 - val_mse: 9.8099\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1545 - mse: 0.1545 - val_loss: 23858.1133 - val_mse: 23858.1133\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1557 - mse: 0.1557 - val_loss: 12533.2822 - val_mse: 12533.2822\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1303 - mse: 0.1303 - val_loss: 11.0996 - val_mse: 11.0996\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1327 - mse: 0.1327 - val_loss: 14.1589 - val_mse: 14.1589\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1191 - mse: 0.1191 - val_loss: 1246.9949 - val_mse: 1246.9949\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1235 - mse: 0.1235 - val_loss: 67.7725 - val_mse: 67.7725\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1320 - mse: 0.1320 - val_loss: 34.3978 - val_mse: 34.3978\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1472 - mse: 0.1472 - val_loss: 154.4624 - val_mse: 154.4624\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "98\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 8ms/step - loss: 0.6179 - mse: 0.6179 - val_loss: 0.6409 - val_mse: 0.6409\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3824 - mse: 0.3824 - val_loss: 2.2938 - val_mse: 2.2938\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3281 - mse: 0.3281 - val_loss: 10.3387 - val_mse: 10.3387\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2870 - mse: 0.2870 - val_loss: 36.8480 - val_mse: 36.8480\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2605 - mse: 0.2605 - val_loss: 370.0465 - val_mse: 370.0465\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 8587.3174 - val_mse: 8587.3174\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2460 - mse: 0.2460 - val_loss: 3.4973 - val_mse: 3.4973\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2139 - mse: 0.2139 - val_loss: 483.4260 - val_mse: 483.4260\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2170 - mse: 0.2170 - val_loss: 70.5347 - val_mse: 70.5347\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1729 - mse: 0.1729 - val_loss: 286.2891 - val_mse: 286.2891\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1892 - mse: 0.1892 - val_loss: 29636.9297 - val_mse: 29636.9297\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "99\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 8ms/step - loss: 0.6902 - mse: 0.6902 - val_loss: 746.8294 - val_mse: 746.8294\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.4165 - mse: 0.4165 - val_loss: 77.8064 - val_mse: 77.8064\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3255 - mse: 0.3255 - val_loss: 45.8743 - val_mse: 45.8743\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2740 - mse: 0.2740 - val_loss: 39.9891 - val_mse: 39.9891\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2604 - mse: 0.2604 - val_loss: 761.9308 - val_mse: 761.9308\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2507 - mse: 0.2507 - val_loss: 9538.2910 - val_mse: 9538.2910\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2593 - mse: 0.2593 - val_loss: 37.0169 - val_mse: 37.0169\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2220 - mse: 0.2220 - val_loss: 6677.7734 - val_mse: 6677.7734\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2327 - mse: 0.2327 - val_loss: 129.6324 - val_mse: 129.6324\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1859 - mse: 0.1859 - val_loss: 1476.5295 - val_mse: 1476.5295\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1874 - mse: 0.1874 - val_loss: 25867.7852 - val_mse: 25867.7852\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 203.4124 - val_mse: 203.4124\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1802 - mse: 0.1802 - val_loss: 764.9901 - val_mse: 764.9901\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1566 - mse: 0.1566 - val_loss: 7670.6821 - val_mse: 7670.6821\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1720 - mse: 0.1720 - val_loss: 65.5606 - val_mse: 65.5606\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1561 - mse: 0.1561 - val_loss: 23.3880 - val_mse: 23.3880\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1510 - mse: 0.1510 - val_loss: 4723.7549 - val_mse: 4723.7549\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1461 - mse: 0.1461 - val_loss: 71314.1328 - val_mse: 71314.1328\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 4111.3979 - val_mse: 4111.3979\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1566 - mse: 0.1566 - val_loss: 426.3812 - val_mse: 426.3812\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1656 - mse: 0.1656 - val_loss: 3172.8586 - val_mse: 3172.8586\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1384 - mse: 0.1384 - val_loss: 939.6552 - val_mse: 939.6552\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1277 - mse: 0.1277 - val_loss: 3.7961 - val_mse: 3.7961\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1255 - mse: 0.1255 - val_loss: 87.6854 - val_mse: 87.6854\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1354 - mse: 0.1354 - val_loss: 2933.5264 - val_mse: 2933.5264\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 23961.7324 - val_mse: 23961.7324\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1237 - mse: 0.1237 - val_loss: 87.4618 - val_mse: 87.4618\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1236 - mse: 0.1236 - val_loss: 0.6640 - val_mse: 0.6640\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1245 - mse: 0.1245 - val_loss: 1980.8319 - val_mse: 1980.8319\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1242 - mse: 0.1242 - val_loss: 324.5791 - val_mse: 324.5791\n",
      "Epoch 31/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1284 - mse: 0.1284 - val_loss: 5025.8950 - val_mse: 5025.8950\n",
      "Epoch 32/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1136 - mse: 0.1136 - val_loss: 18520.3633 - val_mse: 18520.3633\n",
      "Epoch 33/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1273 - mse: 0.1273 - val_loss: 2.7514 - val_mse: 2.7514\n",
      "Epoch 34/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 10.8686 - val_mse: 10.8686\n",
      "Epoch 35/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 2.2290 - val_mse: 2.2290\n",
      "Epoch 36/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1238 - mse: 0.1238 - val_loss: 142.0171 - val_mse: 142.0171\n",
      "Epoch 37/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1081 - mse: 0.1081 - val_loss: 20.3486 - val_mse: 20.3486\n",
      "Epoch 38/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 223.2709 - val_mse: 223.2709\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "100\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6591 - mse: 0.6591 - val_loss: 340.7007 - val_mse: 340.7007\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4128 - mse: 0.4128 - val_loss: 1499.9049 - val_mse: 1499.9049\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3307 - mse: 0.3307 - val_loss: 498.2972 - val_mse: 498.2972\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2913 - mse: 0.2913 - val_loss: 2.0937 - val_mse: 2.0937\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2625 - mse: 0.2625 - val_loss: 30.1388 - val_mse: 30.1388\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2493 - mse: 0.2493 - val_loss: 20925.6211 - val_mse: 20925.6211\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2649 - mse: 0.2649 - val_loss: 4.5052 - val_mse: 4.5052\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2310 - mse: 0.2310 - val_loss: 3082.5146 - val_mse: 3082.5146\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2307 - mse: 0.2307 - val_loss: 29.5355 - val_mse: 29.5355\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1883 - mse: 0.1883 - val_loss: 98.6930 - val_mse: 98.6930\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1813 - mse: 0.1813 - val_loss: 4168.2285 - val_mse: 4168.2285\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1720 - mse: 0.1720 - val_loss: 9.8341 - val_mse: 9.8341\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1691 - mse: 0.1691 - val_loss: 7087.1572 - val_mse: 7087.1572\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1571 - mse: 0.1571 - val_loss: 46.8381 - val_mse: 46.8381\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "101\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.7511 - mse: 0.7511 - val_loss: 1.4251 - val_mse: 1.4251\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3996 - mse: 0.3996 - val_loss: 396.3833 - val_mse: 396.3833\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3436 - mse: 0.3436 - val_loss: 753.4192 - val_mse: 753.4192\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2804 - mse: 0.2804 - val_loss: 7.0419 - val_mse: 7.0419\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2602 - mse: 0.2602 - val_loss: 50.1986 - val_mse: 50.1986\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2506 - mse: 0.2506 - val_loss: 8745.8223 - val_mse: 8745.8223\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 188.0014 - val_mse: 188.0014\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2054 - mse: 0.2054 - val_loss: 4726.1064 - val_mse: 4726.1064\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 2509.7646 - val_mse: 2509.7646\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1991 - mse: 0.1991 - val_loss: 6.9023 - val_mse: 6.9023\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1954 - mse: 0.1954 - val_loss: 12178.9756 - val_mse: 12178.9756\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "102\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.6150 - mse: 0.6150 - val_loss: 144.0823 - val_mse: 144.0823\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3922 - mse: 0.3922 - val_loss: 63.7957 - val_mse: 63.7957\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.3080 - mse: 0.3080 - val_loss: 5264.7988 - val_mse: 5264.7988\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2786 - mse: 0.2786 - val_loss: 180.1490 - val_mse: 180.1490\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2771 - mse: 0.2771 - val_loss: 217.1876 - val_mse: 217.1876\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2385 - mse: 0.2385 - val_loss: 30385.0996 - val_mse: 30385.0996\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2343 - mse: 0.2343 - val_loss: 0.5988 - val_mse: 0.5988\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1990 - mse: 0.1990 - val_loss: 1420.3779 - val_mse: 1420.3779\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.2140 - mse: 0.2140 - val_loss: 18.6605 - val_mse: 18.6605\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1800 - mse: 0.1800 - val_loss: 119.7738 - val_mse: 119.7738\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1766 - mse: 0.1766 - val_loss: 5422.1201 - val_mse: 5422.1201\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1707 - mse: 0.1707 - val_loss: 48.1828 - val_mse: 48.1828\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1567 - mse: 0.1567 - val_loss: 7113.5835 - val_mse: 7113.5835\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 241.6289 - val_mse: 241.6289\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1669 - mse: 0.1669 - val_loss: 55.8899 - val_mse: 55.8899\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1610 - mse: 0.1610 - val_loss: 72.6855 - val_mse: 72.6855\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.1427 - mse: 0.1427 - val_loss: 882.6158 - val_mse: 882.6158\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "103\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 8ms/step - loss: 0.6276 - mse: 0.6276 - val_loss: 7.6859 - val_mse: 7.6859\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3924 - mse: 0.3924 - val_loss: 20.2033 - val_mse: 20.2033\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3212 - mse: 0.3212 - val_loss: 27.6858 - val_mse: 27.6858\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2786 - mse: 0.2786 - val_loss: 22.9257 - val_mse: 22.9257\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2774 - mse: 0.2774 - val_loss: 4604.2637 - val_mse: 4604.2637\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2402 - mse: 0.2402 - val_loss: 14259.4746 - val_mse: 14259.4746\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2452 - mse: 0.2452 - val_loss: 17.3312 - val_mse: 17.3312\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2084 - mse: 0.2084 - val_loss: 1029.4998 - val_mse: 1029.4998\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2198 - mse: 0.2198 - val_loss: 344.4246 - val_mse: 344.4246\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1888 - mse: 0.1888 - val_loss: 259.9539 - val_mse: 259.9539\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1832 - mse: 0.1832 - val_loss: 11988.1758 - val_mse: 11988.1758\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "104\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 8ms/step - loss: 0.6419 - mse: 0.6419 - val_loss: 123.4367 - val_mse: 123.4367\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3917 - mse: 0.3917 - val_loss: 163.8985 - val_mse: 163.8985\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3141 - mse: 0.3141 - val_loss: 417.9607 - val_mse: 417.9607\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2965 - mse: 0.2965 - val_loss: 9.3857 - val_mse: 9.3857\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2617 - mse: 0.2617 - val_loss: 121.6924 - val_mse: 121.6924\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2540 - mse: 0.2540 - val_loss: 8305.5088 - val_mse: 8305.5088\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2477 - mse: 0.2477 - val_loss: 4.3145 - val_mse: 4.3145\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2126 - mse: 0.2126 - val_loss: 3034.7180 - val_mse: 3034.7180\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2143 - mse: 0.2143 - val_loss: 3913.2673 - val_mse: 3913.2673\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1767 - mse: 0.1767 - val_loss: 1.3089 - val_mse: 1.3089\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1855 - mse: 0.1855 - val_loss: 23995.7344 - val_mse: 23995.7344\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1846 - mse: 0.1846 - val_loss: 159.9361 - val_mse: 159.9361\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1587 - mse: 0.1587 - val_loss: 3467.1785 - val_mse: 3467.1785\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1445 - mse: 0.1445 - val_loss: 343.2166 - val_mse: 343.2166\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1718 - mse: 0.1718 - val_loss: 6.2469 - val_mse: 6.2469\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1549 - mse: 0.1549 - val_loss: 113.8297 - val_mse: 113.8297\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1817 - mse: 0.1817 - val_loss: 6902.9434 - val_mse: 6902.9434\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1431 - mse: 0.1431 - val_loss: 2292.5461 - val_mse: 2292.5461\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1451 - mse: 0.1451 - val_loss: 2874.9954 - val_mse: 2874.9954\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1604 - mse: 0.1604 - val_loss: 133.5820 - val_mse: 133.5820\n",
      "169/169 [==============================] - 0s 2ms/step\n",
      "105\n",
      "Epoch 1/100\n",
      "278/278 [==============================] - 4s 7ms/step - loss: 0.5765 - mse: 0.5765 - val_loss: 2.2902 - val_mse: 2.2902\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3767 - mse: 0.3767 - val_loss: 75.9371 - val_mse: 75.9371\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.3128 - mse: 0.3128 - val_loss: 652.4681 - val_mse: 652.4681\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2967 - mse: 0.2967 - val_loss: 162.7079 - val_mse: 162.7079\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2545 - mse: 0.2545 - val_loss: 481.0160 - val_mse: 481.0160\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2410 - mse: 0.2410 - val_loss: 10429.8447 - val_mse: 10429.8447\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2442 - mse: 0.2442 - val_loss: 149.9951 - val_mse: 149.9951\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2135 - mse: 0.2135 - val_loss: 3573.5327 - val_mse: 3573.5327\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.2156 - mse: 0.2156 - val_loss: 2442.8918 - val_mse: 2442.8918\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1905 - mse: 0.1905 - val_loss: 32.6798 - val_mse: 32.6798\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.1831 - mse: 0.1831 - val_loss: 30678.9648 - val_mse: 30678.9648\n",
      "169/169 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of components: 85\n",
      "RMSE: 0.05065266960077463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "best_rmse = np.inf  # Start with infinity so that any score will be better\n",
    "best_n = 0\n",
    "\n",
    "for nn in range(1, X_train.shape[1]+1):  # Start from 1 as PCA with 0 components doesn't make sense\n",
    "    # Create a PCA object, specifying how many components you wish to keep\n",
    "    pca = PCA(n_components=nn)\n",
    "    print(nn)\n",
    "    # Fit the PCA model to your data and then apply the dimensionality reduction on train and test data\n",
    "    pca.fit(X_train)\n",
    "    X_pca_train = pca.transform(X_train_scaled)\n",
    "    X_pca_test = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Define the model structure\n",
    "    model = Sequential()\n",
    "    model.add(Dense(96, input_dim=nn))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(384))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    # Define learning rate decay\n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                                decay_steps=10000,\n",
    "                                decay_rate=0.9)\n",
    "\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "    history = model.fit(X_pca_train, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_scaled = model.predict(X_pca_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "\n",
    "    # If this RMSE is the best we've seen, store this n_components and score\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_n = nn\n",
    "\n",
    "print(f\"Best number of components: {best_n}\")\n",
    "print(f\"RMSE: {best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777ba49",
   "metadata": {},
   "source": [
    "# Each RunId Window PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb9d163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(4 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(4).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(4).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(4).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a283f069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0909a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51b2ce8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "355a4a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01f25462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d4a3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b9c376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "Best number of components: 45\n",
      "RMSE: 0.007351375686733284\n"
     ]
    }
   ],
   "source": [
    "best_rmse = np.inf  # Start with infinity so that any score will be better\n",
    "best_n = 0\n",
    "\n",
    "for nn in range(1, X_train.shape[1]+1):  # Start from 1 as PCA with 0 components doesn't make sense\n",
    "    # Create a PCA object, specifying how many components you wish to keep\n",
    "    pca = PCA(n_components=nn)\n",
    "    print(nn)\n",
    "    # Fit the PCA model to your data and then apply the dimensionality reduction on train and test data\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_pca_train = pca.transform(X_train_scaled)\n",
    "    X_pca_test = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Create a RandomForestRegressor with the best parameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators= 400, \n",
    "        min_samples_split=5, \n",
    "        min_samples_leaf=1, \n",
    "        max_features=\"log2\", \n",
    "        max_depth=30, \n",
    "        bootstrap=False,\n",
    "        random_state=42,  # Seed\n",
    "        n_jobs=-1  # Use all processors\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_pca_train, Y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_pca_test)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "\n",
    "    # If this RMSE is the best we've seen, store this n_components and score\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_n = nn\n",
    "\n",
    "print(f\"Best number of components: {best_n}\")\n",
    "print(f\"RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eca73330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 1.0372 - mse: 1.0372 - val_loss: 3874.2756 - val_mse: 3874.2756\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9689 - mse: 0.9689 - val_loss: 4082.3118 - val_mse: 4082.3118\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9598 - mse: 0.9598 - val_loss: 7870.0190 - val_mse: 7870.0190\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9697 - mse: 0.9697 - val_loss: 6390.7173 - val_mse: 6390.7173\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9621 - mse: 0.9621 - val_loss: 1810.7070 - val_mse: 1810.7070\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9595 - mse: 0.9595 - val_loss: 327.9822 - val_mse: 327.9822\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9587 - mse: 0.9587 - val_loss: 19943.5449 - val_mse: 19943.5449\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9577 - mse: 0.9577 - val_loss: 1760.8787 - val_mse: 1760.8787\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9553 - mse: 0.9553 - val_loss: 8.2689 - val_mse: 8.2689\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9562 - mse: 0.9562 - val_loss: 7879.5376 - val_mse: 7879.5376\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9543 - mse: 0.9543 - val_loss: 13027.1729 - val_mse: 13027.1729\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9501 - mse: 0.9501 - val_loss: 51653.5352 - val_mse: 51653.5352\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9494 - mse: 0.9494 - val_loss: 21812.4512 - val_mse: 21812.4512\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9470 - mse: 0.9470 - val_loss: 6403.0474 - val_mse: 6403.0474\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9459 - mse: 0.9459 - val_loss: 2373.2878 - val_mse: 2373.2878\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9442 - mse: 0.9442 - val_loss: 88139.6641 - val_mse: 88139.6641\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9472 - mse: 0.9472 - val_loss: 877.6489 - val_mse: 877.6489\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9445 - mse: 0.9445 - val_loss: 23218.4863 - val_mse: 23218.4863\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.9459 - mse: 0.9459 - val_loss: 137.9751 - val_mse: 137.9751\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "2\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.5301 - mse: 0.5301 - val_loss: 718.0699 - val_mse: 718.0699\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4581 - mse: 0.4581 - val_loss: 1359.7904 - val_mse: 1359.7904\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4405 - mse: 0.4405 - val_loss: 1213.0394 - val_mse: 1213.0394\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4287 - mse: 0.4287 - val_loss: 878.5309 - val_mse: 878.5309\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4239 - mse: 0.4239 - val_loss: 1170.8983 - val_mse: 1170.8983\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4254 - mse: 0.4254 - val_loss: 485.5824 - val_mse: 485.5824\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4145 - mse: 0.4145 - val_loss: 146.6111 - val_mse: 146.6111\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4157 - mse: 0.4157 - val_loss: 835.1841 - val_mse: 835.1841\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4182 - mse: 0.4182 - val_loss: 2041.7827 - val_mse: 2041.7827\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4212 - mse: 0.4212 - val_loss: 119.0259 - val_mse: 119.0259\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4202 - mse: 0.4202 - val_loss: 3.0804 - val_mse: 3.0804\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4113 - mse: 0.4113 - val_loss: 4470.3950 - val_mse: 4470.3950\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4133 - mse: 0.4133 - val_loss: 112.7579 - val_mse: 112.7579\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4063 - mse: 0.4063 - val_loss: 304.9458 - val_mse: 304.9458\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4030 - mse: 0.4030 - val_loss: 3232.7466 - val_mse: 3232.7466\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4053 - mse: 0.4053 - val_loss: 1018.3495 - val_mse: 1018.3495\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4035 - mse: 0.4035 - val_loss: 7117.3506 - val_mse: 7117.3506\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3982 - mse: 0.3982 - val_loss: 19.9855 - val_mse: 19.9855\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4062 - mse: 0.4062 - val_loss: 449.9338 - val_mse: 449.9338\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3951 - mse: 0.3951 - val_loss: 7622.4624 - val_mse: 7622.4624\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3961 - mse: 0.3961 - val_loss: 163.8854 - val_mse: 163.8854\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "3\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.6075 - mse: 0.6075 - val_loss: 1057.3453 - val_mse: 1057.3453\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.5018 - mse: 0.5018 - val_loss: 4.0394 - val_mse: 4.0394\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4699 - mse: 0.4699 - val_loss: 9.2041 - val_mse: 9.2041\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4593 - mse: 0.4593 - val_loss: 31.5140 - val_mse: 31.5140\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4491 - mse: 0.4491 - val_loss: 30.1200 - val_mse: 30.1200\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4450 - mse: 0.4450 - val_loss: 26.6479 - val_mse: 26.6479\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4349 - mse: 0.4349 - val_loss: 729.5732 - val_mse: 729.5732\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4251 - mse: 0.4251 - val_loss: 1367.3955 - val_mse: 1367.3955\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4234 - mse: 0.4234 - val_loss: 493.1775 - val_mse: 493.1775\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4178 - mse: 0.4178 - val_loss: 886.7617 - val_mse: 886.7617\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4130 - mse: 0.4130 - val_loss: 842.4428 - val_mse: 842.4428\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.4024 - mse: 0.4024 - val_loss: 3804.7471 - val_mse: 3804.7471\n",
      "674/674 [==============================] - 2s 2ms/step\n",
      "4\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.6189 - mse: 0.6189 - val_loss: 2882.5491 - val_mse: 2882.5491\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.5233 - mse: 0.5233 - val_loss: 767.4290 - val_mse: 767.4290\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4819 - mse: 0.4819 - val_loss: 151.8295 - val_mse: 151.8295\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4563 - mse: 0.4563 - val_loss: 6.2095 - val_mse: 6.2095\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4483 - mse: 0.4483 - val_loss: 1795.7236 - val_mse: 1795.7236\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4463 - mse: 0.4463 - val_loss: 1446.2911 - val_mse: 1446.2911\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4246 - mse: 0.4246 - val_loss: 75.6556 - val_mse: 75.6556\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4232 - mse: 0.4232 - val_loss: 12.6747 - val_mse: 12.6747\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4236 - mse: 0.4236 - val_loss: 2322.5596 - val_mse: 2322.5596\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4175 - mse: 0.4175 - val_loss: 1.4159 - val_mse: 1.4159\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4170 - mse: 0.4170 - val_loss: 361.5924 - val_mse: 361.5924\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3965 - mse: 0.3965 - val_loss: 401.8905 - val_mse: 401.8905\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3973 - mse: 0.3973 - val_loss: 38.4109 - val_mse: 38.4109\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3934 - mse: 0.3934 - val_loss: 10.3730 - val_mse: 10.3730\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3958 - mse: 0.3958 - val_loss: 7.0119 - val_mse: 7.0119\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3879 - mse: 0.3879 - val_loss: 38.5820 - val_mse: 38.5820\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3839 - mse: 0.3839 - val_loss: 124.1256 - val_mse: 124.1256\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3791 - mse: 0.3791 - val_loss: 138.4083 - val_mse: 138.4083\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3855 - mse: 0.3855 - val_loss: 362.5682 - val_mse: 362.5682\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3727 - mse: 0.3727 - val_loss: 178.2498 - val_mse: 178.2498\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "5\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.5067 - mse: 0.5067 - val_loss: 1299.5537 - val_mse: 1299.5537\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3951 - mse: 0.3951 - val_loss: 454.2545 - val_mse: 454.2545\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3713 - mse: 0.3713 - val_loss: 1709.5609 - val_mse: 1709.5609\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3647 - mse: 0.3647 - val_loss: 5.0062 - val_mse: 5.0062\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3535 - mse: 0.3535 - val_loss: 124.2543 - val_mse: 124.2543\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3489 - mse: 0.3489 - val_loss: 6359.8140 - val_mse: 6359.8140\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3245 - mse: 0.3245 - val_loss: 869.0715 - val_mse: 869.0715\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3268 - mse: 0.3268 - val_loss: 1432.2073 - val_mse: 1432.2073\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3251 - mse: 0.3251 - val_loss: 1625.2776 - val_mse: 1625.2776\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3095 - mse: 0.3095 - val_loss: 2755.9060 - val_mse: 2755.9060\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3135 - mse: 0.3135 - val_loss: 166.5309 - val_mse: 166.5309\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2971 - mse: 0.2971 - val_loss: 1911.2782 - val_mse: 1911.2782\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3033 - mse: 0.3033 - val_loss: 10.1628 - val_mse: 10.1628\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3006 - mse: 0.3006 - val_loss: 71.3685 - val_mse: 71.3685\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "6\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.4569 - mse: 0.4569 - val_loss: 480.8509 - val_mse: 480.8509\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3605 - mse: 0.3605 - val_loss: 74.3315 - val_mse: 74.3315\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3338 - mse: 0.3338 - val_loss: 100.1054 - val_mse: 100.1054\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3276 - mse: 0.3276 - val_loss: 1.9264 - val_mse: 1.9264\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3230 - mse: 0.3230 - val_loss: 130.3855 - val_mse: 130.3855\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3233 - mse: 0.3233 - val_loss: 85.0174 - val_mse: 85.0174\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2982 - mse: 0.2982 - val_loss: 18.5955 - val_mse: 18.5955\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2996 - mse: 0.2996 - val_loss: 238.1638 - val_mse: 238.1638\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3062 - mse: 0.3062 - val_loss: 12889.0684 - val_mse: 12889.0684\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2962 - mse: 0.2962 - val_loss: 314.2682 - val_mse: 314.2682\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2912 - mse: 0.2912 - val_loss: 2905.9219 - val_mse: 2905.9219\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2883 - mse: 0.2883 - val_loss: 69.6606 - val_mse: 69.6606\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2855 - mse: 0.2855 - val_loss: 21.2020 - val_mse: 21.2020\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2774 - mse: 0.2774 - val_loss: 539.6665 - val_mse: 539.6665\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "7\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.4410 - mse: 0.4410 - val_loss: 1038.2386 - val_mse: 1038.2386\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3512 - mse: 0.3512 - val_loss: 2.9528 - val_mse: 2.9528\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3289 - mse: 0.3289 - val_loss: 697.4179 - val_mse: 697.4179\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3221 - mse: 0.3221 - val_loss: 182.8846 - val_mse: 182.8846\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3091 - mse: 0.3091 - val_loss: 997.4980 - val_mse: 997.4980\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3068 - mse: 0.3068 - val_loss: 57.1789 - val_mse: 57.1789\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2815 - mse: 0.2815 - val_loss: 27.4242 - val_mse: 27.4242\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2834 - mse: 0.2834 - val_loss: 549.7739 - val_mse: 549.7739\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2855 - mse: 0.2855 - val_loss: 2620.8706 - val_mse: 2620.8706\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2782 - mse: 0.2782 - val_loss: 207.0455 - val_mse: 207.0455\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2816 - mse: 0.2816 - val_loss: 94.4211 - val_mse: 94.4211\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2678 - mse: 0.2678 - val_loss: 53.0286 - val_mse: 53.0286\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "8\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4253 - mse: 0.4253 - val_loss: 22.6874 - val_mse: 22.6874\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3413 - mse: 0.3413 - val_loss: 57.0967 - val_mse: 57.0967\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3187 - mse: 0.3187 - val_loss: 41.3329 - val_mse: 41.3329\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3097 - mse: 0.3097 - val_loss: 44.6194 - val_mse: 44.6194\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2957 - mse: 0.2957 - val_loss: 253.1738 - val_mse: 253.1738\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2993 - mse: 0.2993 - val_loss: 390.9282 - val_mse: 390.9282\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2772 - mse: 0.2772 - val_loss: 881.7652 - val_mse: 881.7652\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2800 - mse: 0.2800 - val_loss: 35.2573 - val_mse: 35.2573\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2757 - mse: 0.2757 - val_loss: 245.1324 - val_mse: 245.1324\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2684 - mse: 0.2684 - val_loss: 69.8604 - val_mse: 69.8604\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2650 - mse: 0.2650 - val_loss: 1164.7510 - val_mse: 1164.7510\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "9\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4228 - mse: 0.4228 - val_loss: 84.8454 - val_mse: 84.8454\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3345 - mse: 0.3345 - val_loss: 63.8378 - val_mse: 63.8378\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3127 - mse: 0.3127 - val_loss: 2952.5227 - val_mse: 2952.5227\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3092 - mse: 0.3092 - val_loss: 455.3878 - val_mse: 455.3878\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2958 - mse: 0.2958 - val_loss: 49.5796 - val_mse: 49.5796\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2992 - mse: 0.2992 - val_loss: 85.6215 - val_mse: 85.6215\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2776 - mse: 0.2776 - val_loss: 30.1124 - val_mse: 30.1124\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2722 - mse: 0.2722 - val_loss: 89.1615 - val_mse: 89.1615\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2736 - mse: 0.2736 - val_loss: 512.0448 - val_mse: 512.0448\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2712 - mse: 0.2712 - val_loss: 458.2644 - val_mse: 458.2644\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2623 - mse: 0.2623 - val_loss: 216.0532 - val_mse: 216.0532\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 21.9027 - val_mse: 21.9027\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2484 - mse: 0.2484 - val_loss: 32.1179 - val_mse: 32.1179\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2414 - mse: 0.2414 - val_loss: 402.5683 - val_mse: 402.5683\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2516 - mse: 0.2516 - val_loss: 55.5590 - val_mse: 55.5590\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2445 - mse: 0.2445 - val_loss: 123.4734 - val_mse: 123.4734\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2337 - mse: 0.2337 - val_loss: 120.3787 - val_mse: 120.3787\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2344 - mse: 0.2344 - val_loss: 1.2495 - val_mse: 1.2495\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2409 - mse: 0.2409 - val_loss: 696.9463 - val_mse: 696.9463\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 25.6355 - val_mse: 25.6355\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2298 - mse: 0.2298 - val_loss: 1297.7465 - val_mse: 1297.7465\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2278 - mse: 0.2278 - val_loss: 21.8986 - val_mse: 21.8986\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 116.9498 - val_mse: 116.9498\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 365.5322 - val_mse: 365.5322\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2217 - mse: 0.2217 - val_loss: 215.0269 - val_mse: 215.0269\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2240 - mse: 0.2240 - val_loss: 212.6695 - val_mse: 212.6695\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2177 - mse: 0.2177 - val_loss: 150.8112 - val_mse: 150.8112\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2208 - mse: 0.2208 - val_loss: 241.0435 - val_mse: 241.0435\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "10\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4059 - mse: 0.4059 - val_loss: 325.5567 - val_mse: 325.5567\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3211 - mse: 0.3211 - val_loss: 346.3969 - val_mse: 346.3969\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2954 - mse: 0.2954 - val_loss: 10332.3955 - val_mse: 10332.3955\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2857 - mse: 0.2857 - val_loss: 2.0076 - val_mse: 2.0076\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2727 - mse: 0.2727 - val_loss: 0.9592 - val_mse: 0.9592\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2687 - mse: 0.2687 - val_loss: 2.9851 - val_mse: 2.9851\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2508 - mse: 0.2508 - val_loss: 15.5068 - val_mse: 15.5068\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2512 - mse: 0.2512 - val_loss: 628.4512 - val_mse: 628.4512\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2486 - mse: 0.2486 - val_loss: 871.7944 - val_mse: 871.7944\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2426 - mse: 0.2426 - val_loss: 796.7469 - val_mse: 796.7469\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2370 - mse: 0.2370 - val_loss: 1494.7936 - val_mse: 1494.7936\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2282 - mse: 0.2282 - val_loss: 11.6212 - val_mse: 11.6212\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2239 - mse: 0.2239 - val_loss: 379.3918 - val_mse: 379.3918\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2146 - mse: 0.2146 - val_loss: 87.6137 - val_mse: 87.6137\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2217 - mse: 0.2217 - val_loss: 2.9452 - val_mse: 2.9452\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "11\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.4033 - mse: 0.4033 - val_loss: 1746.1820 - val_mse: 1746.1820\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3147 - mse: 0.3147 - val_loss: 79.8538 - val_mse: 79.8538\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2994 - mse: 0.2994 - val_loss: 1380.5548 - val_mse: 1380.5548\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2904 - mse: 0.2904 - val_loss: 29.5355 - val_mse: 29.5355\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2779 - mse: 0.2779 - val_loss: 1236.5718 - val_mse: 1236.5718\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2792 - mse: 0.2792 - val_loss: 25.4958 - val_mse: 25.4958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2603 - mse: 0.2603 - val_loss: 142.4119 - val_mse: 142.4119\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2602 - mse: 0.2602 - val_loss: 3892.8225 - val_mse: 3892.8225\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 665.9684 - val_mse: 665.9684\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2514 - mse: 0.2514 - val_loss: 361.0112 - val_mse: 361.0112\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2449 - mse: 0.2449 - val_loss: 1447.7670 - val_mse: 1447.7670\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2292 - mse: 0.2292 - val_loss: 2.2890 - val_mse: 2.2890\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2244 - mse: 0.2244 - val_loss: 1.1103 - val_mse: 1.1103\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 885.3008 - val_mse: 885.3008\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 98.7875 - val_mse: 98.7875\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 6432.3608 - val_mse: 6432.3608\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2143 - mse: 0.2143 - val_loss: 415.8096 - val_mse: 415.8096\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2035 - mse: 0.2035 - val_loss: 64.1555 - val_mse: 64.1555\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2114 - mse: 0.2114 - val_loss: 114.6090 - val_mse: 114.6090\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2047 - mse: 0.2047 - val_loss: 391.5693 - val_mse: 391.5693\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2003 - mse: 0.2003 - val_loss: 45.8333 - val_mse: 45.8333\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2076 - mse: 0.2076 - val_loss: 612.1597 - val_mse: 612.1597\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1992 - mse: 0.1992 - val_loss: 139.6902 - val_mse: 139.6902\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "12\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.4152 - mse: 0.4152 - val_loss: 37.9718 - val_mse: 37.9718\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3034 - mse: 0.3034 - val_loss: 28.0055 - val_mse: 28.0055\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2797 - mse: 0.2797 - val_loss: 2228.5947 - val_mse: 2228.5947\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2688 - mse: 0.2688 - val_loss: 4.9604 - val_mse: 4.9604\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2572 - mse: 0.2572 - val_loss: 364.5875 - val_mse: 364.5875\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2578 - mse: 0.2578 - val_loss: 517.9429 - val_mse: 517.9429\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2297 - mse: 0.2297 - val_loss: 0.9618 - val_mse: 0.9618\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2329 - mse: 0.2329 - val_loss: 773.8587 - val_mse: 773.8587\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 2275.3567 - val_mse: 2275.3567\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2160 - mse: 0.2160 - val_loss: 69.1096 - val_mse: 69.1096\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2101 - mse: 0.2101 - val_loss: 130.6987 - val_mse: 130.6987\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2162 - mse: 0.2162 - val_loss: 192.5174 - val_mse: 192.5174\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2101 - mse: 0.2101 - val_loss: 0.7398 - val_mse: 0.7398\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1986 - mse: 0.1986 - val_loss: 715.8610 - val_mse: 715.8610\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2006 - mse: 0.2006 - val_loss: 19.0994 - val_mse: 19.0994\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2018 - mse: 0.2018 - val_loss: 2712.1270 - val_mse: 2712.1270\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1916 - mse: 0.1916 - val_loss: 50.6124 - val_mse: 50.6124\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1843 - mse: 0.1843 - val_loss: 71.0999 - val_mse: 71.0999\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1915 - mse: 0.1915 - val_loss: 1352.5670 - val_mse: 1352.5670\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1871 - mse: 0.1871 - val_loss: 286.8150 - val_mse: 286.8150\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1824 - mse: 0.1824 - val_loss: 88.6747 - val_mse: 88.6747\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1839 - mse: 0.1839 - val_loss: 42.8710 - val_mse: 42.8710\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1869 - mse: 0.1869 - val_loss: 3.7770 - val_mse: 3.7770\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "13\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3732 - mse: 0.3732 - val_loss: 142.9326 - val_mse: 142.9326\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3045 - mse: 0.3045 - val_loss: 503.5558 - val_mse: 503.5558\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2812 - mse: 0.2812 - val_loss: 2145.5242 - val_mse: 2145.5242\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2779 - mse: 0.2779 - val_loss: 132.1140 - val_mse: 132.1140\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2658 - mse: 0.2658 - val_loss: 28.6581 - val_mse: 28.6581\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2580 - mse: 0.2580 - val_loss: 278.6049 - val_mse: 278.6049\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2445 - mse: 0.2445 - val_loss: 1.4505 - val_mse: 1.4505\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2341 - mse: 0.2341 - val_loss: 1232.7478 - val_mse: 1232.7478\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2317 - mse: 0.2317 - val_loss: 273.9959 - val_mse: 273.9959\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 30.8413 - val_mse: 30.8413\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2216 - mse: 0.2216 - val_loss: 15.1537 - val_mse: 15.1537\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2069 - mse: 0.2069 - val_loss: 15.1904 - val_mse: 15.1904\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2019 - mse: 0.2019 - val_loss: 86.2948 - val_mse: 86.2948\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2125 - mse: 0.2125 - val_loss: 513.4906 - val_mse: 513.4906\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1964 - mse: 0.1964 - val_loss: 29.0817 - val_mse: 29.0817\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2046 - mse: 0.2046 - val_loss: 2.2395 - val_mse: 2.2395\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1918 - mse: 0.1918 - val_loss: 283.9745 - val_mse: 283.9745\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "14\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3880 - mse: 0.3880 - val_loss: 70.8018 - val_mse: 70.8018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3025 - mse: 0.3025 - val_loss: 422.5076 - val_mse: 422.5076\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2794 - mse: 0.2794 - val_loss: 458.1764 - val_mse: 458.1764\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2659 - mse: 0.2659 - val_loss: 31.3313 - val_mse: 31.3313\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2459 - mse: 0.2459 - val_loss: 125.0010 - val_mse: 125.0010\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2424 - mse: 0.2424 - val_loss: 37.3039 - val_mse: 37.3039\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2177 - mse: 0.2177 - val_loss: 0.8362 - val_mse: 0.8362\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2167 - mse: 0.2167 - val_loss: 204.9403 - val_mse: 204.9403\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2121 - mse: 0.2121 - val_loss: 41.6275 - val_mse: 41.6275\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2022 - mse: 0.2022 - val_loss: 166.3866 - val_mse: 166.3866\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1989 - mse: 0.1989 - val_loss: 1.3688 - val_mse: 1.3688\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 43.6692 - val_mse: 43.6692\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1919 - mse: 0.1919 - val_loss: 771.2581 - val_mse: 771.2581\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1820 - mse: 0.1820 - val_loss: 1690.8781 - val_mse: 1690.8781\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1870 - mse: 0.1870 - val_loss: 49.7105 - val_mse: 49.7105\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1786 - mse: 0.1786 - val_loss: 45.3126 - val_mse: 45.3126\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1696 - mse: 0.1696 - val_loss: 6395.8311 - val_mse: 6395.8311\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "15\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3930 - mse: 0.3930 - val_loss: 12.2514 - val_mse: 12.2514\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.3021 - mse: 0.3021 - val_loss: 704.5155 - val_mse: 704.5155\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2799 - mse: 0.2799 - val_loss: 2110.9670 - val_mse: 2110.9670\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2653 - mse: 0.2653 - val_loss: 152.8102 - val_mse: 152.8102\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2466 - mse: 0.2466 - val_loss: 187.4643 - val_mse: 187.4643\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2451 - mse: 0.2451 - val_loss: 14.0675 - val_mse: 14.0675\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2173 - mse: 0.2173 - val_loss: 1905.6685 - val_mse: 1905.6685\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2146 - mse: 0.2146 - val_loss: 1065.4042 - val_mse: 1065.4042\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2051 - mse: 0.2051 - val_loss: 137.0428 - val_mse: 137.0428\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1993 - mse: 0.1993 - val_loss: 1598.2113 - val_mse: 1598.2113\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2004 - mse: 0.2004 - val_loss: 80.3702 - val_mse: 80.3702\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "16\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3936 - mse: 0.3936 - val_loss: 18.3692 - val_mse: 18.3692\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2919 - mse: 0.2919 - val_loss: 1.0568 - val_mse: 1.0568\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2712 - mse: 0.2712 - val_loss: 439.1803 - val_mse: 439.1803\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2553 - mse: 0.2553 - val_loss: 1.3270 - val_mse: 1.3270\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2396 - mse: 0.2396 - val_loss: 10.8629 - val_mse: 10.8629\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 129.7552 - val_mse: 129.7552\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2090 - mse: 0.2090 - val_loss: 91.5953 - val_mse: 91.5953\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2009 - mse: 0.2009 - val_loss: 14300.3213 - val_mse: 14300.3213\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2035 - mse: 0.2035 - val_loss: 75.0859 - val_mse: 75.0859\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1864 - mse: 0.1864 - val_loss: 1519.6385 - val_mse: 1519.6385\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1945 - mse: 0.1945 - val_loss: 213.0581 - val_mse: 213.0581\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1810 - mse: 0.1810 - val_loss: 1337.2954 - val_mse: 1337.2954\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "17\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3814 - mse: 0.3814 - val_loss: 1.0056 - val_mse: 1.0056\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2924 - mse: 0.2924 - val_loss: 4.0770 - val_mse: 4.0770\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2737 - mse: 0.2737 - val_loss: 2042.1332 - val_mse: 2042.1332\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2698 - mse: 0.2698 - val_loss: 37.3247 - val_mse: 37.3247\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2537 - mse: 0.2537 - val_loss: 249.6479 - val_mse: 249.6479\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2496 - mse: 0.2496 - val_loss: 6.3375 - val_mse: 6.3375\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2322 - mse: 0.2322 - val_loss: 715.6669 - val_mse: 715.6669\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2277 - mse: 0.2277 - val_loss: 6284.3613 - val_mse: 6284.3613\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2182 - mse: 0.2182 - val_loss: 50.5985 - val_mse: 50.5985\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2051 - mse: 0.2051 - val_loss: 61.8401 - val_mse: 61.8401\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2073 - mse: 0.2073 - val_loss: 42.1745 - val_mse: 42.1745\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "18\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3837 - mse: 0.3837 - val_loss: 3.5540 - val_mse: 3.5540\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2953 - mse: 0.2953 - val_loss: 23.9628 - val_mse: 23.9628\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2733 - mse: 0.2733 - val_loss: 1498.5386 - val_mse: 1498.5386\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2648 - mse: 0.2648 - val_loss: 6.4609 - val_mse: 6.4609\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2515 - mse: 0.2515 - val_loss: 110.5462 - val_mse: 110.5462\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2527 - mse: 0.2527 - val_loss: 1.0425 - val_mse: 1.0425\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2200 - mse: 0.2200 - val_loss: 553.9957 - val_mse: 553.9957\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2186 - mse: 0.2186 - val_loss: 3218.1311 - val_mse: 3218.1311\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2045 - mse: 0.2045 - val_loss: 5.0745 - val_mse: 5.0745\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1999 - mse: 0.1999 - val_loss: 53.2685 - val_mse: 53.2685\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1929 - mse: 0.1929 - val_loss: 23.1402 - val_mse: 23.1402\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1797 - mse: 0.1797 - val_loss: 41.1963 - val_mse: 41.1963\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1806 - mse: 0.1806 - val_loss: 0.5837 - val_mse: 0.5837\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1799 - mse: 0.1799 - val_loss: 1589.1592 - val_mse: 1589.1592\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1740 - mse: 0.1740 - val_loss: 29.6843 - val_mse: 29.6843\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1751 - mse: 0.1751 - val_loss: 6.7035 - val_mse: 6.7035\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1668 - mse: 0.1668 - val_loss: 6834.4761 - val_mse: 6834.4761\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1629 - mse: 0.1629 - val_loss: 18.5498 - val_mse: 18.5498\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1642 - mse: 0.1642 - val_loss: 645.8112 - val_mse: 645.8112\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1576 - mse: 0.1576 - val_loss: 5.1314 - val_mse: 5.1314\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1594 - mse: 0.1594 - val_loss: 252.3152 - val_mse: 252.3152\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1514 - mse: 0.1514 - val_loss: 130.4734 - val_mse: 130.4734\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1499 - mse: 0.1499 - val_loss: 264.2613 - val_mse: 264.2613\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "19\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3849 - mse: 0.3849 - val_loss: 7.7945 - val_mse: 7.7945\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2939 - mse: 0.2939 - val_loss: 489.2419 - val_mse: 489.2419\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2714 - mse: 0.2714 - val_loss: 2969.7092 - val_mse: 2969.7092\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2625 - mse: 0.2625 - val_loss: 19.3735 - val_mse: 19.3735\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2434 - mse: 0.2434 - val_loss: 79.8447 - val_mse: 79.8447\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2310 - mse: 0.2310 - val_loss: 70.2298 - val_mse: 70.2298\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2101 - mse: 0.2101 - val_loss: 69.0182 - val_mse: 69.0182\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2124 - mse: 0.2124 - val_loss: 118.0605 - val_mse: 118.0605\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1961 - mse: 0.1961 - val_loss: 300.6983 - val_mse: 300.6983\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1939 - mse: 0.1939 - val_loss: 106.3702 - val_mse: 106.3702\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1879 - mse: 0.1879 - val_loss: 2773.2480 - val_mse: 2773.2480\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "20\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3852 - mse: 0.3852 - val_loss: 67.8161 - val_mse: 67.8161\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2899 - mse: 0.2899 - val_loss: 172.1786 - val_mse: 172.1786\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2705 - mse: 0.2705 - val_loss: 3802.1731 - val_mse: 3802.1731\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2607 - mse: 0.2607 - val_loss: 26.8533 - val_mse: 26.8533\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2380 - mse: 0.2380 - val_loss: 29.7966 - val_mse: 29.7966\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2354 - mse: 0.2354 - val_loss: 13.2231 - val_mse: 13.2231\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2078 - mse: 0.2078 - val_loss: 992.4326 - val_mse: 992.4326\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2077 - mse: 0.2077 - val_loss: 2251.6738 - val_mse: 2251.6738\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2044 - mse: 0.2044 - val_loss: 3.6327 - val_mse: 3.6327\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1897 - mse: 0.1897 - val_loss: 14.5258 - val_mse: 14.5258\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1831 - mse: 0.1831 - val_loss: 3329.3438 - val_mse: 3329.3438\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1719 - mse: 0.1719 - val_loss: 184.0992 - val_mse: 184.0992\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1727 - mse: 0.1727 - val_loss: 81.5928 - val_mse: 81.5928\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1651 - mse: 0.1651 - val_loss: 445.8190 - val_mse: 445.8190\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1599 - mse: 0.1599 - val_loss: 4.1959 - val_mse: 4.1959\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1689 - mse: 0.1689 - val_loss: 92.0786 - val_mse: 92.0786\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1564 - mse: 0.1564 - val_loss: 70.3114 - val_mse: 70.3114\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1595 - mse: 0.1595 - val_loss: 299.6750 - val_mse: 299.6750\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1525 - mse: 0.1525 - val_loss: 2232.0190 - val_mse: 2232.0190\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "21\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3910 - mse: 0.3910 - val_loss: 224.6229 - val_mse: 224.6229\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2837 - mse: 0.2837 - val_loss: 76.2093 - val_mse: 76.2093\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2632 - mse: 0.2632 - val_loss: 2286.4685 - val_mse: 2286.4685\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2512 - mse: 0.2512 - val_loss: 9.6797 - val_mse: 9.6797\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2349 - mse: 0.2349 - val_loss: 507.0546 - val_mse: 507.0546\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2308 - mse: 0.2308 - val_loss: 3.3749 - val_mse: 3.3749\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1968 - mse: 0.1968 - val_loss: 2178.3223 - val_mse: 2178.3223\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1994 - mse: 0.1994 - val_loss: 2224.7588 - val_mse: 2224.7588\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1920 - mse: 0.1920 - val_loss: 3.8736 - val_mse: 3.8736\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 1377.4827 - val_mse: 1377.4827\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1812 - mse: 0.1812 - val_loss: 8.1046 - val_mse: 8.1046\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1674 - mse: 0.1674 - val_loss: 1.2364 - val_mse: 1.2364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1661 - mse: 0.1661 - val_loss: 3582.7117 - val_mse: 3582.7117\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1632 - mse: 0.1632 - val_loss: 2620.3906 - val_mse: 2620.3906\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1661 - mse: 0.1661 - val_loss: 4.3349 - val_mse: 4.3349\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1620 - mse: 0.1620 - val_loss: 18678.0371 - val_mse: 18678.0371\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1554 - mse: 0.1554 - val_loss: 946.5937 - val_mse: 946.5937\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1531 - mse: 0.1531 - val_loss: 87.4241 - val_mse: 87.4241\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1527 - mse: 0.1527 - val_loss: 9.9959 - val_mse: 9.9959\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1532 - mse: 0.1532 - val_loss: 4.1401 - val_mse: 4.1401\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1440 - mse: 0.1440 - val_loss: 17095.4043 - val_mse: 17095.4043\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1489 - mse: 0.1489 - val_loss: 2.4909 - val_mse: 2.4909\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "22\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4182 - mse: 0.4182 - val_loss: 127.8860 - val_mse: 127.8860\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.3033 - mse: 0.3033 - val_loss: 2.4647 - val_mse: 2.4647\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2724 - mse: 0.2724 - val_loss: 3219.8066 - val_mse: 3219.8066\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2550 - mse: 0.2550 - val_loss: 128.3479 - val_mse: 128.3479\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2338 - mse: 0.2338 - val_loss: 4.5115 - val_mse: 4.5115\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2357 - mse: 0.2357 - val_loss: 277.7309 - val_mse: 277.7309\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2005 - mse: 0.2005 - val_loss: 75.1468 - val_mse: 75.1468\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1957 - mse: 0.1957 - val_loss: 110.3292 - val_mse: 110.3292\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1949 - mse: 0.1949 - val_loss: 2584.3508 - val_mse: 2584.3508\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1856 - mse: 0.1856 - val_loss: 1284.5264 - val_mse: 1284.5264\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1802 - mse: 0.1802 - val_loss: 669.7758 - val_mse: 669.7758\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1683 - mse: 0.1683 - val_loss: 57.6072 - val_mse: 57.6072\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "23\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.4386 - mse: 0.4386 - val_loss: 15.4647 - val_mse: 15.4647\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2919 - mse: 0.2919 - val_loss: 1.1162 - val_mse: 1.1162\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2622 - mse: 0.2622 - val_loss: 12299.5684 - val_mse: 12299.5684\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 62.4139 - val_mse: 62.4139\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2052 - mse: 0.2052 - val_loss: 1246.6040 - val_mse: 1246.6040\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1999 - mse: 0.1999 - val_loss: 1673.4816 - val_mse: 1673.4816\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1720 - mse: 0.1720 - val_loss: 98.8618 - val_mse: 98.8618\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1696 - mse: 0.1696 - val_loss: 29.2621 - val_mse: 29.2621\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1719 - mse: 0.1719 - val_loss: 5417.6475 - val_mse: 5417.6475\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1500 - mse: 0.1500 - val_loss: 23.3916 - val_mse: 23.3916\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1537 - mse: 0.1537 - val_loss: 615.3882 - val_mse: 615.3882\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1446 - mse: 0.1446 - val_loss: 39.4293 - val_mse: 39.4293\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "24\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3793 - mse: 0.3793 - val_loss: 93.2043 - val_mse: 93.2043\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2680 - mse: 0.2680 - val_loss: 104.5445 - val_mse: 104.5445\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2420 - mse: 0.2420 - val_loss: 16711.6543 - val_mse: 16711.6543\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 140.1443 - val_mse: 140.1443\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1991 - mse: 0.1991 - val_loss: 8550.9170 - val_mse: 8550.9170\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1943 - mse: 0.1943 - val_loss: 5.7272 - val_mse: 5.7272\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1659 - mse: 0.1659 - val_loss: 193.5462 - val_mse: 193.5462\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1665 - mse: 0.1665 - val_loss: 6691.4150 - val_mse: 6691.4150\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1587 - mse: 0.1587 - val_loss: 14.6964 - val_mse: 14.6964\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1465 - mse: 0.1465 - val_loss: 16.1128 - val_mse: 16.1128\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1503 - mse: 0.1503 - val_loss: 94.3289 - val_mse: 94.3289\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1411 - mse: 0.1411 - val_loss: 5.7871 - val_mse: 5.7871\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1419 - mse: 0.1419 - val_loss: 459.8354 - val_mse: 459.8354\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1364 - mse: 0.1364 - val_loss: 35.0671 - val_mse: 35.0671\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1334 - mse: 0.1334 - val_loss: 0.6481 - val_mse: 0.6481\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1397 - mse: 0.1397 - val_loss: 21.2824 - val_mse: 21.2824\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1341 - mse: 0.1341 - val_loss: 13349.5801 - val_mse: 13349.5801\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 1524.2026 - val_mse: 1524.2026\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 235.7431 - val_mse: 235.7431\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1262 - mse: 0.1262 - val_loss: 249.8047 - val_mse: 249.8047\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1297 - mse: 0.1297 - val_loss: 14204.9482 - val_mse: 14204.9482\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1227 - mse: 0.1227 - val_loss: 53.1090 - val_mse: 53.1090\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1248 - mse: 0.1248 - val_loss: 4.3218 - val_mse: 4.3218\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1190 - mse: 0.1190 - val_loss: 308.2034 - val_mse: 308.2034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 1.7010 - val_mse: 1.7010\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "25\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 5ms/step - loss: 0.3820 - mse: 0.3820 - val_loss: 1007.1512 - val_mse: 1007.1512\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2773 - mse: 0.2773 - val_loss: 123.9968 - val_mse: 123.9968\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 15154.8828 - val_mse: 15154.8828\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2177 - mse: 0.2177 - val_loss: 49.3081 - val_mse: 49.3081\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1939 - mse: 0.1939 - val_loss: 7138.8994 - val_mse: 7138.8994\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1794 - mse: 0.1794 - val_loss: 416.9650 - val_mse: 416.9650\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1627 - mse: 0.1627 - val_loss: 2780.7014 - val_mse: 2780.7014\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1599 - mse: 0.1599 - val_loss: 1.0682 - val_mse: 1.0682\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1623 - mse: 0.1623 - val_loss: 9.7884 - val_mse: 9.7884\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1475 - mse: 0.1475 - val_loss: 18.8956 - val_mse: 18.8956\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1472 - mse: 0.1472 - val_loss: 23.1039 - val_mse: 23.1039\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1424 - mse: 0.1424 - val_loss: 0.8648 - val_mse: 0.8648\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1434 - mse: 0.1434 - val_loss: 6.2401 - val_mse: 6.2401\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1374 - mse: 0.1374 - val_loss: 6.2838 - val_mse: 6.2838\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1370 - mse: 0.1370 - val_loss: 62.2723 - val_mse: 62.2723\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 2.8714 - val_mse: 2.8714\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1319 - mse: 0.1319 - val_loss: 38971.9609 - val_mse: 38971.9609\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1289 - mse: 0.1289 - val_loss: 2183.8262 - val_mse: 2183.8262\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 23516.3750 - val_mse: 23516.3750\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1289 - mse: 0.1289 - val_loss: 1.2727 - val_mse: 1.2727\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1293 - mse: 0.1293 - val_loss: 10506.7295 - val_mse: 10506.7295\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1173 - mse: 0.1173 - val_loss: 152.8439 - val_mse: 152.8439\n",
      "674/674 [==============================] - 2s 2ms/step\n",
      "26\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3683 - mse: 0.3683 - val_loss: 0.7738 - val_mse: 0.7738\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2361 - mse: 0.2361 - val_loss: 24.5720 - val_mse: 24.5720\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1894 - mse: 0.1894 - val_loss: 7204.4185 - val_mse: 7204.4185\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1849 - mse: 0.1849 - val_loss: 7.1103 - val_mse: 7.1103\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1590 - mse: 0.1590 - val_loss: 5438.3994 - val_mse: 5438.3994\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1549 - mse: 0.1549 - val_loss: 3134.2957 - val_mse: 3134.2957\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1359 - mse: 0.1359 - val_loss: 17.5016 - val_mse: 17.5016\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1372 - mse: 0.1372 - val_loss: 476.3796 - val_mse: 476.3796\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1436 - mse: 0.1436 - val_loss: 2.6791 - val_mse: 2.6791\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1330 - mse: 0.1330 - val_loss: 0.6708 - val_mse: 0.6708\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1287 - mse: 0.1287 - val_loss: 17.5378 - val_mse: 17.5378\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1220 - mse: 0.1220 - val_loss: 4.7872 - val_mse: 4.7872\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 34.6153 - val_mse: 34.6153\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1197 - mse: 0.1197 - val_loss: 3863.2981 - val_mse: 3863.2981\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1151 - mse: 0.1151 - val_loss: 10.3319 - val_mse: 10.3319\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1214 - mse: 0.1214 - val_loss: 1156.4755 - val_mse: 1156.4755\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1221 - mse: 0.1221 - val_loss: 183.5925 - val_mse: 183.5925\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1153 - mse: 0.1153 - val_loss: 1564.2822 - val_mse: 1564.2822\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1112 - mse: 0.1112 - val_loss: 9190.1299 - val_mse: 9190.1299\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1139 - mse: 0.1139 - val_loss: 23.6820 - val_mse: 23.6820\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "27\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3336 - mse: 0.3336 - val_loss: 1123.4434 - val_mse: 1123.4434\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2141 - mse: 0.2141 - val_loss: 108.0960 - val_mse: 108.0960\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1925 - mse: 0.1925 - val_loss: 744.8549 - val_mse: 744.8549\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1591 - mse: 0.1591 - val_loss: 31.3426 - val_mse: 31.3426\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1560 - mse: 0.1560 - val_loss: 6060.8384 - val_mse: 6060.8384\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1496 - mse: 0.1496 - val_loss: 1152.3599 - val_mse: 1152.3599\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 33.1185 - val_mse: 33.1185\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1341 - mse: 0.1341 - val_loss: 484.6382 - val_mse: 484.6382\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1438 - mse: 0.1438 - val_loss: 785.3438 - val_mse: 785.3438\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1242 - mse: 0.1242 - val_loss: 5.8869 - val_mse: 5.8869\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1249 - mse: 0.1249 - val_loss: 182.3776 - val_mse: 182.3776\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1198 - mse: 0.1198 - val_loss: 1.8331 - val_mse: 1.8331\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1218 - mse: 0.1218 - val_loss: 48.5948 - val_mse: 48.5948\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 750.0385 - val_mse: 750.0385\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1188 - mse: 0.1188 - val_loss: 14.6728 - val_mse: 14.6728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1203 - mse: 0.1203 - val_loss: 3.4617 - val_mse: 3.4617\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1155 - mse: 0.1155 - val_loss: 1192.8215 - val_mse: 1192.8215\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1122 - mse: 0.1122 - val_loss: 82.0470 - val_mse: 82.0470\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1091 - mse: 0.1091 - val_loss: 260.9637 - val_mse: 260.9637\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1114 - mse: 0.1114 - val_loss: 144.6645 - val_mse: 144.6645\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1101 - mse: 0.1101 - val_loss: 56875.3125 - val_mse: 56875.3125\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1095 - mse: 0.1095 - val_loss: 403.2010 - val_mse: 403.2010\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "28\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3679 - mse: 0.3679 - val_loss: 525.6053 - val_mse: 525.6053\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2281 - mse: 0.2281 - val_loss: 60.3253 - val_mse: 60.3253\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1895 - mse: 0.1895 - val_loss: 6625.2490 - val_mse: 6625.2490\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1793 - mse: 0.1793 - val_loss: 53.2906 - val_mse: 53.2906\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1587 - mse: 0.1587 - val_loss: 7080.6157 - val_mse: 7080.6157\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1560 - mse: 0.1560 - val_loss: 74.0561 - val_mse: 74.0561\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1340 - mse: 0.1340 - val_loss: 1.0698 - val_mse: 1.0698\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1378 - mse: 0.1378 - val_loss: 14.1239 - val_mse: 14.1239\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1437 - mse: 0.1437 - val_loss: 628.7064 - val_mse: 628.7064\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1258 - mse: 0.1258 - val_loss: 9.6503 - val_mse: 9.6503\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 6.7812 - val_mse: 6.7812\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1203 - mse: 0.1203 - val_loss: 3.4352 - val_mse: 3.4352\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 76.4094 - val_mse: 76.4094\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1196 - mse: 0.1196 - val_loss: 118.9657 - val_mse: 118.9657\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1190 - mse: 0.1190 - val_loss: 4.4992 - val_mse: 4.4992\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1183 - mse: 0.1183 - val_loss: 17.4047 - val_mse: 17.4047\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1198 - mse: 0.1198 - val_loss: 5069.6772 - val_mse: 5069.6772\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "29\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3358 - mse: 0.3358 - val_loss: 11.4057 - val_mse: 11.4057\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2122 - mse: 0.2122 - val_loss: 58.0781 - val_mse: 58.0781\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1852 - mse: 0.1852 - val_loss: 3529.9851 - val_mse: 3529.9851\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1772 - mse: 0.1772 - val_loss: 23.2828 - val_mse: 23.2828\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1510 - mse: 0.1510 - val_loss: 4671.9287 - val_mse: 4671.9287\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1450 - mse: 0.1450 - val_loss: 1482.0925 - val_mse: 1482.0925\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1368 - mse: 0.1368 - val_loss: 266.0066 - val_mse: 266.0066\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1376 - mse: 0.1376 - val_loss: 3.3669 - val_mse: 3.3669\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1335 - mse: 0.1335 - val_loss: 30.9482 - val_mse: 30.9482\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1226 - mse: 0.1226 - val_loss: 290.4633 - val_mse: 290.4633\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 6.4151 - val_mse: 6.4151\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1187 - mse: 0.1187 - val_loss: 2.8932 - val_mse: 2.8932\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1200 - mse: 0.1200 - val_loss: 3.3530 - val_mse: 3.3530\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1170 - mse: 0.1170 - val_loss: 81.5162 - val_mse: 81.5162\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1133 - mse: 0.1133 - val_loss: 16.7885 - val_mse: 16.7885\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1228 - mse: 0.1228 - val_loss: 1203.7219 - val_mse: 1203.7219\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 1639.1125 - val_mse: 1639.1125\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 18.6771 - val_mse: 18.6771\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1101 - mse: 0.1101 - val_loss: 1360.1991 - val_mse: 1360.1991\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1097 - mse: 0.1097 - val_loss: 90.0791 - val_mse: 90.0791\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1076 - mse: 0.1076 - val_loss: 10881.2725 - val_mse: 10881.2725\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 98.7049 - val_mse: 98.7049\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "30\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3615 - mse: 0.3615 - val_loss: 1797.7953 - val_mse: 1797.7953\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2294 - mse: 0.2294 - val_loss: 66.5222 - val_mse: 66.5222\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1944 - mse: 0.1944 - val_loss: 777.3958 - val_mse: 777.3958\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1767 - mse: 0.1767 - val_loss: 8.2650 - val_mse: 8.2650\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1617 - mse: 0.1617 - val_loss: 2203.8254 - val_mse: 2203.8254\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1527 - mse: 0.1527 - val_loss: 6.2817 - val_mse: 6.2817\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1354 - mse: 0.1354 - val_loss: 9.3048 - val_mse: 9.3048\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1394 - mse: 0.1394 - val_loss: 54.9702 - val_mse: 54.9702\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1367 - mse: 0.1367 - val_loss: 10.9492 - val_mse: 10.9492\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1307 - mse: 0.1307 - val_loss: 7.4541 - val_mse: 7.4541\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1273 - mse: 0.1273 - val_loss: 5.1115 - val_mse: 5.1115\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1280 - mse: 0.1280 - val_loss: 21.8516 - val_mse: 21.8516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1200 - mse: 0.1200 - val_loss: 27.6108 - val_mse: 27.6108\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1166 - mse: 0.1166 - val_loss: 17.5782 - val_mse: 17.5782\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1177 - mse: 0.1177 - val_loss: 11.8055 - val_mse: 11.8055\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1230 - mse: 0.1230 - val_loss: 723.9088 - val_mse: 723.9088\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1214 - mse: 0.1214 - val_loss: 22.3196 - val_mse: 22.3196\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1151 - mse: 0.1151 - val_loss: 15.0982 - val_mse: 15.0982\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 1166.6371 - val_mse: 1166.6371\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 659.4206 - val_mse: 659.4206\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1097 - mse: 0.1097 - val_loss: 4450.1484 - val_mse: 4450.1484\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "31\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3439 - mse: 0.3439 - val_loss: 2842.9539 - val_mse: 2842.9539\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 31.9388 - val_mse: 31.9388\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1904 - mse: 0.1904 - val_loss: 11108.2627 - val_mse: 11108.2627\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1691 - mse: 0.1691 - val_loss: 36.4778 - val_mse: 36.4778\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1492 - mse: 0.1492 - val_loss: 737.9468 - val_mse: 737.9468\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1478 - mse: 0.1478 - val_loss: 6.6755 - val_mse: 6.6755\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1347 - mse: 0.1347 - val_loss: 164.4418 - val_mse: 164.4418\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1331 - mse: 0.1331 - val_loss: 14.3936 - val_mse: 14.3936\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1470 - mse: 0.1470 - val_loss: 275.7104 - val_mse: 275.7104\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1280 - mse: 0.1280 - val_loss: 1.6543 - val_mse: 1.6543\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1226 - mse: 0.1226 - val_loss: 81.1884 - val_mse: 81.1884\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1201 - mse: 0.1201 - val_loss: 78.5159 - val_mse: 78.5159\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1218 - mse: 0.1218 - val_loss: 0.6766 - val_mse: 0.6766\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 13.9898 - val_mse: 13.9898\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1186 - mse: 0.1186 - val_loss: 5.3137 - val_mse: 5.3137\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1168 - mse: 0.1168 - val_loss: 6.0020 - val_mse: 6.0020\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1154 - mse: 0.1154 - val_loss: 1.9981 - val_mse: 1.9981\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1123 - mse: 0.1123 - val_loss: 589.5401 - val_mse: 589.5401\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 1895.4572 - val_mse: 1895.4572\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1116 - mse: 0.1116 - val_loss: 43.5317 - val_mse: 43.5317\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1082 - mse: 0.1082 - val_loss: 11990.4014 - val_mse: 11990.4014\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1011 - mse: 0.1011 - val_loss: 86.2467 - val_mse: 86.2467\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1103 - mse: 0.1103 - val_loss: 21.9771 - val_mse: 21.9771\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "32\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3312 - mse: 0.3312 - val_loss: 783.5847 - val_mse: 783.5847\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2113 - mse: 0.2113 - val_loss: 38.3727 - val_mse: 38.3727\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1941 - mse: 0.1941 - val_loss: 4023.6831 - val_mse: 4023.6831\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1726 - mse: 0.1726 - val_loss: 1.5339 - val_mse: 1.5339\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1558 - mse: 0.1558 - val_loss: 2877.9434 - val_mse: 2877.9434\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1518 - mse: 0.1518 - val_loss: 18.5174 - val_mse: 18.5174\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1388 - mse: 0.1388 - val_loss: 32.4866 - val_mse: 32.4866\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1351 - mse: 0.1351 - val_loss: 1.3863 - val_mse: 1.3863\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1390 - mse: 0.1390 - val_loss: 65.1263 - val_mse: 65.1263\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 62.5943 - val_mse: 62.5943\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1298 - mse: 0.1298 - val_loss: 7.1495 - val_mse: 7.1495\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1188 - mse: 0.1188 - val_loss: 2.5208 - val_mse: 2.5208\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1203 - mse: 0.1203 - val_loss: 48.6297 - val_mse: 48.6297\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1173 - mse: 0.1173 - val_loss: 183.0162 - val_mse: 183.0162\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1203 - mse: 0.1203 - val_loss: 65.5380 - val_mse: 65.5380\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 104.0058 - val_mse: 104.0058\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1149 - mse: 0.1149 - val_loss: 10970.1680 - val_mse: 10970.1680\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1102 - mse: 0.1102 - val_loss: 74.9643 - val_mse: 74.9643\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "33\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3423 - mse: 0.3423 - val_loss: 1128.0752 - val_mse: 1128.0752\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 1.1441 - val_mse: 1.1441\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1918 - mse: 0.1918 - val_loss: 1903.2136 - val_mse: 1903.2136\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1666 - mse: 0.1666 - val_loss: 17.2561 - val_mse: 17.2561\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1576 - mse: 0.1576 - val_loss: 3543.3870 - val_mse: 3543.3870\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1418 - mse: 0.1418 - val_loss: 216.1498 - val_mse: 216.1498\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1421 - mse: 0.1421 - val_loss: 6.2979 - val_mse: 6.2979\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1305 - mse: 0.1305 - val_loss: 1.2900 - val_mse: 1.2900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1418 - mse: 0.1418 - val_loss: 533.8752 - val_mse: 533.8752\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1292 - mse: 0.1292 - val_loss: 200.1902 - val_mse: 200.1902\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1294 - mse: 0.1294 - val_loss: 9.9340 - val_mse: 9.9340\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1194 - mse: 0.1194 - val_loss: 1.5508 - val_mse: 1.5508\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "34\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 1022.4171 - val_mse: 1022.4171\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2290 - mse: 0.2290 - val_loss: 258.3729 - val_mse: 258.3729\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1914 - mse: 0.1914 - val_loss: 8555.4395 - val_mse: 8555.4395\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1819 - mse: 0.1819 - val_loss: 0.9273 - val_mse: 0.9273\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1624 - mse: 0.1624 - val_loss: 2284.8337 - val_mse: 2284.8337\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1479 - mse: 0.1479 - val_loss: 205.0231 - val_mse: 205.0231\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1389 - mse: 0.1389 - val_loss: 9.8688 - val_mse: 9.8688\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1378 - mse: 0.1378 - val_loss: 11.6977 - val_mse: 11.6977\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1407 - mse: 0.1407 - val_loss: 419.9603 - val_mse: 419.9603\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1299 - mse: 0.1299 - val_loss: 3.0042 - val_mse: 3.0042\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 32.4151 - val_mse: 32.4151\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1221 - mse: 0.1221 - val_loss: 1.6539 - val_mse: 1.6539\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1217 - mse: 0.1217 - val_loss: 9.8204 - val_mse: 9.8204\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1194 - mse: 0.1194 - val_loss: 0.7398 - val_mse: 0.7398\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1185 - mse: 0.1185 - val_loss: 27.2815 - val_mse: 27.2815\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 18.9197 - val_mse: 18.9197\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1186 - mse: 0.1186 - val_loss: 15.3534 - val_mse: 15.3534\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1098 - mse: 0.1098 - val_loss: 1926.0726 - val_mse: 1926.0726\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1139 - mse: 0.1139 - val_loss: 1104.5161 - val_mse: 1104.5161\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1138 - mse: 0.1138 - val_loss: 32.6114 - val_mse: 32.6114\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1116 - mse: 0.1116 - val_loss: 8271.3154 - val_mse: 8271.3154\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 48.7258 - val_mse: 48.7258\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1105 - mse: 0.1105 - val_loss: 87.5334 - val_mse: 87.5334\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1039 - mse: 0.1039 - val_loss: 1.3577 - val_mse: 1.3577\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "35\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3522 - mse: 0.3522 - val_loss: 578.9292 - val_mse: 578.9292\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2182 - mse: 0.2182 - val_loss: 2.5233 - val_mse: 2.5233\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1852 - mse: 0.1852 - val_loss: 3828.8718 - val_mse: 3828.8718\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1676 - mse: 0.1676 - val_loss: 48.3145 - val_mse: 48.3145\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1616 - mse: 0.1616 - val_loss: 7886.9019 - val_mse: 7886.9019\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1443 - mse: 0.1443 - val_loss: 373.7954 - val_mse: 373.7954\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1341 - mse: 0.1341 - val_loss: 201.0275 - val_mse: 201.0275\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1330 - mse: 0.1330 - val_loss: 365.3268 - val_mse: 365.3268\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1441 - mse: 0.1441 - val_loss: 2371.2634 - val_mse: 2371.2634\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1284 - mse: 0.1284 - val_loss: 2.3169 - val_mse: 2.3169\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1244 - mse: 0.1244 - val_loss: 456.4886 - val_mse: 456.4886\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 1.7617 - val_mse: 1.7617\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 839.5872 - val_mse: 839.5872\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1145 - mse: 0.1145 - val_loss: 256.9259 - val_mse: 256.9259\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1161 - mse: 0.1161 - val_loss: 43.8170 - val_mse: 43.8170\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1202 - mse: 0.1202 - val_loss: 265.9393 - val_mse: 265.9393\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1222 - mse: 0.1222 - val_loss: 1718.1876 - val_mse: 1718.1876\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1095 - mse: 0.1095 - val_loss: 10.4421 - val_mse: 10.4421\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1090 - mse: 0.1090 - val_loss: 1949.7278 - val_mse: 1949.7278\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 5.5136 - val_mse: 5.5136\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1090 - mse: 0.1090 - val_loss: 25474.1191 - val_mse: 25474.1191\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1016 - mse: 0.1016 - val_loss: 2777.6792 - val_mse: 2777.6792\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "36\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3582 - mse: 0.3582 - val_loss: 1464.6823 - val_mse: 1464.6823\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2222 - mse: 0.2222 - val_loss: 745.0820 - val_mse: 745.0820\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1976 - mse: 0.1976 - val_loss: 5155.2261 - val_mse: 5155.2261\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1735 - mse: 0.1735 - val_loss: 809.1689 - val_mse: 809.1689\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1546 - mse: 0.1546 - val_loss: 16421.0645 - val_mse: 16421.0645\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1467 - mse: 0.1467 - val_loss: 10.0670 - val_mse: 10.0670\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1355 - mse: 0.1355 - val_loss: 1.9380 - val_mse: 1.9380\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1395 - mse: 0.1395 - val_loss: 1.0492 - val_mse: 1.0492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1374 - mse: 0.1374 - val_loss: 77.4851 - val_mse: 77.4851\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1269 - mse: 0.1269 - val_loss: 659.5698 - val_mse: 659.5698\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1269 - mse: 0.1269 - val_loss: 11128.0654 - val_mse: 11128.0654\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1197 - mse: 0.1197 - val_loss: 3.8780 - val_mse: 3.8780\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1229 - mse: 0.1229 - val_loss: 127.8676 - val_mse: 127.8676\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1210 - mse: 0.1210 - val_loss: 3.1225 - val_mse: 3.1225\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1160 - mse: 0.1160 - val_loss: 1.1632 - val_mse: 1.1632\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1219 - mse: 0.1219 - val_loss: 28.1344 - val_mse: 28.1344\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1148 - mse: 0.1148 - val_loss: 727.2205 - val_mse: 727.2205\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 22.4749 - val_mse: 22.4749\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "37\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3492 - mse: 0.3492 - val_loss: 2410.2578 - val_mse: 2410.2578\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2324 - mse: 0.2324 - val_loss: 1520.6564 - val_mse: 1520.6564\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1890 - mse: 0.1890 - val_loss: 702.0253 - val_mse: 702.0253\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1702 - mse: 0.1702 - val_loss: 4.4072 - val_mse: 4.4072\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1583 - mse: 0.1583 - val_loss: 2653.0586 - val_mse: 2653.0586\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1444 - mse: 0.1444 - val_loss: 39.2814 - val_mse: 39.2814\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 9.7095 - val_mse: 9.7095\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1320 - mse: 0.1320 - val_loss: 4811.3462 - val_mse: 4811.3462\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1408 - mse: 0.1408 - val_loss: 433.6170 - val_mse: 433.6170\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 11.8251 - val_mse: 11.8251\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1234 - mse: 0.1234 - val_loss: 0.9122 - val_mse: 0.9122\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1194 - mse: 0.1194 - val_loss: 6.0644 - val_mse: 6.0644\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1171 - mse: 0.1171 - val_loss: 80.8656 - val_mse: 80.8656\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1146 - mse: 0.1146 - val_loss: 10.3976 - val_mse: 10.3976\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1130 - mse: 0.1130 - val_loss: 21.9667 - val_mse: 21.9667\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1160 - mse: 0.1160 - val_loss: 50.0670 - val_mse: 50.0670\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1141 - mse: 0.1141 - val_loss: 679.2303 - val_mse: 679.2303\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1082 - mse: 0.1082 - val_loss: 17.6705 - val_mse: 17.6705\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1089 - mse: 0.1089 - val_loss: 3686.0728 - val_mse: 3686.0728\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1076 - mse: 0.1076 - val_loss: 793.8044 - val_mse: 793.8044\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1058 - mse: 0.1058 - val_loss: 4824.2544 - val_mse: 4824.2544\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "38\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3713 - mse: 0.3713 - val_loss: 1717.5039 - val_mse: 1717.5039\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2380 - mse: 0.2380 - val_loss: 159.9495 - val_mse: 159.9495\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1914 - mse: 0.1914 - val_loss: 4138.2188 - val_mse: 4138.2188\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1625 - mse: 0.1625 - val_loss: 16.2501 - val_mse: 16.2501\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1589 - mse: 0.1589 - val_loss: 5245.9683 - val_mse: 5245.9683\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1501 - mse: 0.1501 - val_loss: 601.1324 - val_mse: 601.1324\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1317 - mse: 0.1317 - val_loss: 84.1481 - val_mse: 84.1481\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1410 - mse: 0.1410 - val_loss: 4.9109 - val_mse: 4.9109\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1398 - mse: 0.1398 - val_loss: 86.5208 - val_mse: 86.5208\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 6.6309 - val_mse: 6.6309\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1252 - mse: 0.1252 - val_loss: 10.0261 - val_mse: 10.0261\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1183 - mse: 0.1183 - val_loss: 204.1012 - val_mse: 204.1012\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1183 - mse: 0.1183 - val_loss: 1290.2080 - val_mse: 1290.2080\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 9.6487 - val_mse: 9.6487\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 37.1776 - val_mse: 37.1776\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 74.8996 - val_mse: 74.8996\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1166 - mse: 0.1166 - val_loss: 196.4258 - val_mse: 196.4258\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1092 - mse: 0.1092 - val_loss: 23.1715 - val_mse: 23.1715\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "39\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3338 - mse: 0.3338 - val_loss: 694.9175 - val_mse: 694.9175\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2216 - mse: 0.2216 - val_loss: 1357.6189 - val_mse: 1357.6189\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1860 - mse: 0.1860 - val_loss: 18675.0957 - val_mse: 18675.0957\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1678 - mse: 0.1678 - val_loss: 74.6272 - val_mse: 74.6272\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1492 - mse: 0.1492 - val_loss: 2092.0081 - val_mse: 2092.0081\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1370 - mse: 0.1370 - val_loss: 1190.4725 - val_mse: 1190.4725\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1327 - mse: 0.1327 - val_loss: 2.5924 - val_mse: 2.5924\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1308 - mse: 0.1308 - val_loss: 1.4524 - val_mse: 1.4524\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1386 - mse: 0.1386 - val_loss: 68.8411 - val_mse: 68.8411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1219 - mse: 0.1219 - val_loss: 58.1899 - val_mse: 58.1899\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1210 - mse: 0.1210 - val_loss: 20.5931 - val_mse: 20.5931\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1166 - mse: 0.1166 - val_loss: 1.3909 - val_mse: 1.3909\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1194 - mse: 0.1194 - val_loss: 20.9572 - val_mse: 20.9572\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 2372.1399 - val_mse: 2372.1399\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 8.1976 - val_mse: 8.1976\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1105 - mse: 0.1105 - val_loss: 2.4797 - val_mse: 2.4797\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1137 - mse: 0.1137 - val_loss: 1291.2054 - val_mse: 1291.2054\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1075 - mse: 0.1075 - val_loss: 161.4590 - val_mse: 161.4590\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1060 - mse: 0.1060 - val_loss: 124.1325 - val_mse: 124.1325\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1038 - mse: 0.1038 - val_loss: 119.6698 - val_mse: 119.6698\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 30019.1602 - val_mse: 30019.1602\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0996 - mse: 0.0996 - val_loss: 2889.4585 - val_mse: 2889.4585\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "40\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3631 - mse: 0.3631 - val_loss: 2830.9353 - val_mse: 2830.9353\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2316 - mse: 0.2316 - val_loss: 131.9883 - val_mse: 131.9883\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2000 - mse: 0.2000 - val_loss: 5156.7959 - val_mse: 5156.7959\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1691 - mse: 0.1691 - val_loss: 9.7020 - val_mse: 9.7020\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1550 - mse: 0.1550 - val_loss: 2265.1448 - val_mse: 2265.1448\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1490 - mse: 0.1490 - val_loss: 342.6323 - val_mse: 342.6323\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1339 - mse: 0.1339 - val_loss: 7.6719 - val_mse: 7.6719\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1346 - mse: 0.1346 - val_loss: 394.0791 - val_mse: 394.0791\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1381 - mse: 0.1381 - val_loss: 689.4361 - val_mse: 689.4361\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1270 - mse: 0.1270 - val_loss: 9.4629 - val_mse: 9.4629\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1252 - mse: 0.1252 - val_loss: 3.4575 - val_mse: 3.4575\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 1.0172 - val_mse: 1.0172\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1175 - mse: 0.1175 - val_loss: 401.2560 - val_mse: 401.2560\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1189 - mse: 0.1189 - val_loss: 67.3963 - val_mse: 67.3963\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1144 - mse: 0.1144 - val_loss: 8.5528 - val_mse: 8.5528\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 2669.2910 - val_mse: 2669.2910\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1146 - mse: 0.1146 - val_loss: 1064.5909 - val_mse: 1064.5909\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1081 - mse: 0.1081 - val_loss: 483.0013 - val_mse: 483.0013\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1089 - mse: 0.1089 - val_loss: 127.7943 - val_mse: 127.7943\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1074 - mse: 0.1074 - val_loss: 3.1182 - val_mse: 3.1182\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 11735.5869 - val_mse: 11735.5869\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 2031.9966 - val_mse: 2031.9966\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "41\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3421 - mse: 0.3421 - val_loss: 2854.5698 - val_mse: 2854.5698\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2215 - mse: 0.2215 - val_loss: 142.5746 - val_mse: 142.5746\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1880 - mse: 0.1880 - val_loss: 18937.9355 - val_mse: 18937.9355\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1737 - mse: 0.1737 - val_loss: 0.3962 - val_mse: 0.3962\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1543 - mse: 0.1543 - val_loss: 2695.6428 - val_mse: 2695.6428\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1456 - mse: 0.1456 - val_loss: 622.9963 - val_mse: 622.9963\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1314 - mse: 0.1314 - val_loss: 14.8166 - val_mse: 14.8166\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1327 - mse: 0.1327 - val_loss: 79.4491 - val_mse: 79.4491\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1352 - mse: 0.1352 - val_loss: 0.7407 - val_mse: 0.7407\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 116.4090 - val_mse: 116.4090\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1232 - mse: 0.1232 - val_loss: 1.5142 - val_mse: 1.5142\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 9.0786 - val_mse: 9.0786\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1159 - mse: 0.1159 - val_loss: 80.7385 - val_mse: 80.7385\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1137 - mse: 0.1137 - val_loss: 0.4974 - val_mse: 0.4974\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "42\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3679 - mse: 0.3679 - val_loss: 1490.9329 - val_mse: 1490.9329\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2239 - mse: 0.2239 - val_loss: 41.7804 - val_mse: 41.7804\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1911 - mse: 0.1911 - val_loss: 3951.0396 - val_mse: 3951.0396\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1769 - mse: 0.1769 - val_loss: 1.0570 - val_mse: 1.0570\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1510 - mse: 0.1510 - val_loss: 214.5140 - val_mse: 214.5140\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1421 - mse: 0.1421 - val_loss: 227.8800 - val_mse: 227.8800\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1346 - mse: 0.1346 - val_loss: 16.0946 - val_mse: 16.0946\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1330 - mse: 0.1330 - val_loss: 21.3900 - val_mse: 21.3900\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1371 - mse: 0.1371 - val_loss: 139.8768 - val_mse: 139.8768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 7.3871 - val_mse: 7.3871\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1238 - mse: 0.1238 - val_loss: 1.1241 - val_mse: 1.1241\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1156 - mse: 0.1156 - val_loss: 1.3618 - val_mse: 1.3618\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1161 - mse: 0.1161 - val_loss: 142.1785 - val_mse: 142.1785\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1144 - mse: 0.1144 - val_loss: 143.3944 - val_mse: 143.3944\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "43\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3836 - mse: 0.3836 - val_loss: 241.4281 - val_mse: 241.4281\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2358 - mse: 0.2358 - val_loss: 851.3550 - val_mse: 851.3550\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1887 - mse: 0.1887 - val_loss: 3102.4734 - val_mse: 3102.4734\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1717 - mse: 0.1717 - val_loss: 0.5723 - val_mse: 0.5723\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1495 - mse: 0.1495 - val_loss: 10460.9072 - val_mse: 10460.9072\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1396 - mse: 0.1396 - val_loss: 2391.6443 - val_mse: 2391.6443\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1302 - mse: 0.1302 - val_loss: 594.2408 - val_mse: 594.2408\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1347 - mse: 0.1347 - val_loss: 25.7474 - val_mse: 25.7474\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1353 - mse: 0.1353 - val_loss: 6.6323 - val_mse: 6.6323\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1228 - mse: 0.1228 - val_loss: 30.1481 - val_mse: 30.1481\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1211 - mse: 0.1211 - val_loss: 7215.0723 - val_mse: 7215.0723\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1149 - mse: 0.1149 - val_loss: 0.9846 - val_mse: 0.9846\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1196 - mse: 0.1196 - val_loss: 38.2347 - val_mse: 38.2347\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1128 - mse: 0.1128 - val_loss: 121.9421 - val_mse: 121.9421\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "44\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3243 - mse: 0.3243 - val_loss: 1260.1210 - val_mse: 1260.1210\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2136 - mse: 0.2136 - val_loss: 1676.5762 - val_mse: 1676.5762\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1775 - mse: 0.1775 - val_loss: 13041.3564 - val_mse: 13041.3564\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1601 - mse: 0.1601 - val_loss: 13.9156 - val_mse: 13.9156\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1436 - mse: 0.1436 - val_loss: 4167.7583 - val_mse: 4167.7583\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1390 - mse: 0.1390 - val_loss: 30.1228 - val_mse: 30.1228\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1287 - mse: 0.1287 - val_loss: 6.0754 - val_mse: 6.0754\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1259 - mse: 0.1259 - val_loss: 2.8046 - val_mse: 2.8046\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1287 - mse: 0.1287 - val_loss: 1612.5867 - val_mse: 1612.5867\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 158.1272 - val_mse: 158.1272\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1201 - mse: 0.1201 - val_loss: 5.1047 - val_mse: 5.1047\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1117 - mse: 0.1117 - val_loss: 21.4914 - val_mse: 21.4914\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1145 - mse: 0.1145 - val_loss: 324.0308 - val_mse: 324.0308\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1105 - mse: 0.1105 - val_loss: 2768.9600 - val_mse: 2768.9600\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1076 - mse: 0.1076 - val_loss: 11.2717 - val_mse: 11.2717\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1099 - mse: 0.1099 - val_loss: 29.1383 - val_mse: 29.1383\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1097 - mse: 0.1097 - val_loss: 1945.1172 - val_mse: 1945.1172\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1034 - mse: 0.1034 - val_loss: 1.2365 - val_mse: 1.2365\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1037 - mse: 0.1037 - val_loss: 1715.9564 - val_mse: 1715.9564\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 1.6555 - val_mse: 1.6555\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1004 - mse: 0.1004 - val_loss: 13241.9668 - val_mse: 13241.9668\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0986 - mse: 0.0986 - val_loss: 404.6118 - val_mse: 404.6118\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1014 - mse: 0.1014 - val_loss: 9.6389 - val_mse: 9.6389\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 149.9606 - val_mse: 149.9606\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0966 - mse: 0.0966 - val_loss: 31.1220 - val_mse: 31.1220\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 444.7918 - val_mse: 444.7918\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 59.2726 - val_mse: 59.2726\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.8900 - val_mse: 0.8900\n",
      "Epoch 29/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 44.8429 - val_mse: 44.8429\n",
      "Epoch 30/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0952 - mse: 0.0952 - val_loss: 50.7518 - val_mse: 50.7518\n",
      "Epoch 31/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 13.4646 - val_mse: 13.4646\n",
      "Epoch 32/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 11.0452 - val_mse: 11.0452\n",
      "Epoch 33/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 190.2438 - val_mse: 190.2438\n",
      "Epoch 34/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 142.9309 - val_mse: 142.9309\n",
      "Epoch 35/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0911 - mse: 0.0911 - val_loss: 4.3226 - val_mse: 4.3226\n",
      "Epoch 36/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 1647.0293 - val_mse: 1647.0293\n",
      "Epoch 37/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 21.9525 - val_mse: 21.9525\n",
      "Epoch 38/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 1049.9023 - val_mse: 1049.9023\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "45\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3378 - mse: 0.3378 - val_loss: 675.6494 - val_mse: 675.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2196 - mse: 0.2196 - val_loss: 1.5362 - val_mse: 1.5362\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1836 - mse: 0.1836 - val_loss: 1306.8153 - val_mse: 1306.8153\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1634 - mse: 0.1634 - val_loss: 299.6060 - val_mse: 299.6060\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1457 - mse: 0.1457 - val_loss: 7169.0537 - val_mse: 7169.0537\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1417 - mse: 0.1417 - val_loss: 1619.4716 - val_mse: 1619.4716\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 4.1001 - val_mse: 4.1001\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1303 - mse: 0.1303 - val_loss: 1.5988 - val_mse: 1.5988\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1309 - mse: 0.1309 - val_loss: 192.4756 - val_mse: 192.4756\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1196 - mse: 0.1196 - val_loss: 246.1134 - val_mse: 246.1134\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1204 - mse: 0.1204 - val_loss: 41.1017 - val_mse: 41.1017\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1147 - mse: 0.1147 - val_loss: 333.5779 - val_mse: 333.5779\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "46\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 5ms/step - loss: 0.3363 - mse: 0.3363 - val_loss: 839.7464 - val_mse: 839.7464\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2151 - mse: 0.2151 - val_loss: 68.4066 - val_mse: 68.4066\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1761 - mse: 0.1761 - val_loss: 5784.1860 - val_mse: 5784.1860\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1537 - mse: 0.1537 - val_loss: 433.6331 - val_mse: 433.6331\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1496 - mse: 0.1496 - val_loss: 588.9943 - val_mse: 588.9943\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1429 - mse: 0.1429 - val_loss: 54.6454 - val_mse: 54.6454\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 3.8008 - val_mse: 3.8008\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1292 - mse: 0.1292 - val_loss: 0.7207 - val_mse: 0.7207\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1341 - mse: 0.1341 - val_loss: 63.0593 - val_mse: 63.0593\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1187 - mse: 0.1187 - val_loss: 81.0775 - val_mse: 81.0775\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1199 - mse: 0.1199 - val_loss: 22.3892 - val_mse: 22.3892\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1126 - mse: 0.1126 - val_loss: 34.0264 - val_mse: 34.0264\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 80.5449 - val_mse: 80.5449\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1163 - mse: 0.1163 - val_loss: 829.4230 - val_mse: 829.4230\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 495.6732 - val_mse: 495.6732\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 75.6923 - val_mse: 75.6923\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 28.1743 - val_mse: 28.1743\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 2028.9794 - val_mse: 2028.9794\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "47\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3766 - mse: 0.3766 - val_loss: 1289.6819 - val_mse: 1289.6819\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2387 - mse: 0.2387 - val_loss: 792.7892 - val_mse: 792.7892\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1919 - mse: 0.1919 - val_loss: 6592.0000 - val_mse: 6592.0000\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1712 - mse: 0.1712 - val_loss: 31.7643 - val_mse: 31.7643\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1531 - mse: 0.1531 - val_loss: 10995.4473 - val_mse: 10995.4473\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1382 - mse: 0.1382 - val_loss: 614.1474 - val_mse: 614.1474\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1285 - mse: 0.1285 - val_loss: 81.1861 - val_mse: 81.1861\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1314 - mse: 0.1314 - val_loss: 1.0626 - val_mse: 1.0626\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1428 - mse: 0.1428 - val_loss: 2427.8853 - val_mse: 2427.8853\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 539.7675 - val_mse: 539.7675\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1209 - mse: 0.1209 - val_loss: 354.3689 - val_mse: 354.3689\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1150 - mse: 0.1150 - val_loss: 3.9208 - val_mse: 3.9208\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1168 - mse: 0.1168 - val_loss: 15.0920 - val_mse: 15.0920\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.9756 - val_mse: 0.9756\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 5.2318 - val_mse: 5.2318\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1114 - mse: 0.1114 - val_loss: 804.6909 - val_mse: 804.6909\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1142 - mse: 0.1142 - val_loss: 3790.5747 - val_mse: 3790.5747\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1054 - mse: 0.1054 - val_loss: 153.5017 - val_mse: 153.5017\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 246.4048 - val_mse: 246.4048\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1046 - mse: 0.1046 - val_loss: 2.1323 - val_mse: 2.1323\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 12436.9463 - val_mse: 12436.9463\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0976 - mse: 0.0976 - val_loss: 1651.3231 - val_mse: 1651.3231\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 6.5406 - val_mse: 6.5406\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0985 - mse: 0.0985 - val_loss: 7.7795 - val_mse: 7.7795\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "48\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3818 - mse: 0.3818 - val_loss: 3434.9465 - val_mse: 3434.9465\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2402 - mse: 0.2402 - val_loss: 2132.5425 - val_mse: 2132.5425\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2022 - mse: 0.2022 - val_loss: 5337.8696 - val_mse: 5337.8696\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1728 - mse: 0.1728 - val_loss: 6.4191 - val_mse: 6.4191\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1582 - mse: 0.1582 - val_loss: 8198.3398 - val_mse: 8198.3398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1486 - mse: 0.1486 - val_loss: 336.4863 - val_mse: 336.4863\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1336 - mse: 0.1336 - val_loss: 0.8854 - val_mse: 0.8854\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1349 - mse: 0.1349 - val_loss: 10.2179 - val_mse: 10.2179\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1361 - mse: 0.1361 - val_loss: 71.8091 - val_mse: 71.8091\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1228 - mse: 0.1228 - val_loss: 806.7891 - val_mse: 806.7891\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1198 - mse: 0.1198 - val_loss: 0.5676 - val_mse: 0.5676\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 670.0389 - val_mse: 670.0389\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1140 - mse: 0.1140 - val_loss: 37.4453 - val_mse: 37.4453\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1078 - mse: 0.1078 - val_loss: 61.5389 - val_mse: 61.5389\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 10.4303 - val_mse: 10.4303\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1148 - mse: 0.1148 - val_loss: 4915.7383 - val_mse: 4915.7383\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1123 - mse: 0.1123 - val_loss: 2482.6289 - val_mse: 2482.6289\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1014 - mse: 0.1014 - val_loss: 2344.5464 - val_mse: 2344.5464\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1057 - mse: 0.1057 - val_loss: 2247.9321 - val_mse: 2247.9321\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1036 - mse: 0.1036 - val_loss: 57.3431 - val_mse: 57.3431\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 772.4943 - val_mse: 772.4943\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "49\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3474 - mse: 0.3474 - val_loss: 786.2775 - val_mse: 786.2775\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2312 - mse: 0.2312 - val_loss: 14.8751 - val_mse: 14.8751\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1825 - mse: 0.1825 - val_loss: 8563.0586 - val_mse: 8563.0586\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1607 - mse: 0.1607 - val_loss: 156.2027 - val_mse: 156.2027\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1531 - mse: 0.1531 - val_loss: 4810.7817 - val_mse: 4810.7817\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1393 - mse: 0.1393 - val_loss: 1077.3884 - val_mse: 1077.3884\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1326 - mse: 0.1326 - val_loss: 26.8676 - val_mse: 26.8676\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1301 - mse: 0.1301 - val_loss: 10.3761 - val_mse: 10.3761\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 1.1998 - val_mse: 1.1998\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1250 - mse: 0.1250 - val_loss: 29.7925 - val_mse: 29.7925\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1229 - mse: 0.1229 - val_loss: 1437.2565 - val_mse: 1437.2565\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1145 - mse: 0.1145 - val_loss: 7.3341 - val_mse: 7.3341\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1115 - mse: 0.1115 - val_loss: 188.3811 - val_mse: 188.3811\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 186.5117 - val_mse: 186.5117\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1081 - mse: 0.1081 - val_loss: 685.4041 - val_mse: 685.4041\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1106 - mse: 0.1106 - val_loss: 18.9788 - val_mse: 18.9788\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 1531.2435 - val_mse: 1531.2435\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 2109.2034 - val_mse: 2109.2034\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 1191.3966 - val_mse: 1191.3966\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "50\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3639 - mse: 0.3639 - val_loss: 1740.8801 - val_mse: 1740.8801\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2317 - mse: 0.2317 - val_loss: 240.6396 - val_mse: 240.6396\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1978 - mse: 0.1978 - val_loss: 11714.2061 - val_mse: 11714.2061\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1752 - mse: 0.1752 - val_loss: 0.6641 - val_mse: 0.6641\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1555 - mse: 0.1555 - val_loss: 3455.9695 - val_mse: 3455.9695\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1426 - mse: 0.1426 - val_loss: 0.6994 - val_mse: 0.6994\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1331 - mse: 0.1331 - val_loss: 0.8813 - val_mse: 0.8813\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 483.8460 - val_mse: 483.8460\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1334 - mse: 0.1334 - val_loss: 46.6825 - val_mse: 46.6825\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1218 - mse: 0.1218 - val_loss: 76.9791 - val_mse: 76.9791\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1189 - mse: 0.1189 - val_loss: 51.9801 - val_mse: 51.9801\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 1.8551 - val_mse: 1.8551\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1130 - mse: 0.1130 - val_loss: 25.0165 - val_mse: 25.0165\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1087 - mse: 0.1087 - val_loss: 109.3132 - val_mse: 109.3132\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "51\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3482 - mse: 0.3482 - val_loss: 4621.4551 - val_mse: 4621.4551\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2194 - mse: 0.2194 - val_loss: 49.8919 - val_mse: 49.8919\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1820 - mse: 0.1820 - val_loss: 4929.2173 - val_mse: 4929.2173\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1555 - mse: 0.1555 - val_loss: 26.5579 - val_mse: 26.5579\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1509 - mse: 0.1509 - val_loss: 7220.4736 - val_mse: 7220.4736\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1373 - mse: 0.1373 - val_loss: 47.0688 - val_mse: 47.0688\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1272 - mse: 0.1272 - val_loss: 653.7614 - val_mse: 653.7614\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1260 - mse: 0.1260 - val_loss: 32.7458 - val_mse: 32.7458\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1346 - mse: 0.1346 - val_loss: 406.1354 - val_mse: 406.1354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 306.7550 - val_mse: 306.7550\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1200 - mse: 0.1200 - val_loss: 27.8980 - val_mse: 27.8980\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1098 - mse: 0.1098 - val_loss: 4.4598 - val_mse: 4.4598\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1132 - mse: 0.1132 - val_loss: 9.7151 - val_mse: 9.7151\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1116 - mse: 0.1116 - val_loss: 986.8654 - val_mse: 986.8654\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 20.9095 - val_mse: 20.9095\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1130 - mse: 0.1130 - val_loss: 0.7109 - val_mse: 0.7109\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1097 - mse: 0.1097 - val_loss: 1614.1730 - val_mse: 1614.1730\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1037 - mse: 0.1037 - val_loss: 104.9062 - val_mse: 104.9062\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 3.2360 - val_mse: 3.2360\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1008 - mse: 0.1008 - val_loss: 0.9789 - val_mse: 0.9789\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 11278.8262 - val_mse: 11278.8262\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 577.5934 - val_mse: 577.5934\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1004 - mse: 0.1004 - val_loss: 26.7614 - val_mse: 26.7614\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 12.3003 - val_mse: 12.3003\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 23.0806 - val_mse: 23.0806\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0999 - mse: 0.0999 - val_loss: 1423.0391 - val_mse: 1423.0391\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "52\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3567 - mse: 0.3567 - val_loss: 2156.1086 - val_mse: 2156.1086\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2226 - mse: 0.2226 - val_loss: 1.3076 - val_mse: 1.3076\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1865 - mse: 0.1865 - val_loss: 2776.0505 - val_mse: 2776.0505\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1644 - mse: 0.1644 - val_loss: 94.2511 - val_mse: 94.2511\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1447 - mse: 0.1447 - val_loss: 2858.6558 - val_mse: 2858.6558\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1390 - mse: 0.1390 - val_loss: 2596.1816 - val_mse: 2596.1816\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1288 - mse: 0.1288 - val_loss: 47.9713 - val_mse: 47.9713\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1364 - mse: 0.1364 - val_loss: 7.3092 - val_mse: 7.3092\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1297 - mse: 0.1297 - val_loss: 34.1352 - val_mse: 34.1352\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 18.3883 - val_mse: 18.3883\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 5.0310 - val_mse: 5.0310\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1104 - mse: 0.1104 - val_loss: 265.4536 - val_mse: 265.4536\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "53\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3467 - mse: 0.3467 - val_loss: 1465.4135 - val_mse: 1465.4135\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2337 - mse: 0.2337 - val_loss: 327.8739 - val_mse: 327.8739\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1884 - mse: 0.1884 - val_loss: 7975.7822 - val_mse: 7975.7822\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1694 - mse: 0.1694 - val_loss: 15.2563 - val_mse: 15.2563\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1459 - mse: 0.1459 - val_loss: 4850.9653 - val_mse: 4850.9653\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1338 - mse: 0.1338 - val_loss: 2872.9368 - val_mse: 2872.9368\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1226 - mse: 0.1226 - val_loss: 180.4362 - val_mse: 180.4362\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1246 - mse: 0.1246 - val_loss: 2.8595 - val_mse: 2.8595\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 72.3271 - val_mse: 72.3271\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1166 - mse: 0.1166 - val_loss: 3.8161 - val_mse: 3.8161\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 363.4913 - val_mse: 363.4913\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1088 - mse: 0.1088 - val_loss: 1.0207 - val_mse: 1.0207\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1122 - mse: 0.1122 - val_loss: 6.3156 - val_mse: 6.3156\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1043 - mse: 0.1043 - val_loss: 1981.9236 - val_mse: 1981.9236\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1022 - mse: 0.1022 - val_loss: 37.2954 - val_mse: 37.2954\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1063 - mse: 0.1063 - val_loss: 59.1612 - val_mse: 59.1612\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1047 - mse: 0.1047 - val_loss: 5721.7427 - val_mse: 5721.7427\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 1145.8479 - val_mse: 1145.8479\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1002 - mse: 0.1002 - val_loss: 1445.8339 - val_mse: 1445.8339\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0986 - mse: 0.0986 - val_loss: 161.6239 - val_mse: 161.6239\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 23826.6406 - val_mse: 23826.6406\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 512.0148 - val_mse: 512.0148\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "54\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3501 - mse: 0.3501 - val_loss: 78.6243 - val_mse: 78.6243\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.2098 - mse: 0.2098 - val_loss: 104.6623 - val_mse: 104.6623\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1824 - mse: 0.1824 - val_loss: 2913.1890 - val_mse: 2913.1890\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1521 - mse: 0.1521 - val_loss: 3.3007 - val_mse: 3.3007\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1393 - mse: 0.1393 - val_loss: 1147.6749 - val_mse: 1147.6749\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1287 - mse: 0.1287 - val_loss: 1056.9839 - val_mse: 1056.9839\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1232 - mse: 0.1232 - val_loss: 2.9407 - val_mse: 2.9407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1252 - mse: 0.1252 - val_loss: 10.3310 - val_mse: 10.3310\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1299 - mse: 0.1299 - val_loss: 3.4660 - val_mse: 3.4660\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 6.1871 - val_mse: 6.1871\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1131 - mse: 0.1131 - val_loss: 2255.3762 - val_mse: 2255.3762\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1063 - mse: 0.1063 - val_loss: 2.8467 - val_mse: 2.8467\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1089 - mse: 0.1089 - val_loss: 12.4365 - val_mse: 12.4365\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1069 - mse: 0.1069 - val_loss: 1060.4906 - val_mse: 1060.4906\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1002 - mse: 0.1002 - val_loss: 132.2130 - val_mse: 132.2130\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1064 - mse: 0.1064 - val_loss: 7.8604 - val_mse: 7.8604\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 1888.6445 - val_mse: 1888.6445\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0996 - mse: 0.0996 - val_loss: 3.2948 - val_mse: 3.2948\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0981 - mse: 0.0981 - val_loss: 2.6786 - val_mse: 2.6786\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 113.8341 - val_mse: 113.8341\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 1084.7920 - val_mse: 1084.7920\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 1877.0718 - val_mse: 1877.0718\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 11.1476 - val_mse: 11.1476\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 320.6772 - val_mse: 320.6772\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0909 - mse: 0.0909 - val_loss: 25.8237 - val_mse: 25.8237\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0957 - mse: 0.0957 - val_loss: 1.2921 - val_mse: 1.2921\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 18.6882 - val_mse: 18.6882\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 94.9522 - val_mse: 94.9522\n",
      "Epoch 29/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 122.2783 - val_mse: 122.2783\n",
      "Epoch 30/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 5.3566 - val_mse: 5.3566\n",
      "Epoch 31/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 1.5819 - val_mse: 1.5819\n",
      "Epoch 32/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 91.5116 - val_mse: 91.5116\n",
      "Epoch 33/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0854 - mse: 0.0854 - val_loss: 393.6709 - val_mse: 393.6709\n",
      "Epoch 34/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0842 - mse: 0.0842 - val_loss: 13.0518 - val_mse: 13.0518\n",
      "Epoch 35/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 188.4034 - val_mse: 188.4034\n",
      "Epoch 36/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0866 - mse: 0.0866 - val_loss: 251.7375 - val_mse: 251.7375\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "55\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3264 - mse: 0.3264 - val_loss: 178.2555 - val_mse: 178.2555\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2062 - mse: 0.2062 - val_loss: 1004.0217 - val_mse: 1004.0217\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1733 - mse: 0.1733 - val_loss: 443.7553 - val_mse: 443.7553\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1531 - mse: 0.1531 - val_loss: 26.7232 - val_mse: 26.7232\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1431 - mse: 0.1431 - val_loss: 3456.6416 - val_mse: 3456.6416\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1304 - mse: 0.1304 - val_loss: 47.8399 - val_mse: 47.8399\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1250 - mse: 0.1250 - val_loss: 14.4399 - val_mse: 14.4399\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1222 - mse: 0.1222 - val_loss: 32.8191 - val_mse: 32.8191\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1320 - mse: 0.1320 - val_loss: 692.8074 - val_mse: 692.8074\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1150 - mse: 0.1150 - val_loss: 332.7407 - val_mse: 332.7407\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1161 - mse: 0.1161 - val_loss: 7389.5474 - val_mse: 7389.5474\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1075 - mse: 0.1075 - val_loss: 19.7754 - val_mse: 19.7754\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1092 - mse: 0.1092 - val_loss: 151.4927 - val_mse: 151.4927\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 101.9848 - val_mse: 101.9848\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1034 - mse: 0.1034 - val_loss: 2.1593 - val_mse: 2.1593\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 589.8891 - val_mse: 589.8891\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1055 - mse: 0.1055 - val_loss: 166.9564 - val_mse: 166.9564\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0972 - mse: 0.0972 - val_loss: 1346.8070 - val_mse: 1346.8070\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0975 - mse: 0.0975 - val_loss: 806.5609 - val_mse: 806.5609\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0950 - mse: 0.0950 - val_loss: 49.6724 - val_mse: 49.6724\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 18848.8203 - val_mse: 18848.8203\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 2126.4844 - val_mse: 2126.4844\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0977 - mse: 0.0977 - val_loss: 711.6526 - val_mse: 711.6526\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 381.0129 - val_mse: 381.0129\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0915 - mse: 0.0915 - val_loss: 1.3684 - val_mse: 1.3684\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 262.0792 - val_mse: 262.0792\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 5.1684 - val_mse: 5.1684\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 57.7766 - val_mse: 57.7766\n",
      "Epoch 29/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 17.3848 - val_mse: 17.3848\n",
      "Epoch 30/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 163.6903 - val_mse: 163.6903\n",
      "Epoch 31/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 593.6551 - val_mse: 593.6551\n",
      "Epoch 32/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0904 - mse: 0.0904 - val_loss: 243.9122 - val_mse: 243.9122\n",
      "Epoch 33/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0868 - mse: 0.0868 - val_loss: 111.7548 - val_mse: 111.7548\n",
      "Epoch 34/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 135.3033 - val_mse: 135.3033\n",
      "Epoch 35/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 41.8812 - val_mse: 41.8812\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "56\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3471 - mse: 0.3471 - val_loss: 709.3209 - val_mse: 709.3209\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2050 - mse: 0.2050 - val_loss: 99.6928 - val_mse: 99.6928\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1789 - mse: 0.1789 - val_loss: 5512.9917 - val_mse: 5512.9917\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1517 - mse: 0.1517 - val_loss: 13.5412 - val_mse: 13.5412\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1445 - mse: 0.1445 - val_loss: 79.0540 - val_mse: 79.0540\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1338 - mse: 0.1338 - val_loss: 595.7213 - val_mse: 595.7213\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 75.9623 - val_mse: 75.9623\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 4.5470 - val_mse: 4.5470\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1222 - mse: 0.1222 - val_loss: 1.4045 - val_mse: 1.4045\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1141 - mse: 0.1141 - val_loss: 228.6975 - val_mse: 228.6975\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 2406.4058 - val_mse: 2406.4058\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1061 - mse: 0.1061 - val_loss: 6.0586 - val_mse: 6.0586\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1080 - mse: 0.1080 - val_loss: 1.4859 - val_mse: 1.4859\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 2.9649 - val_mse: 2.9649\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1053 - mse: 0.1053 - val_loss: 3.9629 - val_mse: 3.9629\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1037 - mse: 0.1037 - val_loss: 14.5261 - val_mse: 14.5261\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1020 - mse: 0.1020 - val_loss: 2780.6970 - val_mse: 2780.6970\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 68.1079 - val_mse: 68.1079\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 8.4260 - val_mse: 8.4260\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "57\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3403 - mse: 0.3403 - val_loss: 470.0345 - val_mse: 470.0345\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2128 - mse: 0.2128 - val_loss: 12.2379 - val_mse: 12.2379\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1755 - mse: 0.1755 - val_loss: 2059.4373 - val_mse: 2059.4373\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1557 - mse: 0.1557 - val_loss: 7.7132 - val_mse: 7.7132\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1436 - mse: 0.1436 - val_loss: 313.8542 - val_mse: 313.8542\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1325 - mse: 0.1325 - val_loss: 3076.8315 - val_mse: 3076.8315\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 85.3981 - val_mse: 85.3981\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 78.4537 - val_mse: 78.4537\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 357.5161 - val_mse: 357.5161\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 494.9035 - val_mse: 494.9035\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1129 - mse: 0.1129 - val_loss: 4.5530 - val_mse: 4.5530\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1069 - mse: 0.1069 - val_loss: 1.7356 - val_mse: 1.7356\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 96.0688 - val_mse: 96.0688\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1041 - mse: 0.1041 - val_loss: 1355.0631 - val_mse: 1355.0631\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 9.2271 - val_mse: 9.2271\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1082 - mse: 0.1082 - val_loss: 114.0634 - val_mse: 114.0634\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 25.5690 - val_mse: 25.5690\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0981 - mse: 0.0981 - val_loss: 2421.9785 - val_mse: 2421.9785\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1000 - mse: 0.1000 - val_loss: 81.0558 - val_mse: 81.0558\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 1.8359 - val_mse: 1.8359\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 11867.6934 - val_mse: 11867.6934\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 971.1934 - val_mse: 971.1934\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "58\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3400 - mse: 0.3400 - val_loss: 731.5635 - val_mse: 731.5635\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2041 - mse: 0.2041 - val_loss: 25.4566 - val_mse: 25.4566\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1625 - mse: 0.1625 - val_loss: 77.5832 - val_mse: 77.5832\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1457 - mse: 0.1457 - val_loss: 109.1133 - val_mse: 109.1133\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 2315.9807 - val_mse: 2315.9807\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1265 - mse: 0.1265 - val_loss: 460.6302 - val_mse: 460.6302\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1179 - mse: 0.1179 - val_loss: 28.6289 - val_mse: 28.6289\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1201 - mse: 0.1201 - val_loss: 29.6793 - val_mse: 29.6793\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1199 - mse: 0.1199 - val_loss: 807.0620 - val_mse: 807.0620\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1150 - mse: 0.1150 - val_loss: 439.5937 - val_mse: 439.5937\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 4478.8228 - val_mse: 4478.8228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1048 - mse: 0.1048 - val_loss: 31.7529 - val_mse: 31.7529\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "59\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3567 - mse: 0.3567 - val_loss: 242.2856 - val_mse: 242.2856\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.2158 - mse: 0.2158 - val_loss: 108.8128 - val_mse: 108.8128\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1684 - mse: 0.1684 - val_loss: 4526.5151 - val_mse: 4526.5151\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1512 - mse: 0.1512 - val_loss: 1.7802 - val_mse: 1.7802\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 5984.2881 - val_mse: 5984.2881\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1309 - mse: 0.1309 - val_loss: 2484.6760 - val_mse: 2484.6760\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1214 - mse: 0.1214 - val_loss: 0.8304 - val_mse: 0.8304\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1237 - mse: 0.1237 - val_loss: 8.5524 - val_mse: 8.5524\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1239 - mse: 0.1239 - val_loss: 3202.5859 - val_mse: 3202.5859\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1143 - mse: 0.1143 - val_loss: 14.8286 - val_mse: 14.8286\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 13.1133 - val_mse: 13.1133\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 16.2958 - val_mse: 16.2958\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 2.0146 - val_mse: 2.0146\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 2.5583 - val_mse: 2.5583\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1006 - mse: 0.1006 - val_loss: 35.1281 - val_mse: 35.1281\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1047 - mse: 0.1047 - val_loss: 11.6486 - val_mse: 11.6486\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1026 - mse: 0.1026 - val_loss: 44.1026 - val_mse: 44.1026\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "60\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3347 - mse: 0.3347 - val_loss: 341.5320 - val_mse: 341.5320\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 135.4396 - val_mse: 135.4396\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1598 - mse: 0.1598 - val_loss: 1398.3101 - val_mse: 1398.3101\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1431 - mse: 0.1431 - val_loss: 390.6101 - val_mse: 390.6101\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1332 - mse: 0.1332 - val_loss: 540.0710 - val_mse: 540.0710\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1271 - mse: 0.1271 - val_loss: 166.3995 - val_mse: 166.3995\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1185 - mse: 0.1185 - val_loss: 126.3258 - val_mse: 126.3258\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1160 - mse: 0.1160 - val_loss: 5.6825 - val_mse: 5.6825\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 25.4068 - val_mse: 25.4068\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1156 - mse: 0.1156 - val_loss: 839.1251 - val_mse: 839.1251\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1128 - mse: 0.1128 - val_loss: 1.0973 - val_mse: 1.0973\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1075 - mse: 0.1075 - val_loss: 220.5326 - val_mse: 220.5326\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1053 - mse: 0.1053 - val_loss: 98.0294 - val_mse: 98.0294\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1031 - mse: 0.1031 - val_loss: 148.9037 - val_mse: 148.9037\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0999 - mse: 0.0999 - val_loss: 34.7113 - val_mse: 34.7113\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 2.2809 - val_mse: 2.2809\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1015 - mse: 0.1015 - val_loss: 422.7552 - val_mse: 422.7552\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0975 - mse: 0.0975 - val_loss: 1895.6398 - val_mse: 1895.6398\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 133.9239 - val_mse: 133.9239\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0946 - mse: 0.0946 - val_loss: 0.6698 - val_mse: 0.6698\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 16484.7637 - val_mse: 16484.7637\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0911 - mse: 0.0911 - val_loss: 4297.8354 - val_mse: 4297.8354\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 14.3371 - val_mse: 14.3371\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 612.4142 - val_mse: 612.4142\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0925 - mse: 0.0925 - val_loss: 27.1851 - val_mse: 27.1851\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0946 - mse: 0.0946 - val_loss: 995.5262 - val_mse: 995.5262\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0911 - mse: 0.0911 - val_loss: 1.0690 - val_mse: 1.0690\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0898 - mse: 0.0898 - val_loss: 1.0896 - val_mse: 1.0896\n",
      "Epoch 29/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0866 - mse: 0.0866 - val_loss: 70.2406 - val_mse: 70.2406\n",
      "Epoch 30/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 8.3646 - val_mse: 8.3646\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "61\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3335 - mse: 0.3335 - val_loss: 267.0840 - val_mse: 267.0840\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1936 - mse: 0.1936 - val_loss: 1888.9635 - val_mse: 1888.9635\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1616 - mse: 0.1616 - val_loss: 2343.4443 - val_mse: 2343.4443\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1462 - mse: 0.1462 - val_loss: 1.0834 - val_mse: 1.0834\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1407 - mse: 0.1407 - val_loss: 410.9856 - val_mse: 410.9856\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1252 - mse: 0.1252 - val_loss: 1.3148 - val_mse: 1.3148\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1190 - mse: 0.1190 - val_loss: 0.9828 - val_mse: 0.9828\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 5.9842 - val_mse: 5.9842\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 2.0859 - val_mse: 2.0859\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1106 - mse: 0.1106 - val_loss: 251.3189 - val_mse: 251.3189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1111 - mse: 0.1111 - val_loss: 1.1299 - val_mse: 1.1299\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 26.4541 - val_mse: 26.4541\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1039 - mse: 0.1039 - val_loss: 170.0142 - val_mse: 170.0142\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1017 - mse: 0.1017 - val_loss: 261.3389 - val_mse: 261.3389\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 9.4792 - val_mse: 9.4792\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 24.7786 - val_mse: 24.7786\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 29.0300 - val_mse: 29.0300\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "62\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3207 - mse: 0.3207 - val_loss: 330.9895 - val_mse: 330.9895\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2027 - mse: 0.2027 - val_loss: 835.0111 - val_mse: 835.0111\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1536 - mse: 0.1536 - val_loss: 1465.5144 - val_mse: 1465.5144\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1496 - mse: 0.1496 - val_loss: 14.5099 - val_mse: 14.5099\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1396 - mse: 0.1396 - val_loss: 97.3228 - val_mse: 97.3228\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 175.6008 - val_mse: 175.6008\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1199 - mse: 0.1199 - val_loss: 2.9745 - val_mse: 2.9745\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1188 - mse: 0.1188 - val_loss: 2.1047 - val_mse: 2.1047\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1212 - mse: 0.1212 - val_loss: 0.9525 - val_mse: 0.9525\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 157.2118 - val_mse: 157.2118\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1095 - mse: 0.1095 - val_loss: 31.4839 - val_mse: 31.4839\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1040 - mse: 0.1040 - val_loss: 74.6803 - val_mse: 74.6803\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1060 - mse: 0.1060 - val_loss: 11.4313 - val_mse: 11.4313\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1002 - mse: 0.1002 - val_loss: 266.9441 - val_mse: 266.9441\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 415.3321 - val_mse: 415.3321\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 11.8932 - val_mse: 11.8932\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 141.0213 - val_mse: 141.0213\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 458.1513 - val_mse: 458.1513\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 123.6339 - val_mse: 123.6339\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "63\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3260 - mse: 0.3260 - val_loss: 3.7060 - val_mse: 3.7060\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1907 - mse: 0.1907 - val_loss: 1205.9688 - val_mse: 1205.9688\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1618 - mse: 0.1618 - val_loss: 455.5232 - val_mse: 455.5232\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1456 - mse: 0.1456 - val_loss: 22.3917 - val_mse: 22.3917\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1340 - mse: 0.1340 - val_loss: 26.3071 - val_mse: 26.3071\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1264 - mse: 0.1264 - val_loss: 1972.3134 - val_mse: 1972.3134\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1180 - mse: 0.1180 - val_loss: 0.9570 - val_mse: 0.9570\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1197 - mse: 0.1197 - val_loss: 138.2159 - val_mse: 138.2159\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1264 - mse: 0.1264 - val_loss: 24.6890 - val_mse: 24.6890\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1127 - mse: 0.1127 - val_loss: 187.3278 - val_mse: 187.3278\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 3.7594 - val_mse: 3.7594\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1040 - mse: 0.1040 - val_loss: 0.8623 - val_mse: 0.8623\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 20.6829 - val_mse: 20.6829\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1038 - mse: 0.1038 - val_loss: 17.6303 - val_mse: 17.6303\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0996 - mse: 0.0996 - val_loss: 109.9546 - val_mse: 109.9546\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1041 - mse: 0.1041 - val_loss: 5.6650 - val_mse: 5.6650\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 0.6594 - val_mse: 0.6594\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0976 - mse: 0.0976 - val_loss: 51.9130 - val_mse: 51.9130\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 94.9244 - val_mse: 94.9244\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 174.4174 - val_mse: 174.4174\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 10225.2666 - val_mse: 10225.2666\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 739.6525 - val_mse: 739.6525\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 17.4242 - val_mse: 17.4242\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0904 - mse: 0.0904 - val_loss: 63.0362 - val_mse: 63.0362\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 4.9501 - val_mse: 4.9501\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0933 - mse: 0.0933 - val_loss: 32.7144 - val_mse: 32.7144\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 120.1480 - val_mse: 120.1480\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "64\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3150 - mse: 0.3150 - val_loss: 8.2824 - val_mse: 8.2824\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1847 - mse: 0.1847 - val_loss: 997.5500 - val_mse: 997.5500\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1506 - mse: 0.1506 - val_loss: 6240.1387 - val_mse: 6240.1387\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1466 - mse: 0.1466 - val_loss: 15.3407 - val_mse: 15.3407\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1318 - mse: 0.1318 - val_loss: 4276.3706 - val_mse: 4276.3706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 16.4152 - val_mse: 16.4152\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1167 - mse: 0.1167 - val_loss: 65.0145 - val_mse: 65.0145\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1160 - mse: 0.1160 - val_loss: 0.6146 - val_mse: 0.6146\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1176 - mse: 0.1176 - val_loss: 479.0239 - val_mse: 479.0239\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 5.4791 - val_mse: 5.4791\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 181.8932 - val_mse: 181.8932\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1035 - mse: 0.1035 - val_loss: 41.1055 - val_mse: 41.1055\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1036 - mse: 0.1036 - val_loss: 165.6908 - val_mse: 165.6908\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1010 - mse: 0.1010 - val_loss: 1.1368 - val_mse: 1.1368\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0977 - mse: 0.0977 - val_loss: 130.2706 - val_mse: 130.2706\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1029 - mse: 0.1029 - val_loss: 3.2117 - val_mse: 3.2117\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1023 - mse: 0.1023 - val_loss: 15.8576 - val_mse: 15.8576\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0955 - mse: 0.0955 - val_loss: 163.0171 - val_mse: 163.0171\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "65\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3157 - mse: 0.3157 - val_loss: 716.6815 - val_mse: 716.6815\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1918 - mse: 0.1918 - val_loss: 580.2770 - val_mse: 580.2770\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1597 - mse: 0.1597 - val_loss: 451.1032 - val_mse: 451.1032\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 36.3695 - val_mse: 36.3695\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1360 - mse: 0.1360 - val_loss: 1436.2046 - val_mse: 1436.2046\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1256 - mse: 0.1256 - val_loss: 531.7253 - val_mse: 531.7253\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1213 - mse: 0.1213 - val_loss: 1.4619 - val_mse: 1.4619\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1180 - mse: 0.1180 - val_loss: 11.0970 - val_mse: 11.0970\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1224 - mse: 0.1224 - val_loss: 295.5950 - val_mse: 295.5950\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1124 - mse: 0.1124 - val_loss: 257.1898 - val_mse: 257.1898\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 10.1976 - val_mse: 10.1976\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1032 - mse: 0.1032 - val_loss: 1.4275 - val_mse: 1.4275\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 148.0584 - val_mse: 148.0584\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1014 - mse: 0.1014 - val_loss: 690.8459 - val_mse: 690.8459\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0987 - mse: 0.0987 - val_loss: 0.8715 - val_mse: 0.8715\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1022 - mse: 0.1022 - val_loss: 3.1022 - val_mse: 3.1022\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1033 - mse: 0.1033 - val_loss: 1623.3060 - val_mse: 1623.3060\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 65.3015 - val_mse: 65.3015\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 478.9838 - val_mse: 478.9838\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0950 - mse: 0.0950 - val_loss: 45.4864 - val_mse: 45.4864\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 7657.2520 - val_mse: 7657.2520\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0895 - mse: 0.0895 - val_loss: 5663.3394 - val_mse: 5663.3394\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 66.7196 - val_mse: 66.7196\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 16.9302 - val_mse: 16.9302\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 1620.7396 - val_mse: 1620.7396\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "66\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3326 - mse: 0.3326 - val_loss: 960.5066 - val_mse: 960.5066\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1923 - mse: 0.1923 - val_loss: 1315.5862 - val_mse: 1315.5862\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1555 - mse: 0.1555 - val_loss: 2564.4031 - val_mse: 2564.4031\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1397 - mse: 0.1397 - val_loss: 22.5130 - val_mse: 22.5130\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 599.7659 - val_mse: 599.7659\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1244 - mse: 0.1244 - val_loss: 2111.7646 - val_mse: 2111.7646\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1147 - mse: 0.1147 - val_loss: 27.6205 - val_mse: 27.6205\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1175 - mse: 0.1175 - val_loss: 0.9681 - val_mse: 0.9681\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1219 - mse: 0.1219 - val_loss: 1709.8794 - val_mse: 1709.8794\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 231.2199 - val_mse: 231.2199\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1079 - mse: 0.1079 - val_loss: 0.7296 - val_mse: 0.7296\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1048 - mse: 0.1048 - val_loss: 15.3946 - val_mse: 15.3946\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1052 - mse: 0.1052 - val_loss: 7.2111 - val_mse: 7.2111\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 120.5140 - val_mse: 120.5140\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0978 - mse: 0.0978 - val_loss: 1.7735 - val_mse: 1.7735\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1049 - mse: 0.1049 - val_loss: 57.1523 - val_mse: 57.1523\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0989 - mse: 0.0989 - val_loss: 338.6054 - val_mse: 338.6054\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0950 - mse: 0.0950 - val_loss: 445.8548 - val_mse: 445.8548\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0964 - mse: 0.0964 - val_loss: 16.5402 - val_mse: 16.5402\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 58.3321 - val_mse: 58.3321\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 792.0073 - val_mse: 792.0073\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "67\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3307 - mse: 0.3307 - val_loss: 279.7596 - val_mse: 279.7596\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1885 - mse: 0.1885 - val_loss: 3993.1609 - val_mse: 3993.1609\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1536 - mse: 0.1536 - val_loss: 2431.7703 - val_mse: 2431.7703\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1386 - mse: 0.1386 - val_loss: 505.5016 - val_mse: 505.5016\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 65.0992 - val_mse: 65.0992\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1213 - mse: 0.1213 - val_loss: 2740.1226 - val_mse: 2740.1226\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1139 - mse: 0.1139 - val_loss: 0.6118 - val_mse: 0.6118\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1181 - mse: 0.1181 - val_loss: 94.5315 - val_mse: 94.5315\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1204 - mse: 0.1204 - val_loss: 10.8754 - val_mse: 10.8754\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1070 - mse: 0.1070 - val_loss: 26.4278 - val_mse: 26.4278\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1095 - mse: 0.1095 - val_loss: 7380.6982 - val_mse: 7380.6982\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1036 - mse: 0.1036 - val_loss: 98.2661 - val_mse: 98.2661\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 2.7042 - val_mse: 2.7042\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1015 - mse: 0.1015 - val_loss: 437.1772 - val_mse: 437.1772\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0966 - mse: 0.0966 - val_loss: 139.4750 - val_mse: 139.4750\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1026 - mse: 0.1026 - val_loss: 3.0097 - val_mse: 3.0097\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0976 - mse: 0.0976 - val_loss: 379.8073 - val_mse: 379.8073\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "68\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3350 - mse: 0.3350 - val_loss: 70.9642 - val_mse: 70.9642\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1957 - mse: 0.1957 - val_loss: 105.2389 - val_mse: 105.2389\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1558 - mse: 0.1558 - val_loss: 15324.0654 - val_mse: 15324.0654\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1466 - mse: 0.1466 - val_loss: 4.7319 - val_mse: 4.7319\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1386 - mse: 0.1386 - val_loss: 54.0284 - val_mse: 54.0284\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 620.9023 - val_mse: 620.9023\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1168 - mse: 0.1168 - val_loss: 8.5397 - val_mse: 8.5397\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 6.9224 - val_mse: 6.9224\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 3073.0940 - val_mse: 3073.0940\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 584.6519 - val_mse: 584.6519\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 1840.6543 - val_mse: 1840.6543\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1031 - mse: 0.1031 - val_loss: 1250.2065 - val_mse: 1250.2065\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1022 - mse: 0.1022 - val_loss: 12.1615 - val_mse: 12.1615\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 125.2194 - val_mse: 125.2194\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "69\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3292 - mse: 0.3292 - val_loss: 54.7742 - val_mse: 54.7742\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1847 - mse: 0.1847 - val_loss: 143.1025 - val_mse: 143.1025\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1552 - mse: 0.1552 - val_loss: 10700.3037 - val_mse: 10700.3037\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1434 - mse: 0.1434 - val_loss: 3.8767 - val_mse: 3.8767\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1379 - mse: 0.1379 - val_loss: 508.1692 - val_mse: 508.1692\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1267 - mse: 0.1267 - val_loss: 496.0905 - val_mse: 496.0905\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1160 - mse: 0.1160 - val_loss: 137.5473 - val_mse: 137.5473\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1165 - mse: 0.1165 - val_loss: 9.1584 - val_mse: 9.1584\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 14.2847 - val_mse: 14.2847\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 4.2853 - val_mse: 4.2853\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1087 - mse: 0.1087 - val_loss: 1.7426 - val_mse: 1.7426\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1019 - mse: 0.1019 - val_loss: 1.1423 - val_mse: 1.1423\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1024 - mse: 0.1024 - val_loss: 155.7951 - val_mse: 155.7951\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0999 - mse: 0.0999 - val_loss: 215.8949 - val_mse: 215.8949\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 16.4918 - val_mse: 16.4918\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1006 - mse: 0.1006 - val_loss: 43.8420 - val_mse: 43.8420\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 1015.9499 - val_mse: 1015.9499\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 316.2136 - val_mse: 316.2136\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0934 - mse: 0.0934 - val_loss: 1494.3561 - val_mse: 1494.3561\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 13.0924 - val_mse: 13.0924\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0856 - mse: 0.0856 - val_loss: 14770.9463 - val_mse: 14770.9463\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 44.8105 - val_mse: 44.8105\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "70\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3137 - mse: 0.3137 - val_loss: 138.2647 - val_mse: 138.2647\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1911 - mse: 0.1911 - val_loss: 1135.5325 - val_mse: 1135.5325\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1545 - mse: 0.1545 - val_loss: 411.6724 - val_mse: 411.6724\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 19.3746 - val_mse: 19.3746\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1320 - mse: 0.1320 - val_loss: 1123.1920 - val_mse: 1123.1920\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1208 - mse: 0.1208 - val_loss: 830.4266 - val_mse: 830.4266\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1163 - mse: 0.1163 - val_loss: 0.9222 - val_mse: 0.9222\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1135 - mse: 0.1135 - val_loss: 4.4394 - val_mse: 4.4394\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1180 - mse: 0.1180 - val_loss: 1.3767 - val_mse: 1.3767\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1072 - mse: 0.1072 - val_loss: 1.0990 - val_mse: 1.0990\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1048 - mse: 0.1048 - val_loss: 0.8928 - val_mse: 0.8928\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 10.3711 - val_mse: 10.3711\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1034 - mse: 0.1034 - val_loss: 5.0632 - val_mse: 5.0632\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 167.9094 - val_mse: 167.9094\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 1.7648 - val_mse: 1.7648\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1006 - mse: 0.1006 - val_loss: 5.4385 - val_mse: 5.4385\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 3.5623 - val_mse: 3.5623\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 183.5719 - val_mse: 183.5719\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 2.4140 - val_mse: 2.4140\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 51.1005 - val_mse: 51.1005\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 3143.8850 - val_mse: 3143.8850\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "71\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3102 - mse: 0.3102 - val_loss: 202.4222 - val_mse: 202.4222\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1829 - mse: 0.1829 - val_loss: 4.6070 - val_mse: 4.6070\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1554 - mse: 0.1554 - val_loss: 116.0664 - val_mse: 116.0664\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1372 - mse: 0.1372 - val_loss: 35.3856 - val_mse: 35.3856\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 1276.7755 - val_mse: 1276.7755\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 4563.4336 - val_mse: 4563.4336\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1105 - mse: 0.1105 - val_loss: 11.1302 - val_mse: 11.1302\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1131 - mse: 0.1131 - val_loss: 28.4700 - val_mse: 28.4700\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1172 - mse: 0.1172 - val_loss: 0.6988 - val_mse: 0.6988\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1058 - mse: 0.1058 - val_loss: 1.5151 - val_mse: 1.5151\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 20.6317 - val_mse: 20.6317\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0987 - mse: 0.0987 - val_loss: 3.3978 - val_mse: 3.3978\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 205.1040 - val_mse: 205.1040\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0945 - mse: 0.0945 - val_loss: 11.0717 - val_mse: 11.0717\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 3.1016 - val_mse: 3.1016\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0972 - mse: 0.0972 - val_loss: 99.1472 - val_mse: 99.1472\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 4.1005 - val_mse: 4.1005\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 104.5991 - val_mse: 104.5991\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0906 - mse: 0.0906 - val_loss: 5.8425 - val_mse: 5.8425\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "72\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3070 - mse: 0.3070 - val_loss: 511.6535 - val_mse: 511.6535\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1830 - mse: 0.1830 - val_loss: 273.9211 - val_mse: 273.9211\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1494 - mse: 0.1494 - val_loss: 805.7631 - val_mse: 805.7631\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1313 - mse: 0.1313 - val_loss: 752.6328 - val_mse: 752.6328\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1278 - mse: 0.1278 - val_loss: 510.0962 - val_mse: 510.0962\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1167 - mse: 0.1167 - val_loss: 2036.1324 - val_mse: 2036.1324\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 1.4565 - val_mse: 1.4565\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 41.0988 - val_mse: 41.0988\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 4.7309 - val_mse: 4.7309\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1036 - mse: 0.1036 - val_loss: 649.2017 - val_mse: 649.2017\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1026 - mse: 0.1026 - val_loss: 3364.6948 - val_mse: 3364.6948\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 7.2360 - val_mse: 7.2360\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 13.1270 - val_mse: 13.1270\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 11.5543 - val_mse: 11.5543\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 158.7150 - val_mse: 158.7150\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0959 - mse: 0.0959 - val_loss: 10.6481 - val_mse: 10.6481\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 1234.2338 - val_mse: 1234.2338\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "73\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2977 - mse: 0.2977 - val_loss: 41.2082 - val_mse: 41.2082\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1765 - mse: 0.1765 - val_loss: 180.4387 - val_mse: 180.4387\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1437 - mse: 0.1437 - val_loss: 179.0400 - val_mse: 179.0400\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1342 - mse: 0.1342 - val_loss: 444.4034 - val_mse: 444.4034\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1214 - mse: 0.1214 - val_loss: 157.1546 - val_mse: 157.1546\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1140 - mse: 0.1140 - val_loss: 175.2606 - val_mse: 175.2606\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1040 - mse: 0.1040 - val_loss: 2.9785 - val_mse: 2.9785\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1089 - mse: 0.1089 - val_loss: 3.3415 - val_mse: 3.3415\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1103 - mse: 0.1103 - val_loss: 200.0700 - val_mse: 200.0700\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 19.5759 - val_mse: 19.5759\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 2179.3718 - val_mse: 2179.3718\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 2.9149 - val_mse: 2.9149\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.8069 - val_mse: 0.8069\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 1.6164 - val_mse: 1.6164\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 84.5518 - val_mse: 84.5518\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 15.4768 - val_mse: 15.4768\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0890 - mse: 0.0890 - val_loss: 121.9509 - val_mse: 121.9509\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 2797.2346 - val_mse: 2797.2346\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0890 - mse: 0.0890 - val_loss: 1044.7737 - val_mse: 1044.7737\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0863 - mse: 0.0863 - val_loss: 13.7134 - val_mse: 13.7134\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 2675.1838 - val_mse: 2675.1838\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 3023.4905 - val_mse: 3023.4905\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 589.5042 - val_mse: 589.5042\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "74\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3428 - mse: 0.3428 - val_loss: 56.2879 - val_mse: 56.2879\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1914 - mse: 0.1914 - val_loss: 1066.7645 - val_mse: 1066.7645\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1500 - mse: 0.1500 - val_loss: 2920.7373 - val_mse: 2920.7373\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1322 - mse: 0.1322 - val_loss: 99.1679 - val_mse: 99.1679\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1319 - mse: 0.1319 - val_loss: 8460.5820 - val_mse: 8460.5820\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 202.1320 - val_mse: 202.1320\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1076 - mse: 0.1076 - val_loss: 2.1484 - val_mse: 2.1484\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 62.4412 - val_mse: 62.4412\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 12.6149 - val_mse: 12.6149\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1014 - mse: 0.1014 - val_loss: 8.6232 - val_mse: 8.6232\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 5.7351 - val_mse: 5.7351\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0969 - mse: 0.0969 - val_loss: 2907.4441 - val_mse: 2907.4441\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0966 - mse: 0.0966 - val_loss: 25.2696 - val_mse: 25.2696\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 18.0963 - val_mse: 18.0963\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0906 - mse: 0.0906 - val_loss: 17.4696 - val_mse: 17.4696\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0955 - mse: 0.0955 - val_loss: 24.8447 - val_mse: 24.8447\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0910 - mse: 0.0910 - val_loss: 1037.7693 - val_mse: 1037.7693\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "75\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3135 - mse: 0.3135 - val_loss: 54.3572 - val_mse: 54.3572\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1826 - mse: 0.1826 - val_loss: 318.8793 - val_mse: 318.8793\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1518 - mse: 0.1518 - val_loss: 948.0029 - val_mse: 948.0029\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1330 - mse: 0.1330 - val_loss: 1.8315 - val_mse: 1.8315\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1258 - mse: 0.1258 - val_loss: 9.8686 - val_mse: 9.8686\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1142 - mse: 0.1142 - val_loss: 1639.0948 - val_mse: 1639.0948\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 3.6155 - val_mse: 3.6155\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1058 - mse: 0.1058 - val_loss: 6109.6436 - val_mse: 6109.6436\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1102 - mse: 0.1102 - val_loss: 5.3755 - val_mse: 5.3755\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1012 - mse: 0.1012 - val_loss: 1.2627 - val_mse: 1.2627\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1012 - mse: 0.1012 - val_loss: 1023.5654 - val_mse: 1023.5654\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 15.9149 - val_mse: 15.9149\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 2.2830 - val_mse: 2.2830\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 117.2766 - val_mse: 117.2766\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0890 - mse: 0.0890 - val_loss: 16.4217 - val_mse: 16.4217\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 4.7363 - val_mse: 4.7363\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 517.6185 - val_mse: 517.6185\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0860 - mse: 0.0860 - val_loss: 1444.7266 - val_mse: 1444.7266\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 737.7500 - val_mse: 737.7500\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 14.1142 - val_mse: 14.1142\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "76\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3003 - mse: 0.3003 - val_loss: 5.6247 - val_mse: 5.6247\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1863 - mse: 0.1863 - val_loss: 94.3142 - val_mse: 94.3142\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1511 - mse: 0.1511 - val_loss: 851.6473 - val_mse: 851.6473\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1350 - mse: 0.1350 - val_loss: 2.2732 - val_mse: 2.2732\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1248 - mse: 0.1248 - val_loss: 6340.7036 - val_mse: 6340.7036\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1149 - mse: 0.1149 - val_loss: 2590.9685 - val_mse: 2590.9685\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1092 - mse: 0.1092 - val_loss: 17.8546 - val_mse: 17.8546\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1074 - mse: 0.1074 - val_loss: 10.7967 - val_mse: 10.7967\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1138 - mse: 0.1138 - val_loss: 1.0344 - val_mse: 1.0344\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1016 - mse: 0.1016 - val_loss: 107.1103 - val_mse: 107.1103\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0996 - mse: 0.0996 - val_loss: 1.8538 - val_mse: 1.8538\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 1040.6790 - val_mse: 1040.6790\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 278.9939 - val_mse: 278.9939\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 6.1740 - val_mse: 6.1740\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 12.1959 - val_mse: 12.1959\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 10.0695 - val_mse: 10.0695\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 1018.3993 - val_mse: 1018.3993\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0858 - mse: 0.0858 - val_loss: 3405.7317 - val_mse: 3405.7317\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0867 - mse: 0.0867 - val_loss: 229.0378 - val_mse: 229.0378\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "77\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3471 - mse: 0.3471 - val_loss: 475.9934 - val_mse: 475.9934\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1850 - mse: 0.1850 - val_loss: 194.9665 - val_mse: 194.9665\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1455 - mse: 0.1455 - val_loss: 9436.4639 - val_mse: 9436.4639\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1349 - mse: 0.1349 - val_loss: 1.3384 - val_mse: 1.3384\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1248 - mse: 0.1248 - val_loss: 1565.9883 - val_mse: 1565.9883\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1166 - mse: 0.1166 - val_loss: 5.4416 - val_mse: 5.4416\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 12.2366 - val_mse: 12.2366\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1072 - mse: 0.1072 - val_loss: 1945.1235 - val_mse: 1945.1235\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1103 - mse: 0.1103 - val_loss: 153.7433 - val_mse: 153.7433\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1025 - mse: 0.1025 - val_loss: 646.8909 - val_mse: 646.8909\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.8660 - val_mse: 0.8660\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 7.0842 - val_mse: 7.0842\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 2.1200 - val_mse: 2.1200\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0902 - mse: 0.0902 - val_loss: 1663.3826 - val_mse: 1663.3826\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 30.0462 - val_mse: 30.0462\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 9.1886 - val_mse: 9.1886\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0909 - mse: 0.0909 - val_loss: 1134.5682 - val_mse: 1134.5682\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0879 - mse: 0.0879 - val_loss: 468.5241 - val_mse: 468.5241\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0873 - mse: 0.0873 - val_loss: 1203.5374 - val_mse: 1203.5374\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0839 - mse: 0.0839 - val_loss: 1.9240 - val_mse: 1.9240\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 13971.8008 - val_mse: 13971.8008\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "78\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3358 - mse: 0.3358 - val_loss: 41.1270 - val_mse: 41.1270\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1899 - mse: 0.1899 - val_loss: 782.4678 - val_mse: 782.4678\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1523 - mse: 0.1523 - val_loss: 649.9938 - val_mse: 649.9938\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1359 - mse: 0.1359 - val_loss: 3.2578 - val_mse: 3.2578\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 1309.1442 - val_mse: 1309.1442\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1151 - mse: 0.1151 - val_loss: 153.4228 - val_mse: 153.4228\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1087 - mse: 0.1087 - val_loss: 28.0446 - val_mse: 28.0446\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1062 - mse: 0.1062 - val_loss: 232.1378 - val_mse: 232.1378\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1136 - mse: 0.1136 - val_loss: 32.8428 - val_mse: 32.8428\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 250.2168 - val_mse: 250.2168\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0995 - mse: 0.0995 - val_loss: 32.5216 - val_mse: 32.5216\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 451.3354 - val_mse: 451.3354\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 29.3417 - val_mse: 29.3417\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 8.2422 - val_mse: 8.2422\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "79\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3212 - mse: 0.3212 - val_loss: 0.9274 - val_mse: 0.9274\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1828 - mse: 0.1828 - val_loss: 158.4050 - val_mse: 158.4050\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1447 - mse: 0.1447 - val_loss: 683.4165 - val_mse: 683.4165\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1297 - mse: 0.1297 - val_loss: 6.3225 - val_mse: 6.3225\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 12.3791 - val_mse: 12.3791\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 2979.0312 - val_mse: 2979.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1070 - mse: 0.1070 - val_loss: 4.5625 - val_mse: 4.5625\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 29.0581 - val_mse: 29.0581\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1062 - mse: 0.1062 - val_loss: 100.8737 - val_mse: 100.8737\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 106.8996 - val_mse: 106.8996\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0988 - mse: 0.0988 - val_loss: 4.4174 - val_mse: 4.4174\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "80\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3098 - mse: 0.3098 - val_loss: 3.8697 - val_mse: 3.8697\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1815 - mse: 0.1815 - val_loss: 978.5876 - val_mse: 978.5876\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1480 - mse: 0.1480 - val_loss: 395.5900 - val_mse: 395.5900\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1304 - mse: 0.1304 - val_loss: 17.7308 - val_mse: 17.7308\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1211 - mse: 0.1211 - val_loss: 1951.1216 - val_mse: 1951.1216\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1152 - mse: 0.1152 - val_loss: 2990.1240 - val_mse: 2990.1240\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1104 - mse: 0.1104 - val_loss: 1.0367 - val_mse: 1.0367\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 15.1739 - val_mse: 15.1739\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1115 - mse: 0.1115 - val_loss: 74.9637 - val_mse: 74.9637\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1008 - mse: 0.1008 - val_loss: 36.6681 - val_mse: 36.6681\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 8.7847 - val_mse: 8.7847\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 1760.3976 - val_mse: 1760.3976\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 3.0218 - val_mse: 3.0218\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 2045.9159 - val_mse: 2045.9159\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 10.0995 - val_mse: 10.0995\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0933 - mse: 0.0933 - val_loss: 8.9052 - val_mse: 8.9052\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 403.4093 - val_mse: 403.4093\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "81\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3016 - mse: 0.3016 - val_loss: 28.6199 - val_mse: 28.6199\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1821 - mse: 0.1821 - val_loss: 83.7802 - val_mse: 83.7802\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1425 - mse: 0.1425 - val_loss: 5576.2412 - val_mse: 5576.2412\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1332 - mse: 0.1332 - val_loss: 0.6912 - val_mse: 0.6912\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1256 - mse: 0.1256 - val_loss: 46.3210 - val_mse: 46.3210\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 298.0960 - val_mse: 298.0960\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1054 - mse: 0.1054 - val_loss: 84.2857 - val_mse: 84.2857\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1064 - mse: 0.1064 - val_loss: 4.5923 - val_mse: 4.5923\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 780.7472 - val_mse: 780.7472\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 205.1196 - val_mse: 205.1196\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 56.6455 - val_mse: 56.6455\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 1593.4688 - val_mse: 1593.4688\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0954 - mse: 0.0954 - val_loss: 10.3711 - val_mse: 10.3711\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 1.9461 - val_mse: 1.9461\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "82\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3005 - mse: 0.3005 - val_loss: 4.5703 - val_mse: 4.5703\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1818 - mse: 0.1818 - val_loss: 377.4056 - val_mse: 377.4056\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1476 - mse: 0.1476 - val_loss: 0.5675 - val_mse: 0.5675\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1309 - mse: 0.1309 - val_loss: 3.9739 - val_mse: 3.9739\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1199 - mse: 0.1199 - val_loss: 1990.0579 - val_mse: 1990.0579\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1153 - mse: 0.1153 - val_loss: 3215.8721 - val_mse: 3215.8721\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1080 - mse: 0.1080 - val_loss: 62.0714 - val_mse: 62.0714\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1084 - mse: 0.1084 - val_loss: 6.4041 - val_mse: 6.4041\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1086 - mse: 0.1086 - val_loss: 19.0696 - val_mse: 19.0696\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1053 - mse: 0.1053 - val_loss: 160.9319 - val_mse: 160.9319\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0987 - mse: 0.0987 - val_loss: 660.9724 - val_mse: 660.9724\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 31.2450 - val_mse: 31.2450\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0963 - mse: 0.0963 - val_loss: 230.7526 - val_mse: 230.7526\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "83\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3204 - mse: 0.3204 - val_loss: 225.5289 - val_mse: 225.5289\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1791 - mse: 0.1791 - val_loss: 1.1001 - val_mse: 1.1001\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1476 - mse: 0.1476 - val_loss: 9838.5352 - val_mse: 9838.5352\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 14.6853 - val_mse: 14.6853\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 3559.2205 - val_mse: 3559.2205\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1131 - mse: 0.1131 - val_loss: 61.9238 - val_mse: 61.9238\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1064 - mse: 0.1064 - val_loss: 12881.6299 - val_mse: 12881.6299\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1055 - mse: 0.1055 - val_loss: 8.8737 - val_mse: 8.8737\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 5.7211 - val_mse: 5.7211\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 0.7100 - val_mse: 0.7100\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 1032.7434 - val_mse: 1032.7434\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 49.1008 - val_mse: 49.1008\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0969 - mse: 0.0969 - val_loss: 5.2326 - val_mse: 5.2326\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0925 - mse: 0.0925 - val_loss: 0.9328 - val_mse: 0.9328\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0873 - mse: 0.0873 - val_loss: 16.9226 - val_mse: 16.9226\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 1.9207 - val_mse: 1.9207\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 73.8457 - val_mse: 73.8457\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 53.2615 - val_mse: 53.2615\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0868 - mse: 0.0868 - val_loss: 244.6832 - val_mse: 244.6832\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0854 - mse: 0.0854 - val_loss: 1.3573 - val_mse: 1.3573\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "84\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3077 - mse: 0.3077 - val_loss: 36.2092 - val_mse: 36.2092\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1794 - mse: 0.1794 - val_loss: 2.0111 - val_mse: 2.0111\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1498 - mse: 0.1498 - val_loss: 3815.8652 - val_mse: 3815.8652\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 49.7492 - val_mse: 49.7492\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1271 - mse: 0.1271 - val_loss: 0.9856 - val_mse: 0.9856\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1141 - mse: 0.1141 - val_loss: 1864.1324 - val_mse: 1864.1324\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1080 - mse: 0.1080 - val_loss: 40.5751 - val_mse: 40.5751\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1071 - mse: 0.1071 - val_loss: 23.9805 - val_mse: 23.9805\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1162 - mse: 0.1162 - val_loss: 26.8090 - val_mse: 26.8090\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1025 - mse: 0.1025 - val_loss: 195.6932 - val_mse: 195.6932\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 6.9475 - val_mse: 6.9475\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0949 - mse: 0.0949 - val_loss: 6.2683 - val_mse: 6.2683\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 15.7298 - val_mse: 15.7298\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 30.0586 - val_mse: 30.0586\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0885 - mse: 0.0885 - val_loss: 30.0336 - val_mse: 30.0336\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "85\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.2906 - mse: 0.2906 - val_loss: 699.8232 - val_mse: 699.8232\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1734 - mse: 0.1734 - val_loss: 4.0393 - val_mse: 4.0393\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1422 - mse: 0.1422 - val_loss: 0.6142 - val_mse: 0.6142\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1299 - mse: 0.1299 - val_loss: 32.5005 - val_mse: 32.5005\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 570.4221 - val_mse: 570.4221\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1111 - mse: 0.1111 - val_loss: 899.6212 - val_mse: 899.6212\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1049 - mse: 0.1049 - val_loss: 25.2048 - val_mse: 25.2048\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1055 - mse: 0.1055 - val_loss: 7326.7192 - val_mse: 7326.7192\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1132 - mse: 0.1132 - val_loss: 109.3863 - val_mse: 109.3863\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1017 - mse: 0.1017 - val_loss: 332.1422 - val_mse: 332.1422\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 12.2948 - val_mse: 12.2948\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 19.6221 - val_mse: 19.6221\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0963 - mse: 0.0963 - val_loss: 49.1710 - val_mse: 49.1710\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "86\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3085 - mse: 0.3085 - val_loss: 124.7399 - val_mse: 124.7399\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1852 - mse: 0.1852 - val_loss: 504.2415 - val_mse: 504.2415\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1445 - mse: 0.1445 - val_loss: 1719.9425 - val_mse: 1719.9425\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1322 - mse: 0.1322 - val_loss: 4.3023 - val_mse: 4.3023\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1260 - mse: 0.1260 - val_loss: 235.8967 - val_mse: 235.8967\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1153 - mse: 0.1153 - val_loss: 197.2291 - val_mse: 197.2291\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1079 - mse: 0.1079 - val_loss: 6.8374 - val_mse: 6.8374\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 54.9465 - val_mse: 54.9465\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1095 - mse: 0.1095 - val_loss: 55.9222 - val_mse: 55.9222\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1017 - mse: 0.1017 - val_loss: 410.2842 - val_mse: 410.2842\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0997 - mse: 0.0997 - val_loss: 324.7920 - val_mse: 324.7920\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0933 - mse: 0.0933 - val_loss: 212.2543 - val_mse: 212.2543\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 60.0578 - val_mse: 60.0578\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 15.1560 - val_mse: 15.1560\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "87\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3596 - mse: 0.3596 - val_loss: 11.5756 - val_mse: 11.5756\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1929 - mse: 0.1929 - val_loss: 0.6370 - val_mse: 0.6370\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1547 - mse: 0.1547 - val_loss: 424.6803 - val_mse: 424.6803\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1388 - mse: 0.1388 - val_loss: 65.4273 - val_mse: 65.4273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1269 - mse: 0.1269 - val_loss: 14.7546 - val_mse: 14.7546\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1203 - mse: 0.1203 - val_loss: 3.1344 - val_mse: 3.1344\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1093 - mse: 0.1093 - val_loss: 5.9723 - val_mse: 5.9723\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 47.0888 - val_mse: 47.0888\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1175 - mse: 0.1175 - val_loss: 88.0539 - val_mse: 88.0539\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 1313.9895 - val_mse: 1313.9895\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.8947 - val_mse: 0.8947\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 317.9911 - val_mse: 317.9911\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "88\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3172 - mse: 0.3172 - val_loss: 171.8013 - val_mse: 171.8013\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1766 - mse: 0.1766 - val_loss: 1.9277 - val_mse: 1.9277\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1412 - mse: 0.1412 - val_loss: 684.5154 - val_mse: 684.5154\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1309 - mse: 0.1309 - val_loss: 1.2271 - val_mse: 1.2271\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1224 - mse: 0.1224 - val_loss: 5.2753 - val_mse: 5.2753\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1119 - mse: 0.1119 - val_loss: 427.7168 - val_mse: 427.7168\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1058 - mse: 0.1058 - val_loss: 1.4145 - val_mse: 1.4145\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1080 - mse: 0.1080 - val_loss: 20.9122 - val_mse: 20.9122\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 123.1203 - val_mse: 123.1203\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1010 - mse: 0.1010 - val_loss: 128.7558 - val_mse: 128.7558\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 14.5385 - val_mse: 14.5385\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0955 - mse: 0.0955 - val_loss: 20.0176 - val_mse: 20.0176\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 37.5475 - val_mse: 37.5475\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 8.6297 - val_mse: 8.6297\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "89\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3263 - mse: 0.3263 - val_loss: 94.0859 - val_mse: 94.0859\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1941 - mse: 0.1941 - val_loss: 658.6564 - val_mse: 658.6564\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1484 - mse: 0.1484 - val_loss: 2464.0024 - val_mse: 2464.0024\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 5.7543 - val_mse: 5.7543\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 208.2357 - val_mse: 208.2357\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 2.6254 - val_mse: 2.6254\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 28.2477 - val_mse: 28.2477\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1086 - mse: 0.1086 - val_loss: 52.6382 - val_mse: 52.6382\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1124 - mse: 0.1124 - val_loss: 24.9535 - val_mse: 24.9535\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0972 - mse: 0.0972 - val_loss: 85.7358 - val_mse: 85.7358\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0972 - mse: 0.0972 - val_loss: 5189.3877 - val_mse: 5189.3877\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0966 - mse: 0.0966 - val_loss: 0.9449 - val_mse: 0.9449\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 11.4758 - val_mse: 11.4758\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 0.7481 - val_mse: 0.7481\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 23.5328 - val_mse: 23.5328\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0935 - mse: 0.0935 - val_loss: 165.2285 - val_mse: 165.2285\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0902 - mse: 0.0902 - val_loss: 1184.2557 - val_mse: 1184.2557\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0867 - mse: 0.0867 - val_loss: 459.3393 - val_mse: 459.3393\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 2334.7717 - val_mse: 2334.7717\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0828 - mse: 0.0828 - val_loss: 4.4183 - val_mse: 4.4183\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0847 - mse: 0.0847 - val_loss: 19583.1504 - val_mse: 19583.1504\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 693.8959 - val_mse: 693.8959\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0842 - mse: 0.0842 - val_loss: 18.9696 - val_mse: 18.9696\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0838 - mse: 0.0838 - val_loss: 13.6700 - val_mse: 13.6700\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "90\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3100 - mse: 0.3100 - val_loss: 247.3723 - val_mse: 247.3723\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1803 - mse: 0.1803 - val_loss: 333.8935 - val_mse: 333.8935\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1462 - mse: 0.1462 - val_loss: 4842.2124 - val_mse: 4842.2124\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 71.7787 - val_mse: 71.7787\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1224 - mse: 0.1224 - val_loss: 2267.5420 - val_mse: 2267.5420\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1098 - mse: 0.1098 - val_loss: 544.6390 - val_mse: 544.6390\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 14.6737 - val_mse: 14.6737\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1062 - mse: 0.1062 - val_loss: 158.8191 - val_mse: 158.8191\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 63.4977 - val_mse: 63.4977\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1033 - mse: 0.1033 - val_loss: 13.6730 - val_mse: 13.6730\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0986 - mse: 0.0986 - val_loss: 55.9700 - val_mse: 55.9700\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 93.9180 - val_mse: 93.9180\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 45.1198 - val_mse: 45.1198\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0909 - mse: 0.0909 - val_loss: 1.2171 - val_mse: 1.2171\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 3.4249 - val_mse: 3.4249\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 1.1017 - val_mse: 1.1017\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 692.4073 - val_mse: 692.4073\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 1586.0415 - val_mse: 1586.0415\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0868 - mse: 0.0868 - val_loss: 6.3599 - val_mse: 6.3599\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0841 - mse: 0.0841 - val_loss: 40.9389 - val_mse: 40.9389\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0828 - mse: 0.0828 - val_loss: 16283.8867 - val_mse: 16283.8867\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0795 - mse: 0.0795 - val_loss: 469.1006 - val_mse: 469.1006\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0842 - mse: 0.0842 - val_loss: 546.5150 - val_mse: 546.5150\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 2.5828 - val_mse: 2.5828\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 4.3069 - val_mse: 4.3069\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0839 - mse: 0.0839 - val_loss: 955.7676 - val_mse: 955.7676\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "91\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3148 - mse: 0.3148 - val_loss: 133.8300 - val_mse: 133.8300\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1819 - mse: 0.1819 - val_loss: 62.7907 - val_mse: 62.7907\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1477 - mse: 0.1477 - val_loss: 65.1660 - val_mse: 65.1660\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1341 - mse: 0.1341 - val_loss: 12.6142 - val_mse: 12.6142\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1232 - mse: 0.1232 - val_loss: 132.4409 - val_mse: 132.4409\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 908.3437 - val_mse: 908.3437\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1091 - mse: 0.1091 - val_loss: 56.2886 - val_mse: 56.2886\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 20.7526 - val_mse: 20.7526\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 96.4141 - val_mse: 96.4141\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1030 - mse: 0.1030 - val_loss: 2.7071 - val_mse: 2.7071\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 592.4187 - val_mse: 592.4187\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0943 - mse: 0.0943 - val_loss: 28.5956 - val_mse: 28.5956\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0950 - mse: 0.0950 - val_loss: 111.1760 - val_mse: 111.1760\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 78.7715 - val_mse: 78.7715\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0887 - mse: 0.0887 - val_loss: 56.7726 - val_mse: 56.7726\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 7.3963 - val_mse: 7.3963\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0946 - mse: 0.0946 - val_loss: 1968.1462 - val_mse: 1968.1462\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0854 - mse: 0.0854 - val_loss: 2683.7114 - val_mse: 2683.7114\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 6354.6035 - val_mse: 6354.6035\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 24.4776 - val_mse: 24.4776\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "92\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.2909 - mse: 0.2909 - val_loss: 191.8300 - val_mse: 191.8300\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1726 - mse: 0.1726 - val_loss: 2489.7842 - val_mse: 2489.7842\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 1542.1710 - val_mse: 1542.1710\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1282 - mse: 0.1282 - val_loss: 14.5801 - val_mse: 14.5801\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 1614.9220 - val_mse: 1614.9220\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1103 - mse: 0.1103 - val_loss: 1831.1256 - val_mse: 1831.1256\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 15.2763 - val_mse: 15.2763\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 30.1536 - val_mse: 30.1536\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 26.9895 - val_mse: 26.9895\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1009 - mse: 0.1009 - val_loss: 36.5866 - val_mse: 36.5866\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 247.3813 - val_mse: 247.3813\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 35.1751 - val_mse: 35.1751\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0977 - mse: 0.0977 - val_loss: 47.6769 - val_mse: 47.6769\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 3.1581 - val_mse: 3.1581\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0899 - mse: 0.0899 - val_loss: 118.1267 - val_mse: 118.1267\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 12.5209 - val_mse: 12.5209\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0906 - mse: 0.0906 - val_loss: 422.5667 - val_mse: 422.5667\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 301.5445 - val_mse: 301.5445\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0880 - mse: 0.0880 - val_loss: 0.5087 - val_mse: 0.5087\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0849 - mse: 0.0849 - val_loss: 26.5843 - val_mse: 26.5843\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 7916.8921 - val_mse: 7916.8921\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 729.8849 - val_mse: 729.8849\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0840 - mse: 0.0840 - val_loss: 139.0061 - val_mse: 139.0061\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 92.4512 - val_mse: 92.4512\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 149.1037 - val_mse: 149.1037\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 1.6377 - val_mse: 1.6377\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 44.9200 - val_mse: 44.9200\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0790 - mse: 0.0790 - val_loss: 8.8693 - val_mse: 8.8693\n",
      "Epoch 29/100\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0769 - mse: 0.0769 - val_loss: 317.6449 - val_mse: 317.6449\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "93\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3078 - mse: 0.3078 - val_loss: 2.0494 - val_mse: 2.0494\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1774 - mse: 0.1774 - val_loss: 259.6502 - val_mse: 259.6502\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1430 - mse: 0.1430 - val_loss: 42.0799 - val_mse: 42.0799\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1345 - mse: 0.1345 - val_loss: 0.7737 - val_mse: 0.7737\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 94.0647 - val_mse: 94.0647\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1136 - mse: 0.1136 - val_loss: 5.1154 - val_mse: 5.1154\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 4.4488 - val_mse: 4.4488\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1054 - mse: 0.1054 - val_loss: 54.5369 - val_mse: 54.5369\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1119 - mse: 0.1119 - val_loss: 210.3639 - val_mse: 210.3639\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1040 - mse: 0.1040 - val_loss: 258.3745 - val_mse: 258.3745\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0981 - mse: 0.0981 - val_loss: 1581.2504 - val_mse: 1581.2504\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0946 - mse: 0.0946 - val_loss: 8.7187 - val_mse: 8.7187\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0964 - mse: 0.0964 - val_loss: 5.4514 - val_mse: 5.4514\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 59.9389 - val_mse: 59.9389\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "94\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3267 - mse: 0.3267 - val_loss: 20.4584 - val_mse: 20.4584\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1859 - mse: 0.1859 - val_loss: 19.2556 - val_mse: 19.2556\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1461 - mse: 0.1461 - val_loss: 1286.1904 - val_mse: 1286.1904\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1368 - mse: 0.1368 - val_loss: 7.4109 - val_mse: 7.4109\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1295 - mse: 0.1295 - val_loss: 1386.1183 - val_mse: 1386.1183\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1139 - mse: 0.1139 - val_loss: 333.7885 - val_mse: 333.7885\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1109 - mse: 0.1109 - val_loss: 26.1413 - val_mse: 26.1413\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1063 - mse: 0.1063 - val_loss: 5.3351 - val_mse: 5.3351\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1138 - mse: 0.1138 - val_loss: 69.3296 - val_mse: 69.3296\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 14.6459 - val_mse: 14.6459\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 1.8327 - val_mse: 1.8327\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 765.6318 - val_mse: 765.6318\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0949 - mse: 0.0949 - val_loss: 0.7268 - val_mse: 0.7268\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 42.9063 - val_mse: 42.9063\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 64.6354 - val_mse: 64.6354\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 133.3011 - val_mse: 133.3011\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 15760.2803 - val_mse: 15760.2803\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0859 - mse: 0.0859 - val_loss: 92.0125 - val_mse: 92.0125\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 1055.4036 - val_mse: 1055.4036\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0805 - mse: 0.0805 - val_loss: 1.1479 - val_mse: 1.1479\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0831 - mse: 0.0831 - val_loss: 18260.5645 - val_mse: 18260.5645\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0817 - mse: 0.0817 - val_loss: 1794.9666 - val_mse: 1794.9666\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0838 - mse: 0.0838 - val_loss: 22.3565 - val_mse: 22.3565\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "95\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3007 - mse: 0.3007 - val_loss: 224.4490 - val_mse: 224.4490\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1751 - mse: 0.1751 - val_loss: 9.4250 - val_mse: 9.4250\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1454 - mse: 0.1454 - val_loss: 4408.6426 - val_mse: 4408.6426\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1283 - mse: 0.1283 - val_loss: 1.6245 - val_mse: 1.6245\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 2904.3606 - val_mse: 2904.3606\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1127 - mse: 0.1127 - val_loss: 265.9546 - val_mse: 265.9546\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 461.0588 - val_mse: 461.0588\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1069 - mse: 0.1069 - val_loss: 5.9193 - val_mse: 5.9193\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1129 - mse: 0.1129 - val_loss: 18.2813 - val_mse: 18.2813\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0983 - mse: 0.0983 - val_loss: 316.9445 - val_mse: 316.9445\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 1.2333 - val_mse: 1.2333\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 7.5500 - val_mse: 7.5500\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 72.3131 - val_mse: 72.3131\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 0.6038 - val_mse: 0.6038\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0899 - mse: 0.0899 - val_loss: 0.6854 - val_mse: 0.6854\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 6.3476 - val_mse: 6.3476\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0912 - mse: 0.0912 - val_loss: 138.9668 - val_mse: 138.9668\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 2176.7935 - val_mse: 2176.7935\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0873 - mse: 0.0873 - val_loss: 22.0086 - val_mse: 22.0086\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 239.4102 - val_mse: 239.4102\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0842 - mse: 0.0842 - val_loss: 25377.9355 - val_mse: 25377.9355\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0824 - mse: 0.0824 - val_loss: 3571.7539 - val_mse: 3571.7539\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 93.1253 - val_mse: 93.1253\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 12.3047 - val_mse: 12.3047\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "96\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3504 - mse: 0.3504 - val_loss: 157.1203 - val_mse: 157.1203\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1811 - mse: 0.1811 - val_loss: 258.8430 - val_mse: 258.8430\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1481 - mse: 0.1481 - val_loss: 3577.1860 - val_mse: 3577.1860\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1358 - mse: 0.1358 - val_loss: 17.8328 - val_mse: 17.8328\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1234 - mse: 0.1234 - val_loss: 3459.1018 - val_mse: 3459.1018\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 207.9838 - val_mse: 207.9838\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1096 - mse: 0.1096 - val_loss: 19.1890 - val_mse: 19.1890\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1057 - mse: 0.1057 - val_loss: 1.6956 - val_mse: 1.6956\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1147 - mse: 0.1147 - val_loss: 15.8197 - val_mse: 15.8197\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1009 - mse: 0.1009 - val_loss: 249.7298 - val_mse: 249.7298\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1025 - mse: 0.1025 - val_loss: 1.5003 - val_mse: 1.5003\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 1.8451 - val_mse: 1.8451\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 12.9737 - val_mse: 12.9737\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0935 - mse: 0.0935 - val_loss: 51.9241 - val_mse: 51.9241\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 3.6234 - val_mse: 3.6234\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 12.0131 - val_mse: 12.0131\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 177.1316 - val_mse: 177.1316\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 160.0180 - val_mse: 160.0180\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0881 - mse: 0.0881 - val_loss: 95.2000 - val_mse: 95.2000\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0849 - mse: 0.0849 - val_loss: 2.9225 - val_mse: 2.9225\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0828 - mse: 0.0828 - val_loss: 5225.0918 - val_mse: 5225.0918\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "97\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3312 - mse: 0.3312 - val_loss: 595.5580 - val_mse: 595.5580\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1826 - mse: 0.1826 - val_loss: 214.1432 - val_mse: 214.1432\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1464 - mse: 0.1464 - val_loss: 1552.1066 - val_mse: 1552.1066\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1298 - mse: 0.1298 - val_loss: 15.8420 - val_mse: 15.8420\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 529.0226 - val_mse: 529.0226\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1133 - mse: 0.1133 - val_loss: 55.6048 - val_mse: 55.6048\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 1.1872 - val_mse: 1.1872\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 20.0419 - val_mse: 20.0419\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 49.5236 - val_mse: 49.5236\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 10.3093 - val_mse: 10.3093\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0995 - mse: 0.0995 - val_loss: 10.2482 - val_mse: 10.2482\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 26.9365 - val_mse: 26.9365\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0976 - mse: 0.0976 - val_loss: 28.6656 - val_mse: 28.6656\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0902 - mse: 0.0902 - val_loss: 1.9330 - val_mse: 1.9330\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0899 - mse: 0.0899 - val_loss: 0.7118 - val_mse: 0.7118\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0945 - mse: 0.0945 - val_loss: 116.3533 - val_mse: 116.3533\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 241.7238 - val_mse: 241.7238\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0866 - mse: 0.0866 - val_loss: 1093.5712 - val_mse: 1093.5712\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 737.8273 - val_mse: 737.8273\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0858 - mse: 0.0858 - val_loss: 269.6375 - val_mse: 269.6375\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0845 - mse: 0.0845 - val_loss: 2194.3228 - val_mse: 2194.3228\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0795 - mse: 0.0795 - val_loss: 247.8833 - val_mse: 247.8833\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0819 - mse: 0.0819 - val_loss: 0.7297 - val_mse: 0.7297\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 4.6281 - val_mse: 4.6281\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0820 - mse: 0.0820 - val_loss: 104.1146 - val_mse: 104.1146\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "98\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3127 - mse: 0.3127 - val_loss: 228.4013 - val_mse: 228.4013\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1837 - mse: 0.1837 - val_loss: 1.7959 - val_mse: 1.7959\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1481 - mse: 0.1481 - val_loss: 3455.8899 - val_mse: 3455.8899\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1307 - mse: 0.1307 - val_loss: 168.4936 - val_mse: 168.4936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 3493.4731 - val_mse: 3493.4731\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1117 - mse: 0.1117 - val_loss: 1132.8315 - val_mse: 1132.8315\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1062 - mse: 0.1062 - val_loss: 41.8863 - val_mse: 41.8863\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1083 - mse: 0.1083 - val_loss: 46.8173 - val_mse: 46.8173\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 15.2071 - val_mse: 15.2071\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 39.4541 - val_mse: 39.4541\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 12.7866 - val_mse: 12.7866\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 695.3204 - val_mse: 695.3204\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "99\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3116 - mse: 0.3116 - val_loss: 6.3373 - val_mse: 6.3373\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1774 - mse: 0.1774 - val_loss: 11.8321 - val_mse: 11.8321\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1440 - mse: 0.1440 - val_loss: 1171.6033 - val_mse: 1171.6033\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1311 - mse: 0.1311 - val_loss: 30.4253 - val_mse: 30.4253\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1279 - mse: 0.1279 - val_loss: 167.4425 - val_mse: 167.4425\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1155 - mse: 0.1155 - val_loss: 46.6960 - val_mse: 46.6960\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 18.0363 - val_mse: 18.0363\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 63.8696 - val_mse: 63.8696\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1128 - mse: 0.1128 - val_loss: 7.7940 - val_mse: 7.7940\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.1019 - mse: 0.1019 - val_loss: 77.4497 - val_mse: 77.4497\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0983 - mse: 0.0983 - val_loss: 3.5454 - val_mse: 3.5454\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 33.3308 - val_mse: 33.3308\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 57.4044 - val_mse: 57.4044\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 138.7599 - val_mse: 138.7599\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0890 - mse: 0.0890 - val_loss: 2.2672 - val_mse: 2.2672\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0933 - mse: 0.0933 - val_loss: 0.7752 - val_mse: 0.7752\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 899.5955 - val_mse: 899.5955\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 11.2952 - val_mse: 11.2952\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0868 - mse: 0.0868 - val_loss: 174.6315 - val_mse: 174.6315\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 217.8628 - val_mse: 217.8628\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0827 - mse: 0.0827 - val_loss: 9782.1641 - val_mse: 9782.1641\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0811 - mse: 0.0811 - val_loss: 164.1381 - val_mse: 164.1381\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0838 - mse: 0.0838 - val_loss: 185.3123 - val_mse: 185.3123\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 48.3340 - val_mse: 48.3340\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0801 - mse: 0.0801 - val_loss: 17.6371 - val_mse: 17.6371\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0856 - mse: 0.0856 - val_loss: 26.0380 - val_mse: 26.0380\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "100\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3142 - mse: 0.3142 - val_loss: 511.9650 - val_mse: 511.9650\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1881 - mse: 0.1881 - val_loss: 41.2882 - val_mse: 41.2882\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1511 - mse: 0.1511 - val_loss: 2217.0483 - val_mse: 2217.0483\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1345 - mse: 0.1345 - val_loss: 4.5352 - val_mse: 4.5352\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 4132.1719 - val_mse: 4132.1719\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1138 - mse: 0.1138 - val_loss: 1965.1580 - val_mse: 1965.1580\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 2.1966 - val_mse: 2.1966\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1064 - mse: 0.1064 - val_loss: 25.3908 - val_mse: 25.3908\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1101 - mse: 0.1101 - val_loss: 10.7200 - val_mse: 10.7200\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1006 - mse: 0.1006 - val_loss: 112.9205 - val_mse: 112.9205\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 2.3857 - val_mse: 2.3857\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 7.4640 - val_mse: 7.4640\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 2.5415 - val_mse: 2.5415\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 479.8425 - val_mse: 479.8425\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0884 - mse: 0.0884 - val_loss: 1.5948 - val_mse: 1.5948\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 121.7254 - val_mse: 121.7254\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 6202.6729 - val_mse: 6202.6729\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 2379.0771 - val_mse: 2379.0771\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 74.4353 - val_mse: 74.4353\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 1.5302 - val_mse: 1.5302\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0836 - mse: 0.0836 - val_loss: 11624.3369 - val_mse: 11624.3369\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0817 - mse: 0.0817 - val_loss: 818.5291 - val_mse: 818.5291\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0842 - mse: 0.0842 - val_loss: 6.6601 - val_mse: 6.6601\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0810 - mse: 0.0810 - val_loss: 0.9932 - val_mse: 0.9932\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0793 - mse: 0.0793 - val_loss: 3721.2390 - val_mse: 3721.2390\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 1486.8806 - val_mse: 1486.8806\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 11.1372 - val_mse: 11.1372\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0810 - mse: 0.0810 - val_loss: 9.8303 - val_mse: 9.8303\n",
      "Epoch 29/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 51.8319 - val_mse: 51.8319\n",
      "Epoch 30/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 1.1476 - val_mse: 1.1476\n",
      "Epoch 31/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0785 - mse: 0.0785 - val_loss: 310.9351 - val_mse: 310.9351\n",
      "Epoch 32/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0769 - mse: 0.0769 - val_loss: 8.3834 - val_mse: 8.3834\n",
      "Epoch 33/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0744 - mse: 0.0744 - val_loss: 7.4717 - val_mse: 7.4717\n",
      "Epoch 34/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0745 - mse: 0.0745 - val_loss: 2.4452 - val_mse: 2.4452\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "101\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3097 - mse: 0.3097 - val_loss: 162.2395 - val_mse: 162.2395\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1733 - mse: 0.1733 - val_loss: 161.4703 - val_mse: 161.4703\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1445 - mse: 0.1445 - val_loss: 86.4635 - val_mse: 86.4635\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1288 - mse: 0.1288 - val_loss: 15.1072 - val_mse: 15.1072\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1216 - mse: 0.1216 - val_loss: 3073.3650 - val_mse: 3073.3650\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1130 - mse: 0.1130 - val_loss: 1887.0355 - val_mse: 1887.0355\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1070 - mse: 0.1070 - val_loss: 0.9412 - val_mse: 0.9412\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1088 - mse: 0.1088 - val_loss: 2.1200 - val_mse: 2.1200\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1122 - mse: 0.1122 - val_loss: 25.9382 - val_mse: 25.9382\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 480.2035 - val_mse: 480.2035\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0997 - mse: 0.0997 - val_loss: 6687.8618 - val_mse: 6687.8618\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 1.1910 - val_mse: 1.1910\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 63.1089 - val_mse: 63.1089\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0915 - mse: 0.0915 - val_loss: 107.8620 - val_mse: 107.8620\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0911 - mse: 0.0911 - val_loss: 1.3760 - val_mse: 1.3760\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 0.8742 - val_mse: 0.8742\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 169.2279 - val_mse: 169.2279\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0867 - mse: 0.0867 - val_loss: 26.2353 - val_mse: 26.2353\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 212.9039 - val_mse: 212.9039\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 28.2817 - val_mse: 28.2817\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 4438.4922 - val_mse: 4438.4922\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0793 - mse: 0.0793 - val_loss: 258.7151 - val_mse: 258.7151\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 359.2973 - val_mse: 359.2973\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0821 - mse: 0.0821 - val_loss: 0.4603 - val_mse: 0.4603\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0822 - mse: 0.0822 - val_loss: 17.1578 - val_mse: 17.1578\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0856 - mse: 0.0856 - val_loss: 46.1710 - val_mse: 46.1710\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0829 - mse: 0.0829 - val_loss: 6.7797 - val_mse: 6.7797\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0799 - mse: 0.0799 - val_loss: 87.1620 - val_mse: 87.1620\n",
      "Epoch 29/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 3.9467 - val_mse: 3.9467\n",
      "Epoch 30/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0804 - mse: 0.0804 - val_loss: 3.1577 - val_mse: 3.1577\n",
      "Epoch 31/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0793 - mse: 0.0793 - val_loss: 1438.7130 - val_mse: 1438.7130\n",
      "Epoch 32/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0775 - mse: 0.0775 - val_loss: 36.5923 - val_mse: 36.5923\n",
      "Epoch 33/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 10.1847 - val_mse: 10.1847\n",
      "Epoch 34/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.7454 - val_mse: 0.7454\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "102\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3164 - mse: 0.3164 - val_loss: 49.0525 - val_mse: 49.0525\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1747 - mse: 0.1747 - val_loss: 245.4075 - val_mse: 245.4075\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1478 - mse: 0.1478 - val_loss: 0.4808 - val_mse: 0.4808\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1332 - mse: 0.1332 - val_loss: 5.1203 - val_mse: 5.1203\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1223 - mse: 0.1223 - val_loss: 812.1684 - val_mse: 812.1684\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1127 - mse: 0.1127 - val_loss: 3.5955 - val_mse: 3.5955\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1052 - mse: 0.1052 - val_loss: 2.4334 - val_mse: 2.4334\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1059 - mse: 0.1059 - val_loss: 19.5572 - val_mse: 19.5572\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 9.2078 - val_mse: 9.2078\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0995 - mse: 0.0995 - val_loss: 44.3675 - val_mse: 44.3675\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1009 - mse: 0.1009 - val_loss: 149.9352 - val_mse: 149.9352\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 8.7620 - val_mse: 8.7620\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0964 - mse: 0.0964 - val_loss: 79.3044 - val_mse: 79.3044\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "103\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.3176 - mse: 0.3176 - val_loss: 470.0861 - val_mse: 470.0861\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1800 - mse: 0.1800 - val_loss: 590.6306 - val_mse: 590.6306\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1559 - mse: 0.1559 - val_loss: 1.6880 - val_mse: 1.6880\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1334 - mse: 0.1334 - val_loss: 52.2749 - val_mse: 52.2749\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1256 - mse: 0.1256 - val_loss: 1287.4026 - val_mse: 1287.4026\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1168 - mse: 0.1168 - val_loss: 1490.4164 - val_mse: 1490.4164\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1092 - mse: 0.1092 - val_loss: 168.1194 - val_mse: 168.1194\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1098 - mse: 0.1098 - val_loss: 1193.4232 - val_mse: 1193.4232\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 12.5379 - val_mse: 12.5379\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0996 - mse: 0.0996 - val_loss: 27.1794 - val_mse: 27.1794\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1031 - mse: 0.1031 - val_loss: 49.4613 - val_mse: 49.4613\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 18.6111 - val_mse: 18.6111\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 52.2473 - val_mse: 52.2473\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "104\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3165 - mse: 0.3165 - val_loss: 1855.6891 - val_mse: 1855.6891\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1865 - mse: 0.1865 - val_loss: 1124.2098 - val_mse: 1124.2098\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1486 - mse: 0.1486 - val_loss: 7634.9692 - val_mse: 7634.9692\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1294 - mse: 0.1294 - val_loss: 48.8805 - val_mse: 48.8805\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1271 - mse: 0.1271 - val_loss: 536.8984 - val_mse: 536.8984\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1148 - mse: 0.1148 - val_loss: 301.7076 - val_mse: 301.7076\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 14.1687 - val_mse: 14.1687\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 27.9097 - val_mse: 27.9097\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1111 - mse: 0.1111 - val_loss: 16.6855 - val_mse: 16.6855\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 4.0641 - val_mse: 4.0641\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 156.4952 - val_mse: 156.4952\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 159.0662 - val_mse: 159.0662\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0945 - mse: 0.0945 - val_loss: 2.7779 - val_mse: 2.7779\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 51.6462 - val_mse: 51.6462\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 42.5481 - val_mse: 42.5481\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0918 - mse: 0.0918 - val_loss: 21.5050 - val_mse: 21.5050\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0904 - mse: 0.0904 - val_loss: 3355.3347 - val_mse: 3355.3347\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0867 - mse: 0.0867 - val_loss: 955.2740 - val_mse: 955.2740\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 489.4895 - val_mse: 489.4895\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.5581 - val_mse: 0.5581\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 8133.1074 - val_mse: 8133.1074\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 116.2600 - val_mse: 116.2600\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0841 - mse: 0.0841 - val_loss: 53.7327 - val_mse: 53.7327\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0815 - mse: 0.0815 - val_loss: 30.7007 - val_mse: 30.7007\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 27.2576 - val_mse: 27.2576\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 1.0514 - val_mse: 1.0514\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0805 - mse: 0.0805 - val_loss: 2.2450 - val_mse: 2.2450\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0787 - mse: 0.0787 - val_loss: 492.3168 - val_mse: 492.3168\n",
      "Epoch 29/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0773 - mse: 0.0773 - val_loss: 8.2115 - val_mse: 8.2115\n",
      "Epoch 30/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0797 - mse: 0.0797 - val_loss: 1.7227 - val_mse: 1.7227\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "105\n",
      "Epoch 1/100\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.3131 - mse: 0.3131 - val_loss: 55.8171 - val_mse: 55.8171\n",
      "Epoch 2/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1767 - mse: 0.1767 - val_loss: 711.8625 - val_mse: 711.8625\n",
      "Epoch 3/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1466 - mse: 0.1466 - val_loss: 485.0850 - val_mse: 485.0850\n",
      "Epoch 4/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1270 - mse: 0.1270 - val_loss: 58.6045 - val_mse: 58.6045\n",
      "Epoch 5/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1243 - mse: 0.1243 - val_loss: 221.2058 - val_mse: 221.2058\n",
      "Epoch 6/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 217.2632 - val_mse: 217.2632\n",
      "Epoch 7/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1047 - mse: 0.1047 - val_loss: 11.4404 - val_mse: 11.4404\n",
      "Epoch 8/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 784.1312 - val_mse: 784.1312\n",
      "Epoch 9/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.1128 - mse: 0.1128 - val_loss: 124.2487 - val_mse: 124.2487\n",
      "Epoch 10/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 27.7518 - val_mse: 27.7518\n",
      "Epoch 11/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.7356 - val_mse: 0.7356\n",
      "Epoch 12/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 90.3589 - val_mse: 90.3589\n",
      "Epoch 13/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 12.2353 - val_mse: 12.2353\n",
      "Epoch 14/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 13.1488 - val_mse: 13.1488\n",
      "Epoch 15/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0884 - mse: 0.0884 - val_loss: 0.6840 - val_mse: 0.6840\n",
      "Epoch 16/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0934 - mse: 0.0934 - val_loss: 10.4193 - val_mse: 10.4193\n",
      "Epoch 17/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 650.3442 - val_mse: 650.3442\n",
      "Epoch 18/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.4572 - val_mse: 0.4572\n",
      "Epoch 19/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0865 - mse: 0.0865 - val_loss: 3653.1592 - val_mse: 3653.1592\n",
      "Epoch 20/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 26.5736 - val_mse: 26.5736\n",
      "Epoch 21/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0820 - mse: 0.0820 - val_loss: 15218.6787 - val_mse: 15218.6787\n",
      "Epoch 22/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 1957.2294 - val_mse: 1957.2294\n",
      "Epoch 23/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0839 - mse: 0.0839 - val_loss: 3.7046 - val_mse: 3.7046\n",
      "Epoch 24/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 1.0292 - val_mse: 1.0292\n",
      "Epoch 25/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0816 - mse: 0.0816 - val_loss: 40.0133 - val_mse: 40.0133\n",
      "Epoch 26/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0849 - mse: 0.0849 - val_loss: 116.8988 - val_mse: 116.8988\n",
      "Epoch 27/100\n",
      "1106/1106 [==============================] - 6s 6ms/step - loss: 0.0794 - mse: 0.0794 - val_loss: 1.3589 - val_mse: 1.3589\n",
      "Epoch 28/100\n",
      "1106/1106 [==============================] - 6s 5ms/step - loss: 0.0784 - mse: 0.0784 - val_loss: 1.5069 - val_mse: 1.5069\n",
      "674/674 [==============================] - 1s 2ms/step\n",
      "Best number of components: 41\n",
      "RMSE: 0.020795042942920557\n"
     ]
    }
   ],
   "source": [
    "best_rmse = np.inf  # Start with infinity so that any score will be better\n",
    "best_n = 0\n",
    "\n",
    "for nn in range(1, X_train.shape[1]+1):  # Start from 1 as PCA with 0 components doesn't make sense\n",
    "    # Create a PCA object, specifying how many components you wish to keep\n",
    "    pca = PCA(n_components=nn)\n",
    "    print(nn)\n",
    "    # Fit the PCA model to your data and then apply the dimensionality reduction on train and test data\n",
    "    pca.fit(X_train)\n",
    "    X_pca_train = pca.transform(X_train_scaled)\n",
    "    X_pca_test = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Define the model structure\n",
    "    model = Sequential()\n",
    "    model.add(Dense(96, input_dim=nn))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(384))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    # Define learning rate decay\n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                                decay_steps=10000,\n",
    "                                decay_rate=0.9)\n",
    "\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "    history = model.fit(X_pca_train, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_scaled = model.predict(X_pca_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "\n",
    "    # If this RMSE is the best we've seen, store this n_components and score\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_n = nn\n",
    "\n",
    "print(f\"Best number of components: {best_n}\")\n",
    "print(f\"RMSE: {best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52b6bd",
   "metadata": {},
   "source": [
    "# Each RunId Bucket 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de9f2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s.iloc[::10, :]['Z02013']\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 10).mean()\n",
    "        resample_list.append(grouped_df)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 10).max()\n",
    "        resample_list.append(grouped_df)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        grouped_df = s.groupby(s.index // 10).min()\n",
    "        resample_list.append(grouped_df)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53632b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0a5752a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9fe50aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a78e1b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8dd8953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b78ae96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4809337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2f0b13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.00430150633738439\n",
      "MSE:  0.00011571921138425477\n",
      "RMSE:  0.010757286432193518\n",
      "R2:  0.9242082226710217\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e86879a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f743f6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.004314075296991037\n",
      "MSE:  0.00011761779096036252\n",
      "RMSE:  0.010845173625182888\n",
      "R2:  0.9229647236983586\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "657cf5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_848 (Dense)           (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu_636 (LeakyReLU)  (None, 96)               0         \n",
      "                                                                 \n",
      " batch_normalization_636 (Ba  (None, 96)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_424 (Dropout)       (None, 96)                0         \n",
      "                                                                 \n",
      " dense_849 (Dense)           (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_637 (LeakyReLU)  (None, 384)              0         \n",
      "                                                                 \n",
      " batch_normalization_637 (Ba  (None, 384)              1536      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_425 (Dropout)       (None, 384)               0         \n",
      "                                                                 \n",
      " dense_850 (Dense)           (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_638 (LeakyReLU)  (None, 32)               0         \n",
      "                                                                 \n",
      " batch_normalization_638 (Ba  (None, 32)               128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_851 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abce1bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 10ms/step - loss: 0.9090 - mse: 0.9090 - val_loss: 0.2630 - val_mse: 0.2630\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6424 - mse: 0.6424 - val_loss: 0.3278 - val_mse: 0.3278\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5272 - mse: 0.5272 - val_loss: 0.4134 - val_mse: 0.4134\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4827 - mse: 0.4827 - val_loss: 0.3396 - val_mse: 0.3396\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4404 - mse: 0.4404 - val_loss: 0.1333 - val_mse: 0.1333\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4127 - mse: 0.4127 - val_loss: 0.1835 - val_mse: 0.1835\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4040 - mse: 0.4040 - val_loss: 0.2134 - val_mse: 0.2134\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3162 - mse: 0.3162 - val_loss: 0.1966 - val_mse: 0.1966\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3060 - mse: 0.3060 - val_loss: 0.1464 - val_mse: 0.1464\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2871 - mse: 0.2871 - val_loss: 0.1629 - val_mse: 0.1629\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2692 - mse: 0.2692 - val_loss: 0.1440 - val_mse: 0.1440\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2478 - mse: 0.2478 - val_loss: 0.1313 - val_mse: 0.1313\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.1523 - val_mse: 0.1523\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2397 - mse: 0.2397 - val_loss: 0.1234 - val_mse: 0.1234\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2609 - mse: 0.2609 - val_loss: 0.3006 - val_mse: 0.3006\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2578 - mse: 0.2578 - val_loss: 0.1759 - val_mse: 0.1759\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2422 - mse: 0.2422 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2798 - val_mse: 0.2798\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1962 - mse: 0.1962 - val_loss: 0.1435 - val_mse: 0.1435\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.1175 - val_mse: 0.1175\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2135 - mse: 0.2135 - val_loss: 0.1094 - val_mse: 0.1094\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1931 - mse: 0.1931 - val_loss: 0.1286 - val_mse: 0.1286\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2416 - mse: 0.2416 - val_loss: 0.1481 - val_mse: 0.1481\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1901 - mse: 0.1901 - val_loss: 0.1531 - val_mse: 0.1531\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2123 - mse: 0.2123 - val_loss: 0.0945 - val_mse: 0.0945\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1749 - mse: 0.1749 - val_loss: 0.1791 - val_mse: 0.1791\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2411 - mse: 0.2411 - val_loss: 0.1820 - val_mse: 0.1820\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1884 - mse: 0.1884 - val_loss: 0.1715 - val_mse: 0.1715\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2015 - mse: 0.2015 - val_loss: 0.3030 - val_mse: 0.3030\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2058 - mse: 0.2058 - val_loss: 0.8488 - val_mse: 0.8488\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1770 - mse: 0.1770 - val_loss: 0.1002 - val_mse: 0.1002\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1679 - mse: 0.1679 - val_loss: 0.2887 - val_mse: 0.2887\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1837 - mse: 0.1837 - val_loss: 0.2225 - val_mse: 0.2225\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1596 - mse: 0.1596 - val_loss: 0.0945 - val_mse: 0.0945\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1457 - mse: 0.1457 - val_loss: 0.0955 - val_mse: 0.0955\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "952ae5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 2ms/step\n",
      "Root Mean Squared Error: 0.011470020263703107\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d3345f",
   "metadata": {},
   "source": [
    "#  Each RunId Window 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ffbde70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(10 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(10).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(10).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(10).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75a1b0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "009c219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3238b19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2015f71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e7e14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a4eac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3fb15558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "955ac2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0021264588658232208\n",
      "MSE:  1.9928944976649204e-05\n",
      "RMSE:  0.004464184693384583\n",
      "R2:  0.9838583387108969\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f95c8638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af9bf27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.002125586792359217\n",
      "MSE:  1.9848293530643294e-05\n",
      "RMSE:  0.004455142369290043\n",
      "R2:  0.9839236632087782\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7beadcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_852 (Dense)           (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu_639 (LeakyReLU)  (None, 96)               0         \n",
      "                                                                 \n",
      " batch_normalization_639 (Ba  (None, 96)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_426 (Dropout)       (None, 96)                0         \n",
      "                                                                 \n",
      " dense_853 (Dense)           (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_640 (LeakyReLU)  (None, 384)              0         \n",
      "                                                                 \n",
      " batch_normalization_640 (Ba  (None, 384)              1536      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_427 (Dropout)       (None, 384)               0         \n",
      "                                                                 \n",
      " dense_854 (Dense)           (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_641 (LeakyReLU)  (None, 32)               0         \n",
      "                                                                 \n",
      " batch_normalization_641 (Ba  (None, 32)               128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_855 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65af4e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1101/1101 [==============================] - 10s 8ms/step - loss: 0.2920 - mse: 0.2920 - val_loss: 0.2026 - val_mse: 0.2026\n",
      "Epoch 2/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.1695 - mse: 0.1695 - val_loss: 0.1248 - val_mse: 0.1248\n",
      "Epoch 3/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.1495 - mse: 0.1495 - val_loss: 0.1403 - val_mse: 0.1403\n",
      "Epoch 4/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.1288 - mse: 0.1288 - val_loss: 0.1157 - val_mse: 0.1157\n",
      "Epoch 5/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.1198 - mse: 0.1198 - val_loss: 0.1247 - val_mse: 0.1247\n",
      "Epoch 6/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.1164 - mse: 0.1164 - val_loss: 0.1011 - val_mse: 0.1011\n",
      "Epoch 7/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.1091 - mse: 0.1091 - val_loss: 0.0943 - val_mse: 0.0943\n",
      "Epoch 8/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.1081 - mse: 0.1081 - val_loss: 0.1026 - val_mse: 0.1026\n",
      "Epoch 9/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.1049 - mse: 0.1049 - val_loss: 0.1139 - val_mse: 0.1139\n",
      "Epoch 10/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0989 - mse: 0.0989 - val_loss: 0.0981 - val_mse: 0.0981\n",
      "Epoch 11/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.1027 - mse: 0.1027 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 12/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.1012 - mse: 0.1012 - val_loss: 0.1238 - val_mse: 0.1238\n",
      "Epoch 13/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 0.0894 - val_mse: 0.0894\n",
      "Epoch 14/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.0898 - mse: 0.0898 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 15/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 0.0950 - val_mse: 0.0950\n",
      "Epoch 16/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 0.0962 - val_mse: 0.0962\n",
      "Epoch 17/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 0.0877 - val_mse: 0.0877\n",
      "Epoch 18/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0814 - val_mse: 0.0814\n",
      "Epoch 19/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0872 - val_mse: 0.0872\n",
      "Epoch 20/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0887 - mse: 0.0887 - val_loss: 0.0837 - val_mse: 0.0837\n",
      "Epoch 21/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 0.0897 - val_mse: 0.0897\n",
      "Epoch 22/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0821 - mse: 0.0821 - val_loss: 0.0865 - val_mse: 0.0865\n",
      "Epoch 23/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0843 - val_mse: 0.0843\n",
      "Epoch 24/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.0816 - mse: 0.0816 - val_loss: 0.0883 - val_mse: 0.0883\n",
      "Epoch 25/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 26/100\n",
      "1101/1101 [==============================] - 9s 9ms/step - loss: 0.0823 - mse: 0.0823 - val_loss: 0.0966 - val_mse: 0.0966\n",
      "Epoch 27/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0790 - mse: 0.0790 - val_loss: 0.0865 - val_mse: 0.0865\n",
      "Epoch 28/100\n",
      "1101/1101 [==============================] - 10s 9ms/step - loss: 0.0819 - mse: 0.0819 - val_loss: 0.0889 - val_mse: 0.0889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56257317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/670 [==============================] - 2s 2ms/step\n",
      "Root Mean Squared Error: 0.007152453676415017\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a038d",
   "metadata": {},
   "source": [
    "#  Each RunId Window 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfc1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(20 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(20).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(20).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(20).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effeeeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17f31141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633e26fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e672182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c03cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a796e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda0e068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8675592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0026769656209846746\n",
      "MSE:  2.4184560208650113e-05\n",
      "RMSE:  0.004917780008159181\n",
      "R2:  0.9804065499074148\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ee7af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a27f9258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.002692817494731529\n",
      "MSE:  2.449771373322876e-05\n",
      "RMSE:  0.004949516515098092\n",
      "R2:  0.9801528443240918\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4097722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 96)               384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 384)              1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30324a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1092/1092 [==============================] - 12s 8ms/step - loss: 0.3218 - mse: 0.3218 - val_loss: 0.1191 - val_mse: 0.1191\n",
      "Epoch 2/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.1832 - mse: 0.1832 - val_loss: 0.1418 - val_mse: 0.1418\n",
      "Epoch 3/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.1535 - mse: 0.1535 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 4/100\n",
      "1092/1092 [==============================] - 10s 9ms/step - loss: 0.1462 - mse: 0.1462 - val_loss: 0.0714 - val_mse: 0.0714\n",
      "Epoch 5/100\n",
      "1092/1092 [==============================] - 12s 11ms/step - loss: 0.1324 - mse: 0.1324 - val_loss: 0.0658 - val_mse: 0.0658\n",
      "Epoch 6/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.1259 - mse: 0.1259 - val_loss: 0.0741 - val_mse: 0.0741\n",
      "Epoch 7/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.1239 - mse: 0.1239 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Epoch 8/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.1163 - mse: 0.1163 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 9/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.1150 - mse: 0.1150 - val_loss: 0.0836 - val_mse: 0.0836\n",
      "Epoch 10/100\n",
      "1092/1092 [==============================] - 8s 8ms/step - loss: 0.1090 - mse: 0.1090 - val_loss: 0.0533 - val_mse: 0.0533\n",
      "Epoch 11/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.1057 - mse: 0.1057 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 12/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.1026 - mse: 0.1026 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 13/100\n",
      "1092/1092 [==============================] - 10s 10ms/step - loss: 0.1025 - mse: 0.1025 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 14/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.1006 - mse: 0.1006 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 15/100\n",
      "1092/1092 [==============================] - 9s 9ms/step - loss: 0.1002 - mse: 0.1002 - val_loss: 0.0574 - val_mse: 0.0574\n",
      "Epoch 16/100\n",
      "1092/1092 [==============================] - 8s 8ms/step - loss: 0.0969 - mse: 0.0969 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 17/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 18/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0986 - mse: 0.0986 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 19/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 20/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 21/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 22/100\n",
      "1092/1092 [==============================] - 12s 11ms/step - loss: 0.0918 - mse: 0.0918 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 23/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0924 - mse: 0.0924 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 24/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 25/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 26/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 27/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 28/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 29/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0860 - mse: 0.0860 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 30/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0868 - mse: 0.0868 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 31/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 32/100\n",
      "1092/1092 [==============================] - 10s 9ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 33/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 34/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0847 - mse: 0.0847 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 35/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 36/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 37/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0820 - mse: 0.0820 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 38/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.0802 - mse: 0.0802 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 39/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 40/100\n",
      "1092/1092 [==============================] - 8s 7ms/step - loss: 0.0795 - mse: 0.0795 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 41/100\n",
      "1092/1092 [==============================] - 8s 8ms/step - loss: 0.0809 - mse: 0.0809 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 42/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 43/100\n",
      "1092/1092 [==============================] - 9s 9ms/step - loss: 0.0802 - mse: 0.0802 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 44/100\n",
      "1092/1092 [==============================] - 8s 8ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 45/100\n",
      "1092/1092 [==============================] - 10s 9ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 46/100\n",
      "1092/1092 [==============================] - 13s 12ms/step - loss: 0.0783 - mse: 0.0783 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 47/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0771 - mse: 0.0771 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 48/100\n",
      "1092/1092 [==============================] - 12s 11ms/step - loss: 0.0776 - mse: 0.0776 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 49/100\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 50/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 51/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.0773 - mse: 0.0773 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 52/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0769 - mse: 0.0769 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 53/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 54/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0799 - mse: 0.0799 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 55/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 56/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.0754 - mse: 0.0754 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 57/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 58/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.0747 - mse: 0.0747 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 59/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.0751 - mse: 0.0751 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 60/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 61/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0727 - mse: 0.0727 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 62/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 63/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0738 - mse: 0.0738 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 64/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0765 - mse: 0.0765 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 65/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 66/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 67/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.0741 - mse: 0.0741 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 68/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.0750 - mse: 0.0750 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 69/100\n",
      "1092/1092 [==============================] - 7s 6ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 70/100\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 0.0746 - mse: 0.0746 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 71/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.0722 - mse: 0.0722 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 72/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.0783 - mse: 0.0783 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 73/100\n",
      "1092/1092 [==============================] - 6s 6ms/step - loss: 0.0750 - mse: 0.0750 - val_loss: 0.0270 - val_mse: 0.0270\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f5f9ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 2s 2ms/step\n",
      "Root Mean Squared Error: 0.005906932389023096\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bc8b9",
   "metadata": {},
   "source": [
    "#  Each RunId Window 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2843f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(15 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(15).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(15).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(15).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3faf0777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98b761e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68d480c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "915d5411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc969837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe1b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db3c72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d02c00f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0024175786539649092\n",
      "MSE:  2.0534367532862214e-05\n",
      "RMSE:  0.004531486238847274\n",
      "R2:  0.9833227589332517\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a9cdbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dff17ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0024172788228556045\n",
      "MSE:  2.0373232582359018e-05\n",
      "RMSE:  0.0045136717406518406\n",
      "R2:  0.9834536266801895\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25468028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 96)               384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 384)              1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e60881a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1096/1096 [==============================] - 11s 7ms/step - loss: 0.2965 - mse: 0.2965 - val_loss: 0.1150 - val_mse: 0.1150\n",
      "Epoch 2/100\n",
      "1096/1096 [==============================] - 9s 8ms/step - loss: 0.1748 - mse: 0.1748 - val_loss: 0.0920 - val_mse: 0.0920\n",
      "Epoch 3/100\n",
      "1096/1096 [==============================] - 8s 7ms/step - loss: 0.1510 - mse: 0.1510 - val_loss: 0.0870 - val_mse: 0.0870\n",
      "Epoch 4/100\n",
      "1096/1096 [==============================] - 7s 7ms/step - loss: 0.1384 - mse: 0.1384 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 5/100\n",
      "1096/1096 [==============================] - 7s 7ms/step - loss: 0.1303 - mse: 0.1303 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 6/100\n",
      "1096/1096 [==============================] - 8s 8ms/step - loss: 0.1242 - mse: 0.1242 - val_loss: 0.0674 - val_mse: 0.0674\n",
      "Epoch 7/100\n",
      "1096/1096 [==============================] - 7s 7ms/step - loss: 0.1210 - mse: 0.1210 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 8/100\n",
      "1096/1096 [==============================] - 12s 11ms/step - loss: 0.1151 - mse: 0.1151 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 9/100\n",
      "1096/1096 [==============================] - 11s 10ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 10/100\n",
      "1096/1096 [==============================] - 8s 8ms/step - loss: 0.1076 - mse: 0.1076 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 11/100\n",
      "1096/1096 [==============================] - 10s 9ms/step - loss: 0.1035 - mse: 0.1035 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 12/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.1020 - mse: 0.1020 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 13/100\n",
      "1096/1096 [==============================] - 7s 7ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 14/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.0540 - val_mse: 0.0540\n",
      "Epoch 15/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 16/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 17/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 18/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 19/100\n",
      "1096/1096 [==============================] - 6s 6ms/step - loss: 0.0951 - mse: 0.0951 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 20/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 21/100\n",
      "1096/1096 [==============================] - 7s 7ms/step - loss: 0.0879 - mse: 0.0879 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 22/100\n",
      "1096/1096 [==============================] - 8s 8ms/step - loss: 0.0914 - mse: 0.0914 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 23/100\n",
      "1096/1096 [==============================] - 7s 7ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 24/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0895 - mse: 0.0895 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 25/100\n",
      "1096/1096 [==============================] - 6s 6ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 26/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 27/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 28/100\n",
      "1096/1096 [==============================] - 6s 6ms/step - loss: 0.0862 - mse: 0.0862 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 29/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0849 - mse: 0.0849 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 30/100\n",
      "1096/1096 [==============================] - 6s 6ms/step - loss: 0.0863 - mse: 0.0863 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 31/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0810 - mse: 0.0810 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 32/100\n",
      "1096/1096 [==============================] - 7s 6ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 33/100\n",
      "1096/1096 [==============================] - 6s 6ms/step - loss: 0.0815 - mse: 0.0815 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 34/100\n",
      "1096/1096 [==============================] - 6s 6ms/step - loss: 0.0810 - mse: 0.0810 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 35/100\n",
      "1096/1096 [==============================] - 9s 9ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 36/100\n",
      "1096/1096 [==============================] - 5s 5ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 37/100\n",
      "1096/1096 [==============================] - 5s 4ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 38/100\n",
      "1096/1096 [==============================] - 5s 5ms/step - loss: 0.0777 - mse: 0.0777 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 39/100\n",
      "1096/1096 [==============================] - 5s 5ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 40/100\n",
      "1096/1096 [==============================] - 5s 5ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 41/100\n",
      "1096/1096 [==============================] - 5s 4ms/step - loss: 0.0808 - mse: 0.0808 - val_loss: 0.0339 - val_mse: 0.0339\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e821a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 1s 2ms/step\n",
      "Root Mean Squared Error: 0.006280597459042615\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54e5e0",
   "metadata": {},
   "source": [
    "#   Each RunId Window 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c84f1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(12 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(12).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(12).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(12).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3a16a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "608de5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b43f01d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcf7d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97ab9776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6c98d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1244b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da942b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0022303102333894893\n",
      "MSE:  1.8367413008499974e-05\n",
      "RMSE:  0.004285721993841874\n",
      "R2:  0.9850637629364802\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "820487bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbcd75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0022357397490679913\n",
      "MSE:  1.852489211018848e-05\n",
      "RMSE:  0.004304055309843088\n",
      "R2:  0.9849357021587168\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f20bc21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 96)               384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 384)              1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de53cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1099/1099 [==============================] - 7s 5ms/step - loss: 0.3002 - mse: 0.3002 - val_loss: 0.1330 - val_mse: 0.1330\n",
      "Epoch 2/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.1675 - mse: 0.1675 - val_loss: 0.1207 - val_mse: 0.1207\n",
      "Epoch 3/100\n",
      "1099/1099 [==============================] - 5s 4ms/step - loss: 0.1425 - mse: 0.1425 - val_loss: 0.0928 - val_mse: 0.0928\n",
      "Epoch 4/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 0.0880 - val_mse: 0.0880\n",
      "Epoch 5/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 0.0864 - val_mse: 0.0864\n",
      "Epoch 6/100\n",
      "1099/1099 [==============================] - 5s 4ms/step - loss: 0.1213 - mse: 0.1213 - val_loss: 0.0733 - val_mse: 0.0733\n",
      "Epoch 7/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.1103 - mse: 0.1103 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 8/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 0.1475 - val_mse: 0.1475\n",
      "Epoch 9/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.1047 - mse: 0.1047 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 10/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.1047 - mse: 0.1047 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 11/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0999 - mse: 0.0999 - val_loss: 0.0681 - val_mse: 0.0681\n",
      "Epoch 12/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 0.0585 - val_mse: 0.0585\n",
      "Epoch 13/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0965 - mse: 0.0965 - val_loss: 0.0796 - val_mse: 0.0796\n",
      "Epoch 14/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 0.0670 - val_mse: 0.0670\n",
      "Epoch 15/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0895 - mse: 0.0895 - val_loss: 0.0608 - val_mse: 0.0608\n",
      "Epoch 16/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0654 - val_mse: 0.0654\n",
      "Epoch 17/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0906 - mse: 0.0906 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 18/100\n",
      "1099/1099 [==============================] - 5s 4ms/step - loss: 0.0879 - mse: 0.0879 - val_loss: 0.0899 - val_mse: 0.0899\n",
      "Epoch 19/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 20/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 21/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0875 - mse: 0.0875 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 22/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0863 - mse: 0.0863 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 23/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0854 - mse: 0.0854 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 24/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 25/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 26/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0854 - mse: 0.0854 - val_loss: 0.0632 - val_mse: 0.0632\n",
      "Epoch 27/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0805 - mse: 0.0805 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 28/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0811 - mse: 0.0811 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 29/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0809 - mse: 0.0809 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Epoch 30/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 31/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0768 - mse: 0.0768 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 32/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 0.0504 - val_mse: 0.0504\n",
      "Epoch 33/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0803 - mse: 0.0803 - val_loss: 0.0525 - val_mse: 0.0525\n",
      "Epoch 34/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0788 - mse: 0.0788 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 35/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 0.0475 - val_mse: 0.0475\n",
      "Epoch 36/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 37/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.0827 - mse: 0.0827 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 38/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 39/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 40/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0777 - mse: 0.0777 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 41/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0799 - mse: 0.0799 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 42/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.0779 - mse: 0.0779 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 43/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0760 - mse: 0.0760 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 44/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 45/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0552 - val_mse: 0.0552\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcc5a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - 2s 2ms/step\n",
      "Root Mean Squared Error: 0.006602803217811296\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b12c0",
   "metadata": {},
   "source": [
    "#   Each RunId Window 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70a360d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(8 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(8).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(8).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(8).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73dc1beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df559e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d386315a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c22dc9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "884e7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4a57a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "21917957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "82577ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0020273575050704716\n",
      "MSE:  2.378390635590004e-05\n",
      "RMSE:  0.004876874650419061\n",
      "R2:  0.9810194602318809\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3cb1a605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0c0249a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0020238769330192807\n",
      "MSE:  2.4132370753167854e-05\n",
      "RMSE:  0.004912470941712313\n",
      "R2:  0.980741371248047\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4596c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 96)               384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 384)              1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a68b1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1103/1103 [==============================] - 9s 7ms/step - loss: 0.3032 - mse: 0.3032 - val_loss: 0.2202 - val_mse: 0.2202\n",
      "Epoch 2/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.1719 - mse: 0.1719 - val_loss: 0.1725 - val_mse: 0.1725\n",
      "Epoch 3/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.1419 - mse: 0.1419 - val_loss: 0.3552 - val_mse: 0.3552\n",
      "Epoch 4/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.1299 - mse: 0.1299 - val_loss: 0.1315 - val_mse: 0.1315\n",
      "Epoch 5/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 0.1521 - val_mse: 0.1521\n",
      "Epoch 6/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.1165 - mse: 0.1165 - val_loss: 0.1352 - val_mse: 0.1352\n",
      "Epoch 7/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 0.1317 - val_mse: 0.1317\n",
      "Epoch 8/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.1106 - mse: 0.1106 - val_loss: 0.1299 - val_mse: 0.1299\n",
      "Epoch 9/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.1075 - mse: 0.1075 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 10/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.1024 - mse: 0.1024 - val_loss: 0.1320 - val_mse: 0.1320\n",
      "Epoch 11/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0977 - mse: 0.0977 - val_loss: 0.1445 - val_mse: 0.1445\n",
      "Epoch 12/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 0.1209 - val_mse: 0.1209\n",
      "Epoch 13/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 14/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 0.1369 - val_mse: 0.1369\n",
      "Epoch 15/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 0.1211 - val_mse: 0.1211\n",
      "Epoch 16/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.1198 - val_mse: 0.1198\n",
      "Epoch 17/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.1495 - val_mse: 0.1495\n",
      "Epoch 18/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0898 - mse: 0.0898 - val_loss: 0.1325 - val_mse: 0.1325\n",
      "Epoch 19/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 0.1299 - val_mse: 0.1299\n",
      "Epoch 20/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.1466 - val_mse: 0.1466\n",
      "Epoch 21/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.0862 - mse: 0.0862 - val_loss: 0.1376 - val_mse: 0.1376\n",
      "Epoch 22/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.0865 - mse: 0.0865 - val_loss: 0.1219 - val_mse: 0.1219\n",
      "Epoch 23/100\n",
      "1103/1103 [==============================] - 8s 7ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 0.1329 - val_mse: 0.1329\n",
      "Epoch 24/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.0860 - mse: 0.0860 - val_loss: 0.1227 - val_mse: 0.1227\n",
      "Epoch 25/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.0828 - mse: 0.0828 - val_loss: 0.1345 - val_mse: 0.1345\n",
      "Epoch 26/100\n",
      "1103/1103 [==============================] - 7s 7ms/step - loss: 0.0822 - mse: 0.0822 - val_loss: 0.1327 - val_mse: 0.1327\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "646ea95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671/671 [==============================] - 1s 2ms/step\n",
      "Root Mean Squared Error: 0.00895364154827438\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9068b89",
   "metadata": {},
   "source": [
    "#   Each RunId Window 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a9f1be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(11 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(11).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(11).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(11).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a9ea590b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "494cca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d7e0c740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "42fe4974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f188bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "47ef2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c2bee8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3738db5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0021787016826751173\n",
      "MSE:  1.8589989301996275e-05\n",
      "RMSE:  0.004311610986858192\n",
      "R2:  0.984898292345378\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "db5b8384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6e8c82e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.002179602318631892\n",
      "MSE:  1.8557957037632508e-05\n",
      "RMSE:  0.004307894733815174\n",
      "R2:  0.984924313979069\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "791a896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 96)               384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 384)              1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b194503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1100/1100 [==============================] - 11s 8ms/step - loss: 0.2566 - mse: 0.2566 - val_loss: 0.1531 - val_mse: 0.1531\n",
      "Epoch 2/100\n",
      "1100/1100 [==============================] - 9s 8ms/step - loss: 0.1576 - mse: 0.1576 - val_loss: 0.1104 - val_mse: 0.1104\n",
      "Epoch 3/100\n",
      "1100/1100 [==============================] - 9s 8ms/step - loss: 0.1404 - mse: 0.1404 - val_loss: 0.1057 - val_mse: 0.1057\n",
      "Epoch 4/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.1244 - mse: 0.1244 - val_loss: 0.0929 - val_mse: 0.0929\n",
      "Epoch 5/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.1184 - mse: 0.1184 - val_loss: 0.0888 - val_mse: 0.0888\n",
      "Epoch 6/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.1128 - mse: 0.1128 - val_loss: 0.1059 - val_mse: 0.1059\n",
      "Epoch 7/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.1101 - mse: 0.1101 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 8/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 0.0774 - val_mse: 0.0774\n",
      "Epoch 9/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.1027 - mse: 0.1027 - val_loss: 0.0900 - val_mse: 0.0900\n",
      "Epoch 10/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 0.0715 - val_mse: 0.0715\n",
      "Epoch 11/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 0.0668 - val_mse: 0.0668\n",
      "Epoch 12/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 0.0735 - val_mse: 0.0735\n",
      "Epoch 13/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.0716 - val_mse: 0.0716\n",
      "Epoch 14/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Epoch 15/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.0870 - val_mse: 0.0870\n",
      "Epoch 16/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.0890 - mse: 0.0890 - val_loss: 0.0789 - val_mse: 0.0789\n",
      "Epoch 17/100\n",
      "1100/1100 [==============================] - 8s 7ms/step - loss: 0.0910 - mse: 0.0910 - val_loss: 0.0785 - val_mse: 0.0785\n",
      "Epoch 18/100\n",
      "1100/1100 [==============================] - 8s 8ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 19/100\n",
      "1100/1100 [==============================] - 7s 7ms/step - loss: 0.0874 - mse: 0.0874 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 20/100\n",
      "1100/1100 [==============================] - 7s 7ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 21/100\n",
      "1100/1100 [==============================] - 7s 7ms/step - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0684 - val_mse: 0.0684\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3a8d9262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/670 [==============================] - 1s 2ms/step\n",
      "Root Mean Squared Error: 0.006909572259647484\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece9ed8",
   "metadata": {},
   "source": [
    "#   Each RunId Window 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7a4bc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(13 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(13).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(13).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(13).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dae69680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1fa0a793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "576f16d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "09eb485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9f937dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bacd2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71be3599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f0b7f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.002295907552592605\n",
      "MSE:  1.8779721946371162e-05\n",
      "RMSE:  0.004333557654672563\n",
      "R2:  0.9847319291250409\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8201143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8ae3c8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0022961080459611353\n",
      "MSE:  1.875616395126814e-05\n",
      "RMSE:  0.004330838712220549\n",
      "R2:  0.9847510819719218\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f532261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 96)                10176     \n",
      "                                                                 \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 96)               384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 384)              1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,825\n",
      "Trainable params: 60,801\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6bf7d265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1098/1098 [==============================] - 14s 8ms/step - loss: 0.2620 - mse: 0.2620 - val_loss: 0.1567 - val_mse: 0.1567\n",
      "Epoch 2/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1561 - mse: 0.1561 - val_loss: 0.0969 - val_mse: 0.0969\n",
      "Epoch 3/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1405 - mse: 0.1405 - val_loss: 0.1013 - val_mse: 0.1013\n",
      "Epoch 4/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1313 - mse: 0.1313 - val_loss: 0.0831 - val_mse: 0.0831\n",
      "Epoch 5/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1254 - mse: 0.1254 - val_loss: 0.1503 - val_mse: 0.1503\n",
      "Epoch 6/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1165 - mse: 0.1165 - val_loss: 0.0884 - val_mse: 0.0884\n",
      "Epoch 7/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1130 - mse: 0.1130 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "Epoch 8/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 0.0674 - val_mse: 0.0674\n",
      "Epoch 9/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 0.0739 - val_mse: 0.0739\n",
      "Epoch 10/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1029 - mse: 0.1029 - val_loss: 0.0704 - val_mse: 0.0704\n",
      "Epoch 11/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.1024 - mse: 0.1024 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 12/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 0.0743 - val_mse: 0.0743\n",
      "Epoch 13/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0972 - mse: 0.0972 - val_loss: 0.0706 - val_mse: 0.0706\n",
      "Epoch 14/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 0.0641 - val_mse: 0.0641\n",
      "Epoch 15/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 16/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 0.0709 - val_mse: 0.0709\n",
      "Epoch 17/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0959 - mse: 0.0959 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 18/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0898 - mse: 0.0898 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 19/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 20/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 21/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 22/100\n",
      "1098/1098 [==============================] - 10s 9ms/step - loss: 0.0885 - mse: 0.0885 - val_loss: 0.0660 - val_mse: 0.0660\n",
      "Epoch 23/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 24/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0556 - val_mse: 0.0556\n",
      "Epoch 25/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 26/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 27/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0825 - mse: 0.0825 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 28/100\n",
      "1098/1098 [==============================] - 10s 9ms/step - loss: 0.0867 - mse: 0.0867 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 29/100\n",
      "1098/1098 [==============================] - 9s 8ms/step - loss: 0.0828 - mse: 0.0828 - val_loss: 0.0577 - val_mse: 0.0577\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "513900d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - 2s 3ms/step\n",
      "Root Mean Squared Error: 0.006337774053523272\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2638e74",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d4f486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(12 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        y.dropna(inplace=True)\n",
    "        y.reset_index(drop=True,inplace=True)\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(12).mean()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(12).max()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(12).min()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(12).std()\n",
    "        rolling_mean.dropna(inplace=True)\n",
    "        rolling_mean.reset_index(drop=True,inplace=True)\n",
    "        resample_list.append(rolling_mean)\n",
    "    df4 = pd.concat(resample_list, axis=0)\n",
    "    df4.reset_index(drop=True,inplace=True)\n",
    "    df = pd.concat([df1, df2, df3,df4], axis=1)\n",
    "    x = df\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6e0ab5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21120505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2dfa29fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec8786c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "275f2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46e8e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c813c7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "895d7838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.002173274012235055\n",
      "MSE:  1.910380109740352e-05\n",
      "RMSE:  0.004370789527923247\n",
      "R2:  0.9844649378835713\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c561c7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d6793228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.0021955090596002267\n",
      "MSE:  1.9049966291868898e-05\n",
      "RMSE:  0.00436462670704711\n",
      "R2:  0.9845087159277282\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a34bb153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 96)                13536     \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 96)               384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 384)              1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,185\n",
      "Trainable params: 64,161\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7f03b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1099/1099 [==============================] - 12s 7ms/step - loss: 0.2654 - mse: 0.2654 - val_loss: 0.2001 - val_mse: 0.2001\n",
      "Epoch 2/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.1564 - mse: 0.1564 - val_loss: 0.1907 - val_mse: 0.1907\n",
      "Epoch 3/100\n",
      "1099/1099 [==============================] - 7s 7ms/step - loss: 0.1328 - mse: 0.1328 - val_loss: 0.1008 - val_mse: 0.1008\n",
      "Epoch 4/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.1254 - mse: 0.1254 - val_loss: 0.0918 - val_mse: 0.0918\n",
      "Epoch 5/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.1140 - mse: 0.1140 - val_loss: 0.1060 - val_mse: 0.1060\n",
      "Epoch 6/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.1137 - mse: 0.1137 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 7/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.1023 - mse: 0.1023 - val_loss: 0.0800 - val_mse: 0.0800\n",
      "Epoch 8/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.1024 - mse: 0.1024 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 9/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0963 - mse: 0.0963 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 10/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 0.0880 - val_mse: 0.0880\n",
      "Epoch 11/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 12/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0910 - mse: 0.0910 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 13/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 14/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 15/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0832 - mse: 0.0832 - val_loss: 0.0743 - val_mse: 0.0743\n",
      "Epoch 16/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 0.0685 - val_mse: 0.0685\n",
      "Epoch 17/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0585 - val_mse: 0.0585\n",
      "Epoch 18/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 19/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0824 - mse: 0.0824 - val_loss: 0.0950 - val_mse: 0.0950\n",
      "Epoch 20/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0794 - mse: 0.0794 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 21/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 22/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0670 - val_mse: 0.0670\n",
      "Epoch 23/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0802 - mse: 0.0802 - val_loss: 0.0753 - val_mse: 0.0753\n",
      "Epoch 24/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0802 - mse: 0.0802 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 25/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0782 - mse: 0.0782 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 26/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0808 - mse: 0.0808 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 27/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0751 - mse: 0.0751 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 28/100\n",
      "1099/1099 [==============================] - 5s 5ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0660 - val_mse: 0.0660\n",
      "Epoch 29/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0754 - mse: 0.0754 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 30/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0753 - mse: 0.0753 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 31/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0721 - mse: 0.0721 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 32/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0753 - mse: 0.0753 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 33/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0753 - mse: 0.0753 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 34/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0734 - mse: 0.0734 - val_loss: 0.0620 - val_mse: 0.0620\n",
      "Epoch 35/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0480 - val_mse: 0.0480\n",
      "Epoch 36/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 37/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 38/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0719 - mse: 0.0719 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 39/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0721 - mse: 0.0721 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 40/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 41/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0749 - mse: 0.0749 - val_loss: 0.0556 - val_mse: 0.0556\n",
      "Epoch 42/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 43/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 44/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0506 - val_mse: 0.0506\n",
      "Epoch 45/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0697 - mse: 0.0697 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 46/100\n",
      "1099/1099 [==============================] - 7s 6ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 47/100\n",
      "1099/1099 [==============================] - 6s 5ms/step - loss: 0.0717 - mse: 0.0717 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 48/100\n",
      "1099/1099 [==============================] - 7s 7ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 49/100\n",
      "1099/1099 [==============================] - 8s 7ms/step - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 50/100\n",
      "1099/1099 [==============================] - 8s 7ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 51/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 52/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 53/100\n",
      "1099/1099 [==============================] - 6s 6ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0525 - val_mse: 0.0525\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "124122db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - 4s 3ms/step\n",
      "Root Mean Squared Error: 0.006747283380785661\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd7e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "def preprocess(df):\n",
    "    SeaTemp='SW20'\n",
    "    WindSpeed='WC0'\n",
    "    Load='FAU'\n",
    "    abr_sensor_list = ['E02005', 'E02006', 'E02056', 'E03760', 'G00027', 'G00108', 'G02011', 'N02015', 'P00023', 'P01005', 'P01302', 'P01303', 'P01600', 'P01602', 'P02055', 'P02065', 'P02066', 'P02071', 'P02072', 'Q02004', 'T00002', 'T01010', 'T01011', 'T01350', 'T01351', 'T01601', 'T01603', 'T02014', 'T02040', 'T02041', 'T02042', 'T02044', 'T04600', 'Z00518', 'Z01970', 'Z02013']\n",
    "    run_list = ['Time', 'Load', 'SeaTemp', 'WindSpeed', 'RunId']\n",
    "    df_sample=df[abr_sensor_list+run_list]\n",
    "    df_sample=df_sample[df_sample['SeaTemp']==SeaTemp]\n",
    "    df_sample=df_sample[df_sample['WindSpeed']==WindSpeed]\n",
    "    df_sample=df_sample[df_sample['Load']==Load]\n",
    "    resample_list=[]\n",
    "    output=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        y=s['Z02013']\n",
    "        y=y.shift(-(12 - 1)) # Shift so that last value in window corresponds to first position\n",
    "        y=y.rolling(1).mean() # Get rightmost value from each original window\n",
    "        s.drop(columns=['Z02013'],inplace=True)\n",
    "        rolling_mean = s.rolling(12).mean()\n",
    "        resample_list.append(rolling_mean)\n",
    "        output.append(y)\n",
    "    df1 = pd.concat(resample_list, axis=0)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    print(df1.shape)\n",
    "    resample_list=[]\n",
    "    \n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(12).max()\n",
    "        resample_list.append(rolling_mean)\n",
    "    df2 = pd.concat(resample_list, axis=0)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    print(df2.shape)\n",
    "    \n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(12).min()\n",
    "        resample_list.append(rolling_mean)\n",
    "    df3 = pd.concat(resample_list, axis=0)\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "    print(df3.shape)\n",
    "    \n",
    "    resample_list=[]\n",
    "    \n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_mean = s.rolling(12).std()\n",
    "        resample_list.append(rolling_mean)\n",
    "    df4 = pd.concat(resample_list, axis=0)\n",
    "    df4.reset_index(drop=True,inplace=True)\n",
    "    print(df4.shape)\n",
    "    \n",
    "    resample_list=[]\n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_skewness = s.rolling(12).apply(skew, raw=True)  # Compute skewness\n",
    "        resample_list.append(rolling_skewness)\n",
    "    df5 = pd.concat(resample_list, axis=0)\n",
    "    df5.reset_index(drop=True,inplace=True)\n",
    "    print(df5.shape)\n",
    "    resample_list=[]\n",
    "    \n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_kurtosis = s.rolling(12).apply(kurtosis, raw=True)  # Compute kurtosis\n",
    "        resample_list.append(rolling_kurtosis)\n",
    "    df6 = pd.concat(resample_list, axis=0)\n",
    "    df6.reset_index(drop=True,inplace=True)\n",
    "    print(df6.shape)\n",
    "    resample_list=[]\n",
    "    \n",
    "    for uniq in df_sample['RunId'].unique():\n",
    "        s=df_sample[df_sample['RunId']==uniq]\n",
    "        s.drop(columns=['Time', 'Load','SeaTemp','RunId','WindSpeed','Z02013'],inplace=True)\n",
    "        s.dropna(inplace=True)\n",
    "        s.reset_index(drop=True,inplace=True)\n",
    "        rolling_percentile = s.rolling(12).quantile(0.5)  # Compute median (50th percentile)\n",
    "        resample_list.append(rolling_percentile)\n",
    "    df7 = pd.concat(resample_list, axis=0)\n",
    "    df7.reset_index(drop=True,inplace=True)\n",
    "    print(df7.shape)\n",
    "    \n",
    "    df = pd.concat([df1, df2, df3, df4, df5, df6, df7], axis=1)\n",
    "    x = df\n",
    "    print(x.shape)\n",
    "    y = pd.concat(output, axis=0)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    print(y.shape)\n",
    "    df_deneme = pd.concat([x,y], axis=1)\n",
    "    df_deneme.dropna(inplace=True)\n",
    "    x = df_deneme.drop('Z02013', axis = 1) # Features\n",
    "    y = df_deneme['Z02013']  # Target\n",
    "    return x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea2fb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>16.5258</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778855</th>\n",
       "      <td>00:23:47</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4944</td>\n",
       "      <td>25.0092</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.9058</td>\n",
       "      <td>2.91922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1273</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1544</td>\n",
       "      <td>31.5922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778856</th>\n",
       "      <td>00:23:48</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4761</td>\n",
       "      <td>24.9927</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.7802</td>\n",
       "      <td>2.91487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1317</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1275</td>\n",
       "      <td>31.5982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778857</th>\n",
       "      <td>00:23:49</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4578</td>\n",
       "      <td>24.9762</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.6545</td>\n",
       "      <td>2.91053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1361</td>\n",
       "      <td>6</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>31.6042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778858</th>\n",
       "      <td>00:23:50</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4395</td>\n",
       "      <td>24.9597</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.5288</td>\n",
       "      <td>2.90618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1405</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0736</td>\n",
       "      <td>31.6102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778859</th>\n",
       "      <td>00:23:51</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>35</td>\n",
       "      <td>12.4212</td>\n",
       "      <td>24.9431</td>\n",
       "      <td>3353.82</td>\n",
       "      <td>12.4032</td>\n",
       "      <td>2.90183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1449</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0467</td>\n",
       "      <td>31.6162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778860 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0      1  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "778855  00:23:47  FAU    SW28       WC6     35  12.4944   25.0092  3353.82   \n",
       "778856  00:23:48  FAU    SW28       WC6     35  12.4761   24.9927  3353.82   \n",
       "778857  00:23:49  FAU    SW28       WC6     35  12.4578   24.9762  3353.82   \n",
       "778858  00:23:50  FAU    SW28       WC6     35  12.4395   24.9597  3353.82   \n",
       "778859  00:23:51  FAU    SW28       WC6     35  12.4212   24.9431  3353.82   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "1       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "2       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "3       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "4       16.5258  3.17649  ...     0.0  12.9311       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "778855  12.9058  2.91922  ...     0.0  16.1273       6  16.1544  31.5922   \n",
       "778856  12.7802  2.91487  ...     0.0  16.1317       6  16.1275  31.5982   \n",
       "778857  12.6545  2.91053  ...     0.0  16.1361       6  16.1005  31.6042   \n",
       "778858  12.5288  2.90618  ...     0.0  16.1405       6  16.0736  31.6102   \n",
       "778859  12.4032  2.90183  ...     0.0  16.1449       6  16.0467  31.6162   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1410  \n",
       "1          0.0     0.0       0       0    1409  \n",
       "2          0.0     0.0       0       0    1408  \n",
       "3          0.0     0.0       0       0    1407  \n",
       "4          0.0     0.0       0       0    1406  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "778855     0.0     1.0       0       0       4  \n",
       "778856     0.0     1.0       0       0       3  \n",
       "778857     0.0     1.0       0       0       2  \n",
       "778858     0.0     1.0       0       0       1  \n",
       "778859     0.0     1.0       0       0       0  \n",
       "\n",
       "[778860 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_train_sensors.csv', engine='c')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d5ee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44328, 35)\n",
      "(44328, 35)\n",
      "(44328, 35)\n",
      "(44328, 35)\n",
      "(44328, 35)\n",
      "(44328, 35)\n",
      "(44328, 35)\n",
      "(44328, 245)\n",
      "(44328,)\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4e3369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>G00108</th>\n",
       "      <th>G02011</th>\n",
       "      <th>N02015</th>\n",
       "      <th>P00023</th>\n",
       "      <th>P01005</th>\n",
       "      <th>...</th>\n",
       "      <th>T01601</th>\n",
       "      <th>T01603</th>\n",
       "      <th>T02014</th>\n",
       "      <th>T02040</th>\n",
       "      <th>T02041</th>\n",
       "      <th>T02042</th>\n",
       "      <th>T02044</th>\n",
       "      <th>T04600</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z01970</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.027000</td>\n",
       "      <td>312.616917</td>\n",
       "      <td>844.514083</td>\n",
       "      <td>13.801008</td>\n",
       "      <td>2.642437</td>\n",
       "      <td>2.836143</td>\n",
       "      <td>2.643335</td>\n",
       "      <td>73.951017</td>\n",
       "      <td>7.789336</td>\n",
       "      <td>2.154161</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53235</td>\n",
       "      <td>348.4440</td>\n",
       "      <td>305.373</td>\n",
       "      <td>303.5600</td>\n",
       "      <td>-1.828145</td>\n",
       "      <td>43.76470</td>\n",
       "      <td>48.00455</td>\n",
       "      <td>220.3750</td>\n",
       "      <td>12.80635</td>\n",
       "      <td>12.88630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.024908</td>\n",
       "      <td>314.617333</td>\n",
       "      <td>1032.184083</td>\n",
       "      <td>13.798533</td>\n",
       "      <td>2.643208</td>\n",
       "      <td>2.836438</td>\n",
       "      <td>2.644141</td>\n",
       "      <td>73.949333</td>\n",
       "      <td>7.789287</td>\n",
       "      <td>2.154257</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53205</td>\n",
       "      <td>348.4440</td>\n",
       "      <td>305.389</td>\n",
       "      <td>303.5725</td>\n",
       "      <td>-1.830540</td>\n",
       "      <td>43.75505</td>\n",
       "      <td>48.00440</td>\n",
       "      <td>220.3785</td>\n",
       "      <td>12.80640</td>\n",
       "      <td>12.88630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.023583</td>\n",
       "      <td>316.146167</td>\n",
       "      <td>1238.620750</td>\n",
       "      <td>13.796933</td>\n",
       "      <td>2.643834</td>\n",
       "      <td>2.836761</td>\n",
       "      <td>2.644791</td>\n",
       "      <td>73.948242</td>\n",
       "      <td>7.789235</td>\n",
       "      <td>2.154360</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53175</td>\n",
       "      <td>348.4440</td>\n",
       "      <td>305.405</td>\n",
       "      <td>303.5850</td>\n",
       "      <td>-1.832940</td>\n",
       "      <td>43.74535</td>\n",
       "      <td>48.00425</td>\n",
       "      <td>220.3815</td>\n",
       "      <td>12.80645</td>\n",
       "      <td>12.88630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.032850</td>\n",
       "      <td>310.487250</td>\n",
       "      <td>1463.824917</td>\n",
       "      <td>13.807467</td>\n",
       "      <td>2.642083</td>\n",
       "      <td>2.837114</td>\n",
       "      <td>2.642923</td>\n",
       "      <td>73.955358</td>\n",
       "      <td>7.789185</td>\n",
       "      <td>2.154445</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53145</td>\n",
       "      <td>348.4315</td>\n",
       "      <td>305.421</td>\n",
       "      <td>303.5975</td>\n",
       "      <td>-1.835335</td>\n",
       "      <td>43.73570</td>\n",
       "      <td>48.00410</td>\n",
       "      <td>220.3845</td>\n",
       "      <td>12.80650</td>\n",
       "      <td>12.88365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.042117</td>\n",
       "      <td>304.828333</td>\n",
       "      <td>1689.028750</td>\n",
       "      <td>13.818008</td>\n",
       "      <td>2.640331</td>\n",
       "      <td>2.837468</td>\n",
       "      <td>2.641055</td>\n",
       "      <td>73.962483</td>\n",
       "      <td>7.789135</td>\n",
       "      <td>2.154530</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53115</td>\n",
       "      <td>348.4190</td>\n",
       "      <td>305.437</td>\n",
       "      <td>303.6100</td>\n",
       "      <td>-1.837730</td>\n",
       "      <td>43.72605</td>\n",
       "      <td>48.00395</td>\n",
       "      <td>220.3875</td>\n",
       "      <td>12.80655</td>\n",
       "      <td>12.88100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44312</th>\n",
       "      <td>14.092300</td>\n",
       "      <td>267.508000</td>\n",
       "      <td>3131.996667</td>\n",
       "      <td>13.876283</td>\n",
       "      <td>2.626069</td>\n",
       "      <td>2.834361</td>\n",
       "      <td>2.626052</td>\n",
       "      <td>74.001392</td>\n",
       "      <td>7.789750</td>\n",
       "      <td>2.156336</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53785</td>\n",
       "      <td>348.3760</td>\n",
       "      <td>305.396</td>\n",
       "      <td>303.9135</td>\n",
       "      <td>-1.489035</td>\n",
       "      <td>44.05450</td>\n",
       "      <td>48.00870</td>\n",
       "      <td>220.3875</td>\n",
       "      <td>12.80430</td>\n",
       "      <td>12.83010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44313</th>\n",
       "      <td>14.092683</td>\n",
       "      <td>266.521083</td>\n",
       "      <td>3131.919167</td>\n",
       "      <td>13.876692</td>\n",
       "      <td>2.625958</td>\n",
       "      <td>2.834342</td>\n",
       "      <td>2.625938</td>\n",
       "      <td>74.001492</td>\n",
       "      <td>7.789777</td>\n",
       "      <td>2.156388</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53740</td>\n",
       "      <td>348.3760</td>\n",
       "      <td>305.410</td>\n",
       "      <td>303.9305</td>\n",
       "      <td>-1.486765</td>\n",
       "      <td>44.04710</td>\n",
       "      <td>48.00870</td>\n",
       "      <td>220.3900</td>\n",
       "      <td>12.80430</td>\n",
       "      <td>12.82850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44314</th>\n",
       "      <td>14.093083</td>\n",
       "      <td>265.438667</td>\n",
       "      <td>3131.837500</td>\n",
       "      <td>13.877117</td>\n",
       "      <td>2.625839</td>\n",
       "      <td>2.834316</td>\n",
       "      <td>2.625817</td>\n",
       "      <td>74.001575</td>\n",
       "      <td>7.789807</td>\n",
       "      <td>2.156427</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53695</td>\n",
       "      <td>348.3760</td>\n",
       "      <td>305.424</td>\n",
       "      <td>303.9470</td>\n",
       "      <td>-1.484495</td>\n",
       "      <td>44.03290</td>\n",
       "      <td>48.00870</td>\n",
       "      <td>220.3925</td>\n",
       "      <td>12.80430</td>\n",
       "      <td>12.82690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44315</th>\n",
       "      <td>14.093492</td>\n",
       "      <td>264.260583</td>\n",
       "      <td>3131.753333</td>\n",
       "      <td>13.877558</td>\n",
       "      <td>2.625712</td>\n",
       "      <td>2.834282</td>\n",
       "      <td>2.625687</td>\n",
       "      <td>74.001633</td>\n",
       "      <td>7.789841</td>\n",
       "      <td>2.156453</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53645</td>\n",
       "      <td>348.3760</td>\n",
       "      <td>305.438</td>\n",
       "      <td>303.9635</td>\n",
       "      <td>-1.482225</td>\n",
       "      <td>44.01870</td>\n",
       "      <td>48.00870</td>\n",
       "      <td>220.3955</td>\n",
       "      <td>12.80430</td>\n",
       "      <td>12.82530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44316</th>\n",
       "      <td>14.093917</td>\n",
       "      <td>262.986917</td>\n",
       "      <td>3131.665000</td>\n",
       "      <td>13.878017</td>\n",
       "      <td>2.625575</td>\n",
       "      <td>2.834241</td>\n",
       "      <td>2.625549</td>\n",
       "      <td>74.001675</td>\n",
       "      <td>7.789878</td>\n",
       "      <td>2.156467</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53595</td>\n",
       "      <td>348.3760</td>\n",
       "      <td>305.452</td>\n",
       "      <td>303.9805</td>\n",
       "      <td>-1.479955</td>\n",
       "      <td>44.00450</td>\n",
       "      <td>48.00870</td>\n",
       "      <td>220.3980</td>\n",
       "      <td>12.80430</td>\n",
       "      <td>12.82370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43558 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E02005      E02006       E02056     E03760    G00027    G00108  \\\n",
       "11     14.027000  312.616917   844.514083  13.801008  2.642437  2.836143   \n",
       "12     14.024908  314.617333  1032.184083  13.798533  2.643208  2.836438   \n",
       "13     14.023583  316.146167  1238.620750  13.796933  2.643834  2.836761   \n",
       "14     14.032850  310.487250  1463.824917  13.807467  2.642083  2.837114   \n",
       "15     14.042117  304.828333  1689.028750  13.818008  2.640331  2.837468   \n",
       "...          ...         ...          ...        ...       ...       ...   \n",
       "44312  14.092300  267.508000  3131.996667  13.876283  2.626069  2.834361   \n",
       "44313  14.092683  266.521083  3131.919167  13.876692  2.625958  2.834342   \n",
       "44314  14.093083  265.438667  3131.837500  13.877117  2.625839  2.834316   \n",
       "44315  14.093492  264.260583  3131.753333  13.877558  2.625712  2.834282   \n",
       "44316  14.093917  262.986917  3131.665000  13.878017  2.625575  2.834241   \n",
       "\n",
       "         G02011     N02015    P00023    P01005  ...    T01601    T01603  \\\n",
       "11     2.643335  73.951017  7.789336  2.154161  ...  43.53235  348.4440   \n",
       "12     2.644141  73.949333  7.789287  2.154257  ...  43.53205  348.4440   \n",
       "13     2.644791  73.948242  7.789235  2.154360  ...  43.53175  348.4440   \n",
       "14     2.642923  73.955358  7.789185  2.154445  ...  43.53145  348.4315   \n",
       "15     2.641055  73.962483  7.789135  2.154530  ...  43.53115  348.4190   \n",
       "...         ...        ...       ...       ...  ...       ...       ...   \n",
       "44312  2.626052  74.001392  7.789750  2.156336  ...  43.53785  348.3760   \n",
       "44313  2.625938  74.001492  7.789777  2.156388  ...  43.53740  348.3760   \n",
       "44314  2.625817  74.001575  7.789807  2.156427  ...  43.53695  348.3760   \n",
       "44315  2.625687  74.001633  7.789841  2.156453  ...  43.53645  348.3760   \n",
       "44316  2.625549  74.001675  7.789878  2.156467  ...  43.53595  348.3760   \n",
       "\n",
       "        T02014    T02040    T02041    T02042    T02044    T04600    Z00518  \\\n",
       "11     305.373  303.5600 -1.828145  43.76470  48.00455  220.3750  12.80635   \n",
       "12     305.389  303.5725 -1.830540  43.75505  48.00440  220.3785  12.80640   \n",
       "13     305.405  303.5850 -1.832940  43.74535  48.00425  220.3815  12.80645   \n",
       "14     305.421  303.5975 -1.835335  43.73570  48.00410  220.3845  12.80650   \n",
       "15     305.437  303.6100 -1.837730  43.72605  48.00395  220.3875  12.80655   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "44312  305.396  303.9135 -1.489035  44.05450  48.00870  220.3875  12.80430   \n",
       "44313  305.410  303.9305 -1.486765  44.04710  48.00870  220.3900  12.80430   \n",
       "44314  305.424  303.9470 -1.484495  44.03290  48.00870  220.3925  12.80430   \n",
       "44315  305.438  303.9635 -1.482225  44.01870  48.00870  220.3955  12.80430   \n",
       "44316  305.452  303.9805 -1.479955  44.00450  48.00870  220.3980  12.80430   \n",
       "\n",
       "         Z01970  \n",
       "11     12.88630  \n",
       "12     12.88630  \n",
       "13     12.88630  \n",
       "14     12.88365  \n",
       "15     12.88100  \n",
       "...         ...  \n",
       "44312  12.83010  \n",
       "44313  12.82850  \n",
       "44314  12.82690  \n",
       "44315  12.82530  \n",
       "44316  12.82370  \n",
       "\n",
       "[43558 rows x 245 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e03a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Load</th>\n",
       "      <th>SeaTemp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RunId</th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>...</th>\n",
       "      <th>X02445</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z00770</th>\n",
       "      <th>Z01970</th>\n",
       "      <th>Z02013</th>\n",
       "      <th>Z02436</th>\n",
       "      <th>Z02437</th>\n",
       "      <th>Z02477</th>\n",
       "      <th>Z02482</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:01</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:02</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:03</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>FAL</td>\n",
       "      <td>SW20</td>\n",
       "      <td>WC0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.7659</td>\n",
       "      <td>430.9120</td>\n",
       "      <td>3647.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.9813</td>\n",
       "      <td>22.5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402488</th>\n",
       "      <td>00:19:20</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5748</td>\n",
       "      <td>25.1889</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>12.2076</td>\n",
       "      <td>3.11218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2952</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9101</td>\n",
       "      <td>31.4515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402489</th>\n",
       "      <td>00:19:21</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.5252</td>\n",
       "      <td>25.1680</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.9689</td>\n",
       "      <td>3.09877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2934</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9109</td>\n",
       "      <td>31.3278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402490</th>\n",
       "      <td>00:19:22</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>25.1472</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.7302</td>\n",
       "      <td>3.08536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2917</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9116</td>\n",
       "      <td>31.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402491</th>\n",
       "      <td>00:19:23</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.4259</td>\n",
       "      <td>25.1263</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.4916</td>\n",
       "      <td>3.07195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2899</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9123</td>\n",
       "      <td>31.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402492</th>\n",
       "      <td>00:19:24</td>\n",
       "      <td>FAU</td>\n",
       "      <td>SW28</td>\n",
       "      <td>WC6</td>\n",
       "      <td>53</td>\n",
       "      <td>13.3763</td>\n",
       "      <td>25.1055</td>\n",
       "      <td>3573.65</td>\n",
       "      <td>11.2529</td>\n",
       "      <td>3.05854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2882</td>\n",
       "      <td>6</td>\n",
       "      <td>16.9131</td>\n",
       "      <td>30.9567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402493 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time Load SeaTemp WindSpeed  RunId   E02005    E02006   E02056  \\\n",
       "0       00:00:00  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "1       00:00:01  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "2       00:00:02  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "3       00:00:03  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "4       00:00:04  FAL    SW20       WC0     36  16.7659  430.9120  3647.98   \n",
       "...          ...  ...     ...       ...    ...      ...       ...      ...   \n",
       "402488  00:19:20  FAU    SW28       WC6     53  13.5748   25.1889  3573.65   \n",
       "402489  00:19:21  FAU    SW28       WC6     53  13.5252   25.1680  3573.65   \n",
       "402490  00:19:22  FAU    SW28       WC6     53  13.4756   25.1472  3573.65   \n",
       "402491  00:19:23  FAU    SW28       WC6     53  13.4259   25.1263  3573.65   \n",
       "402492  00:19:24  FAU    SW28       WC6     53  13.3763   25.1055  3573.65   \n",
       "\n",
       "         E03760   G00027  ...  X02445   Z00518  Z00770   Z01970   Z02013  \\\n",
       "0           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "1           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "2           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "3           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "4           NaN  3.17649  ...     NaN      NaN       0  14.9813  22.5320   \n",
       "...         ...      ...  ...     ...      ...     ...      ...      ...   \n",
       "402488  12.2076  3.11218  ...     0.0  16.2952       6  16.9101  31.4515   \n",
       "402489  11.9689  3.09877  ...     0.0  16.2934       6  16.9109  31.3278   \n",
       "402490  11.7302  3.08536  ...     0.0  16.2917       6  16.9116  31.2041   \n",
       "402491  11.4916  3.07195  ...     0.0  16.2899       6  16.9123  31.0804   \n",
       "402492  11.2529  3.05854  ...     0.0  16.2882       6  16.9131  30.9567   \n",
       "\n",
       "        Z02436  Z02437  Z02477  Z02482  Linear  \n",
       "0          0.0     0.0       0       0    1413  \n",
       "1          0.0     0.0       0       0    1412  \n",
       "2          0.0     0.0       0       0    1411  \n",
       "3          0.0     0.0       0       0    1410  \n",
       "4          0.0     0.0       0       0    1409  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "402488     0.0     1.0       0       0       4  \n",
       "402489     0.0     1.0       0       0       3  \n",
       "402490     0.0     1.0       0       0       2  \n",
       "402491     0.0     1.0       0       0       1  \n",
       "402492     0.0     1.0       0       0       0  \n",
       "\n",
       "[402493 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft=pd.read_csv(r'E:\\Havelsan\\Datasets\\M0000_test_sensors.csv', engine='c')\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911bb474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\anilo\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21594, 35)\n",
      "(21594, 35)\n",
      "(21594, 35)\n",
      "(21594, 35)\n",
      "(21594, 35)\n",
      "(21594, 35)\n",
      "(21594, 35)\n",
      "(21594, 245)\n",
      "(21594,)\n"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = preprocess(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f039f029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E02005</th>\n",
       "      <th>E02006</th>\n",
       "      <th>E02056</th>\n",
       "      <th>E03760</th>\n",
       "      <th>G00027</th>\n",
       "      <th>G00108</th>\n",
       "      <th>G02011</th>\n",
       "      <th>N02015</th>\n",
       "      <th>P00023</th>\n",
       "      <th>P01005</th>\n",
       "      <th>...</th>\n",
       "      <th>T01601</th>\n",
       "      <th>T01603</th>\n",
       "      <th>T02014</th>\n",
       "      <th>T02040</th>\n",
       "      <th>T02041</th>\n",
       "      <th>T02042</th>\n",
       "      <th>T02044</th>\n",
       "      <th>T04600</th>\n",
       "      <th>Z00518</th>\n",
       "      <th>Z01970</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.093850</td>\n",
       "      <td>271.489667</td>\n",
       "      <td>1050.313333</td>\n",
       "      <td>13.877708</td>\n",
       "      <td>2.628002</td>\n",
       "      <td>2.836724</td>\n",
       "      <td>2.628002</td>\n",
       "      <td>74.000500</td>\n",
       "      <td>7.789170</td>\n",
       "      <td>2.153618</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53340</td>\n",
       "      <td>348.1430</td>\n",
       "      <td>305.3170</td>\n",
       "      <td>303.4970</td>\n",
       "      <td>-1.819760</td>\n",
       "      <td>43.79850</td>\n",
       "      <td>48.0050</td>\n",
       "      <td>220.3590</td>\n",
       "      <td>12.80620</td>\n",
       "      <td>12.82970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.094692</td>\n",
       "      <td>272.417333</td>\n",
       "      <td>1312.625833</td>\n",
       "      <td>13.878583</td>\n",
       "      <td>2.628277</td>\n",
       "      <td>2.837165</td>\n",
       "      <td>2.628269</td>\n",
       "      <td>74.000500</td>\n",
       "      <td>7.789082</td>\n",
       "      <td>2.153661</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53340</td>\n",
       "      <td>348.1430</td>\n",
       "      <td>305.3170</td>\n",
       "      <td>303.4970</td>\n",
       "      <td>-1.819760</td>\n",
       "      <td>43.79850</td>\n",
       "      <td>48.0050</td>\n",
       "      <td>220.3590</td>\n",
       "      <td>12.80620</td>\n",
       "      <td>12.82970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.095517</td>\n",
       "      <td>273.234750</td>\n",
       "      <td>1574.832500</td>\n",
       "      <td>13.879450</td>\n",
       "      <td>2.628532</td>\n",
       "      <td>2.837592</td>\n",
       "      <td>2.628516</td>\n",
       "      <td>74.000500</td>\n",
       "      <td>7.789000</td>\n",
       "      <td>2.153717</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53175</td>\n",
       "      <td>348.3240</td>\n",
       "      <td>305.3950</td>\n",
       "      <td>303.5610</td>\n",
       "      <td>-1.832230</td>\n",
       "      <td>43.75605</td>\n",
       "      <td>48.0050</td>\n",
       "      <td>220.3595</td>\n",
       "      <td>12.80645</td>\n",
       "      <td>12.85100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.096333</td>\n",
       "      <td>273.941833</td>\n",
       "      <td>1836.932500</td>\n",
       "      <td>13.880308</td>\n",
       "      <td>2.628767</td>\n",
       "      <td>2.838006</td>\n",
       "      <td>2.628742</td>\n",
       "      <td>74.000500</td>\n",
       "      <td>7.788925</td>\n",
       "      <td>2.153788</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53010</td>\n",
       "      <td>348.4995</td>\n",
       "      <td>305.4770</td>\n",
       "      <td>303.6290</td>\n",
       "      <td>-1.844360</td>\n",
       "      <td>43.71260</td>\n",
       "      <td>48.0049</td>\n",
       "      <td>220.3635</td>\n",
       "      <td>12.80670</td>\n",
       "      <td>12.87055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.097142</td>\n",
       "      <td>274.538667</td>\n",
       "      <td>2098.926667</td>\n",
       "      <td>13.881150</td>\n",
       "      <td>2.628980</td>\n",
       "      <td>2.838405</td>\n",
       "      <td>2.628947</td>\n",
       "      <td>74.000500</td>\n",
       "      <td>7.788857</td>\n",
       "      <td>2.153874</td>\n",
       "      <td>...</td>\n",
       "      <td>43.53010</td>\n",
       "      <td>348.4995</td>\n",
       "      <td>305.4845</td>\n",
       "      <td>303.6370</td>\n",
       "      <td>-1.844360</td>\n",
       "      <td>43.71065</td>\n",
       "      <td>48.0047</td>\n",
       "      <td>220.3705</td>\n",
       "      <td>12.80670</td>\n",
       "      <td>12.87055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21578</th>\n",
       "      <td>14.085133</td>\n",
       "      <td>288.563583</td>\n",
       "      <td>3132.349167</td>\n",
       "      <td>13.869200</td>\n",
       "      <td>2.627865</td>\n",
       "      <td>2.833995</td>\n",
       "      <td>2.627865</td>\n",
       "      <td>73.996200</td>\n",
       "      <td>7.789395</td>\n",
       "      <td>2.148295</td>\n",
       "      <td>...</td>\n",
       "      <td>43.52610</td>\n",
       "      <td>348.3680</td>\n",
       "      <td>305.7035</td>\n",
       "      <td>304.2970</td>\n",
       "      <td>-1.406090</td>\n",
       "      <td>43.53935</td>\n",
       "      <td>48.0106</td>\n",
       "      <td>220.5460</td>\n",
       "      <td>12.80620</td>\n",
       "      <td>12.85135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21579</th>\n",
       "      <td>14.085808</td>\n",
       "      <td>288.241500</td>\n",
       "      <td>3132.585000</td>\n",
       "      <td>13.869917</td>\n",
       "      <td>2.627917</td>\n",
       "      <td>2.834190</td>\n",
       "      <td>2.627918</td>\n",
       "      <td>73.996692</td>\n",
       "      <td>7.789378</td>\n",
       "      <td>2.148227</td>\n",
       "      <td>...</td>\n",
       "      <td>43.52610</td>\n",
       "      <td>348.3580</td>\n",
       "      <td>305.7035</td>\n",
       "      <td>304.2970</td>\n",
       "      <td>-1.405905</td>\n",
       "      <td>43.53590</td>\n",
       "      <td>48.0106</td>\n",
       "      <td>220.5505</td>\n",
       "      <td>12.80600</td>\n",
       "      <td>12.85135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21580</th>\n",
       "      <td>14.086517</td>\n",
       "      <td>287.742667</td>\n",
       "      <td>3132.821667</td>\n",
       "      <td>13.870650</td>\n",
       "      <td>2.627952</td>\n",
       "      <td>2.834383</td>\n",
       "      <td>2.627952</td>\n",
       "      <td>73.997208</td>\n",
       "      <td>7.789366</td>\n",
       "      <td>2.148182</td>\n",
       "      <td>...</td>\n",
       "      <td>43.52610</td>\n",
       "      <td>348.3485</td>\n",
       "      <td>305.7010</td>\n",
       "      <td>304.2935</td>\n",
       "      <td>-1.405720</td>\n",
       "      <td>43.53245</td>\n",
       "      <td>48.0106</td>\n",
       "      <td>220.5550</td>\n",
       "      <td>12.80580</td>\n",
       "      <td>12.85135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21581</th>\n",
       "      <td>14.087258</td>\n",
       "      <td>287.067000</td>\n",
       "      <td>3133.059167</td>\n",
       "      <td>13.871408</td>\n",
       "      <td>2.627970</td>\n",
       "      <td>2.834575</td>\n",
       "      <td>2.627970</td>\n",
       "      <td>73.997742</td>\n",
       "      <td>7.789360</td>\n",
       "      <td>2.148160</td>\n",
       "      <td>...</td>\n",
       "      <td>43.52610</td>\n",
       "      <td>348.3390</td>\n",
       "      <td>305.6985</td>\n",
       "      <td>304.2905</td>\n",
       "      <td>-1.405535</td>\n",
       "      <td>43.52895</td>\n",
       "      <td>48.0106</td>\n",
       "      <td>220.5590</td>\n",
       "      <td>12.80560</td>\n",
       "      <td>12.85135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>14.088017</td>\n",
       "      <td>286.214500</td>\n",
       "      <td>3133.296667</td>\n",
       "      <td>13.872192</td>\n",
       "      <td>2.627970</td>\n",
       "      <td>2.834765</td>\n",
       "      <td>2.627970</td>\n",
       "      <td>73.998300</td>\n",
       "      <td>7.789360</td>\n",
       "      <td>2.148160</td>\n",
       "      <td>...</td>\n",
       "      <td>43.52610</td>\n",
       "      <td>348.3290</td>\n",
       "      <td>305.6960</td>\n",
       "      <td>304.2875</td>\n",
       "      <td>-1.405350</td>\n",
       "      <td>43.52550</td>\n",
       "      <td>48.0106</td>\n",
       "      <td>220.5630</td>\n",
       "      <td>12.80540</td>\n",
       "      <td>12.85125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21198 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E02005      E02006       E02056     E03760    G00027    G00108  \\\n",
       "11     14.093850  271.489667  1050.313333  13.877708  2.628002  2.836724   \n",
       "12     14.094692  272.417333  1312.625833  13.878583  2.628277  2.837165   \n",
       "13     14.095517  273.234750  1574.832500  13.879450  2.628532  2.837592   \n",
       "14     14.096333  273.941833  1836.932500  13.880308  2.628767  2.838006   \n",
       "15     14.097142  274.538667  2098.926667  13.881150  2.628980  2.838405   \n",
       "...          ...         ...          ...        ...       ...       ...   \n",
       "21578  14.085133  288.563583  3132.349167  13.869200  2.627865  2.833995   \n",
       "21579  14.085808  288.241500  3132.585000  13.869917  2.627917  2.834190   \n",
       "21580  14.086517  287.742667  3132.821667  13.870650  2.627952  2.834383   \n",
       "21581  14.087258  287.067000  3133.059167  13.871408  2.627970  2.834575   \n",
       "21582  14.088017  286.214500  3133.296667  13.872192  2.627970  2.834765   \n",
       "\n",
       "         G02011     N02015    P00023    P01005  ...    T01601    T01603  \\\n",
       "11     2.628002  74.000500  7.789170  2.153618  ...  43.53340  348.1430   \n",
       "12     2.628269  74.000500  7.789082  2.153661  ...  43.53340  348.1430   \n",
       "13     2.628516  74.000500  7.789000  2.153717  ...  43.53175  348.3240   \n",
       "14     2.628742  74.000500  7.788925  2.153788  ...  43.53010  348.4995   \n",
       "15     2.628947  74.000500  7.788857  2.153874  ...  43.53010  348.4995   \n",
       "...         ...        ...       ...       ...  ...       ...       ...   \n",
       "21578  2.627865  73.996200  7.789395  2.148295  ...  43.52610  348.3680   \n",
       "21579  2.627918  73.996692  7.789378  2.148227  ...  43.52610  348.3580   \n",
       "21580  2.627952  73.997208  7.789366  2.148182  ...  43.52610  348.3485   \n",
       "21581  2.627970  73.997742  7.789360  2.148160  ...  43.52610  348.3390   \n",
       "21582  2.627970  73.998300  7.789360  2.148160  ...  43.52610  348.3290   \n",
       "\n",
       "         T02014    T02040    T02041    T02042   T02044    T04600    Z00518  \\\n",
       "11     305.3170  303.4970 -1.819760  43.79850  48.0050  220.3590  12.80620   \n",
       "12     305.3170  303.4970 -1.819760  43.79850  48.0050  220.3590  12.80620   \n",
       "13     305.3950  303.5610 -1.832230  43.75605  48.0050  220.3595  12.80645   \n",
       "14     305.4770  303.6290 -1.844360  43.71260  48.0049  220.3635  12.80670   \n",
       "15     305.4845  303.6370 -1.844360  43.71065  48.0047  220.3705  12.80670   \n",
       "...         ...       ...       ...       ...      ...       ...       ...   \n",
       "21578  305.7035  304.2970 -1.406090  43.53935  48.0106  220.5460  12.80620   \n",
       "21579  305.7035  304.2970 -1.405905  43.53590  48.0106  220.5505  12.80600   \n",
       "21580  305.7010  304.2935 -1.405720  43.53245  48.0106  220.5550  12.80580   \n",
       "21581  305.6985  304.2905 -1.405535  43.52895  48.0106  220.5590  12.80560   \n",
       "21582  305.6960  304.2875 -1.405350  43.52550  48.0106  220.5630  12.80540   \n",
       "\n",
       "         Z01970  \n",
       "11     12.82970  \n",
       "12     12.82970  \n",
       "13     12.85100  \n",
       "14     12.87055  \n",
       "15     12.87055  \n",
       "...         ...  \n",
       "21578  12.85135  \n",
       "21579  12.85135  \n",
       "21580  12.85135  \n",
       "21581  12.85135  \n",
       "21582  12.85125  \n",
       "\n",
       "[21198 rows x 245 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70c8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8466934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_scaled = scaler.transform(Y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0efeb2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a889fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.004342132517769868\n",
      "MSE:  5.92788913183345e-05\n",
      "RMSE:  0.007699278623243511\n",
      "R2:  0.9520415954286464\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edc9775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=30, max_features='log2',\n",
       "                      min_samples_split=5, n_estimators=400, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with the best parameters\n",
    "model_3 = RandomForestRegressor(\n",
    "   n_estimators= 400, \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf= 1, \n",
    "    max_features=\"log2\", \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    random_state=42,  # Seed\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "model_3.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6657ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "MAE:  0.004367964500878407\n",
      "MSE:  5.9666700615626876e-05\n",
      "RMSE:  0.007724422348345983\n",
      "R2:  0.9517278460523937\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evolution_Metrics(model_3,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53908d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 96)                23616     \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 96)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 96)               384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 384)               37248     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 384)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 384)              1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                12320     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,265\n",
      "Trainable params: 74,241\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(96, input_dim=X_train_scaled.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(384))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.30000000000000004))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Define learning rate decay\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                               decay_steps=10000,\n",
    "                               decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "335af6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1089/1089 [==============================] - 6s 4ms/step - loss: 0.4369 - mse: 0.4369 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 2/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.2404 - mse: 0.2404 - val_loss: 0.1310 - val_mse: 0.1310\n",
      "Epoch 3/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.2129 - mse: 0.2129 - val_loss: 0.1244 - val_mse: 0.1244\n",
      "Epoch 4/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1905 - mse: 0.1905 - val_loss: 0.2440 - val_mse: 0.2440\n",
      "Epoch 5/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1807 - mse: 0.1807 - val_loss: 0.1054 - val_mse: 0.1054\n",
      "Epoch 6/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1751 - mse: 0.1751 - val_loss: 0.1443 - val_mse: 0.1443\n",
      "Epoch 7/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1651 - mse: 0.1651 - val_loss: 0.1149 - val_mse: 0.1149\n",
      "Epoch 8/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1560 - mse: 0.1560 - val_loss: 0.1144 - val_mse: 0.1144\n",
      "Epoch 9/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1543 - mse: 0.1543 - val_loss: 0.0998 - val_mse: 0.0998\n",
      "Epoch 10/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1493 - mse: 0.1493 - val_loss: 0.0856 - val_mse: 0.0856\n",
      "Epoch 11/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1437 - mse: 0.1437 - val_loss: 0.0960 - val_mse: 0.0960\n",
      "Epoch 12/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.0973 - val_mse: 0.0973\n",
      "Epoch 13/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1405 - mse: 0.1405 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 14/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1375 - mse: 0.1375 - val_loss: 0.0814 - val_mse: 0.0814\n",
      "Epoch 15/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1337 - mse: 0.1337 - val_loss: 0.0949 - val_mse: 0.0949\n",
      "Epoch 16/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1321 - mse: 0.1321 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 17/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 0.0928 - val_mse: 0.0928\n",
      "Epoch 18/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1293 - mse: 0.1293 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 19/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1260 - mse: 0.1260 - val_loss: 0.0849 - val_mse: 0.0849\n",
      "Epoch 20/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1258 - mse: 0.1258 - val_loss: 0.0899 - val_mse: 0.0899\n",
      "Epoch 21/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1262 - mse: 0.1262 - val_loss: 0.0825 - val_mse: 0.0825\n",
      "Epoch 22/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 0.0816 - val_mse: 0.0816\n",
      "Epoch 23/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1223 - mse: 0.1223 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 24/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 25/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1208 - mse: 0.1208 - val_loss: 0.0857 - val_mse: 0.0857\n",
      "Epoch 26/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1207 - mse: 0.1207 - val_loss: 0.0707 - val_mse: 0.0707\n",
      "Epoch 27/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1207 - mse: 0.1207 - val_loss: 0.0828 - val_mse: 0.0828\n",
      "Epoch 28/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 29/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1180 - mse: 0.1180 - val_loss: 0.0946 - val_mse: 0.0946\n",
      "Epoch 30/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 0.0796 - val_mse: 0.0796\n",
      "Epoch 31/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1177 - mse: 0.1177 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 32/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1156 - mse: 0.1156 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 33/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 0.0989 - val_mse: 0.0989\n",
      "Epoch 34/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1164 - mse: 0.1164 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 35/100\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 0.1144 - mse: 0.1144 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 36/100\n",
      "1089/1089 [==============================] - 5s 4ms/step - loss: 0.1132 - mse: 0.1132 - val_loss: 0.0739 - val_mse: 0.0739\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_scaled, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd26939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663/663 [==============================] - 1s 2ms/step\n",
      "Root Mean Squared Error: 0.009258542199731372\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predicted values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239de7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf8c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
